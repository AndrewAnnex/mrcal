#!/usr/bin/python3

r'''Visualize the difference in projection between N models

SYNOPSIS

  $ mrcal-show-projection-diff before.cameramodel after.cameramodel
  ... a plot pops up showing how these two models differ in their projections

The operation of this tool is documented at
http://fatty.jpl.nasa.gov/mrcal/differencing.html

It is often useful to compare the projection behavior of two camera models. For
instance, one may want to validate a calibration by comparing the results of two
different chessboard dances. Or one may want to evaluate the stability of the
intrinsics in response to mechanical or thermal stresses. This tool makes these
comparisons, and produces a visualization of the results.

In the most common case we're given exactly 2 models to compare. We then display
the projection difference as either a vector field or a heat map. If we're given
more than 2 models, then a vector field isn't possible and we instead display as
a heatmap the standard deviation of the differences between models 1..N and
model0.

How are we computing the differences? The details are in the docstring of
mrcal.projection_diff(). Broadly, we do this:

- grid the imager
- unproject each point in the grid from one camera to produce a world point
- apply a transformation we compute to match up the two camera geometries
- reproject the transformed points to the other camera
- look at the resulting pixel difference in the reprojection

When looking at multiple cameras, their lens intrinsics differ. Less obviously,
the position and orientation of the camera coordinate system in respect to the
physical camera housing differ also. These geometric uncertainties are baked
into the intrinsics. So when we project "the same world point" into both
cameras, we must apply a geometric transformation because we want to be
comparing projections of world points (relative to the camera housing), not
projections relative to the (floating) camera coordinate systems. This
transformation is unknown, but we can estimate it in one of several ways:

- If we KNOW that there is no geometric difference between our cameras, and we
  thus should look at the intrinsics differences only, we assuming that
  implied_Rt10 = identity. Indicate this case by passing --radius 0

- Otherwise, we fit projections across the imager: the "right" transformation
  would result in apparent low projection differences in a wide area.

This fitted transformation is computed by implied_Rt10__from_unprojections(),
and some details of its operation are significant:

- The imager area we use for the fit
- Which world points we're looking at

In most practical usages, we would not expect a good fit everywhere in the
imager: areas where no chessboards were observed will not fit well, for
instance. From the point of view of the fit we perform, those ill-fitting areas
should be treated as outliers, and they should NOT be a part of the solve. How
do we specify the well-fitting area? The best way is to use the model
uncertainties: these can be used to emphasize the confident regions of the
imager. This is the default behavior. If uncertainties aren't available, or if
we want a faster solve, pass --no-uncertainties. The well-fitting region can
then be passed using --where and --radius to indicate the circle in the imager
we care about.

If using uncertainties then we utilize all the data in the imager by default. if
--no-uncertainties, then the defaults are to use a more reasonable circle of
radius min(width,height)/6 at the center of the imager. Usually this is
sufficiently correct, and we don't need to mess with it. If we aren't guided to
the correct focus region, the implied-by-the-intrinsics solve will try to fit
lots of outliers, which would result in an incorrect transformation, which in
turn would produce overly-high reported diffs. A common case when this happens
is if the chessboard observations used in the calibration were concentrated to
the side of the image (off-center), no uncertainties were used, and --where was
not pointed to that area.

Unlike the projection operation, the diff operation is NOT invariant under
geometric scaling: if we look at the projection difference for two points at
different locations along a single observation ray, there will be a variation in
the observed diff. This is due to the geometric difference in the two cameras.
If the models differed only in their intrinsics parameters, then this variation
would not appear. Thus we need to know how far from the camera to look, and this
is specified by --distance. By default we look out to infinity. If we care about
the projection difference at some other distance, pass that here. Generally the
most confident distance will be where the chessboards were observed at
calibration time.

'''


import sys
import argparse
import re
import os

def parse_args():

    parser = \
        argparse.ArgumentParser(description = __doc__,
                                formatter_class=argparse.RawDescriptionHelpFormatter)

    parser.add_argument('--gridn',
                        type=int,
                        default = (60,40),
                        nargs = 2,
                        help='''How densely we should sample the imager. By default we use a 60x40 grid''')
    parser.add_argument('--distance',
                        type=str,
                        help='''By default we compute the implied transformation for points infinitely far
                        away from the camera. If we want to look closer in, the
                        desired observation distance can be given in this
                        argument. We can also fit multiple distances at the same
                        time by passing them here in a comma-separated,
                        whitespace-less list. If multiple distances are given,
                        we fit the implied-by-the-intrinsics transformation
                        using ALL the distances, but we display the best-fitting
                        difference for each point. Only one distance is
                        supported if --vectorfield. Multiple distances are
                        especially useful if we have uncertainties: the most
                        confident distance will be found, and displayed.''')
    parser.add_argument('--where',
                        type=float,
                        nargs=2,
                        help='''Center of the region of interest for this diff. It is usually impossible for
                        the models to match everywhere, but focusing on a
                        particular area can work better. The implied
                        transformation will be fit to match as large as possible
                        an area centered on this argument. If omitted, we will
                        focus on the center of the imager''')
    parser.add_argument('--radius',
                        type=float,
                        default=-1.,
                        help='''Radius of the region of interest. If ==0, we do NOT fit an implied
                        transformation at all. If omitted or <0, we use a
                        "reasonable" value: the whole imager if we're using
                        uncertainties, or min(width,height)/6 if
                        --no-uncertainties. To fit with data across the whole
                        imager in either case, pass in a very large radius''')
    parser.add_argument('--same-dance',
                        action='store_true',
                        default=False,
                        help=argparse.SUPPRESS)
    '''--same-dance IS NOT READY FOR PUBLIC CONSUMPTION. It is purposely
    undocumented. If given, I assume that the given models all came from the
    same calibration dance, and I can thus compute implied_Rt10 geometrically,
    instead of fitting projections. Valid only if we're given exactly two
    models. Exclusive with --where and --radius (those control the fit that we
    skip with --same-dance

    If putting this back, this was a part of the docstring for this tool:

    - If we know that our models came from different interpretations of the same
      board dance (using different lens models or optimization parameters, for
      instance), we can use the geometry of the cameras and frames to compute
      implied_Rt10. Indicate this case by passing --same-dance
'''



    parser.add_argument('--observations',
                        action='store_true',
                        default=False,
                        help='''If given, I show where the chessboard corners were observed at calibration
                        time. These should correspond to the low-diff regions.''')
    parser.add_argument('--valid-intrinsics-region',
                        action='store_true',
                        default=False,
                        help='''If given, I overlay the valid-intrinsics regions onto the plot''')
    parser.add_argument('--cbmax',
                        type=float,
                        default=4,
                        help='''Maximum range of the colorbar''')

    parser.add_argument('--extratitle',
                        type=str,
                        default = None,
                        help='''Extra title string for the plot''')

    parser.add_argument('--vectorfield',
                        action = 'store_true',
                        default = False,
                        help='''Plot the diff as a vector field instead of as a heat map. The vector field
                        contains more information (magnitude AND direction), but
                        is less clear at a glance''')

    parser.add_argument('--vectorscale',
                        type = float,
                        default = 1.0,
                        help='''If plotting a vectorfield, scale all the vectors by this factor. Useful to
                        improve legibility if the vectors are too small to
                        see''')

    parser.add_argument('--no-uncertainties',
                        action = 'store_true',
                        default = False,
                        help='''By default we use the uncertainties in the model to weigh the fit. This will
                        focus the fit on the confident region in the models
                        without --where or --radius. The computation will run
                        faster with --no-uncertainties, but the default --where
                        and --radius may need to be adjusted''')

    parser.add_argument('--hardcopy',
                        type=str,
                        help='''Write the output to disk, instead of making an interactive plot''')
    parser.add_argument('--terminal',
                        type=str,
                        help=r'''gnuplotlib terminal. The default is good almost always, so most people don't
                        need this option''')
    parser.add_argument('--set',
                        type=str,
                        action='append',
                        help='''Extra 'set' directives to gnuplotlib. Can be given multiple times''')
    parser.add_argument('--unset',
                        type=str,
                        action='append',
                        help='''Extra 'unset' directives to gnuplotlib. Can be given multiple times''')

    parser.add_argument('models',
                        type=str,
                        nargs='+',
                        help='''Camera models to diff''')

    args = parser.parse_args()

    if len(args.models) < 2:
        raise Exception(f"I need at least two models to diff. Instead got '{args.models}'")

    return args

args = parse_args()

# arg-parsing is done before the imports so that --help works without building
# stuff, so that I can generate the manpages and README

if args.vectorscale != 1.0 and not args.vectorfield:
    raise Exception("--vectorscale only makes sense with --vectorfield")

if args.distance is None:
    distance = None
else:
    try:
        distance = [float(d) for d in args.distance.split(',')]
    except:
        raise Exception("--distances must be given a comma-separated list of distances")

    if len(distance) > 1 and args.vectorfield:
        raise Exception("--distance can support at most one value if --vectorfield. Not clear how to plot otherwise")

if len(args.models) > 2:
    if args.vectorfield:
        raise Exception("--vectorfield works only with exactly 2 models")
    if args.same_dance:
        raise Exception("--same-dance works only with exactly 2 models")

if args.same_dance and \
   (args.where is not None or args.radius >= 0):
    raise Exception("--same-dance is exclusive with --where and --radius")


import mrcal
import numpy as np
import numpysane as nps


plotkwargs_extra = {}
if args.set is not None:
    plotkwargs_extra['set'] = args.set
if args.unset is not None:
    plotkwargs_extra['unset'] = args.unset

models = [mrcal.cameramodel(modelfilename) for modelfilename in args.models]


if args.same_dance:

    # EXPERIMENTAL, UNDOCUMENTED STUFF
    if 1:

        # default method: fit the corner observations in the coord system of the
        # camera. Each observation contributes a point to the fit


        # I need to make sure to pick the same inlier set when choosing the frame
        # observations. I pick the intersection of the two
        i_f_ci_ce = [model.optimization_inputs()['indices_frame_camintrinsics_camextrinsics'] \
                     for model in models]
        if i_f_ci_ce[0].shape != i_f_ci_ce[1].shape or \
           not np.all(i_f_ci_ce[0] == i_f_ci_ce[1]):
            raise Exception(f"--same-dance means that the two models must have an identical indices_frame_camintrinsics_camextrinsics, but they do not. Shapes {i_f_ci_ce[0].shape},{i_f_ci_ce[1].shape}")

        obs = [model.optimization_inputs()['observations_board'] \
                     for model in models]
        if obs[0].shape != obs[1].shape:
            raise Exception(f"--same-dance means that the two models must have an identically-laid-out observations_board, but they do not. Shapes {obs[0].shape},{obs[1].shape}")

        idx_inliers = [ obs[i][ ...,2] > 0 \
                        for i in range(len(models)) ]

        calobjects = \
            [ mrcal.hypothesis_corner_positions(model.icam_intrinsics(),
                                                **model.optimization_inputs(),
                                                idx_inliers = idx_inliers[0]*idx_inliers[1] )[1] \
              for model in models ]

        implied_Rt10 = mrcal.align_procrustes_points_Rt01(calobjects[1], calobjects[0])

    elif 1:

        # new method being tested. Fit the corners in the ref coordinate
        # systems. This explicitly models the extra existing rotation, so it
        # should be most correct

        optimization_inputs0 = models[0].optimization_inputs()
        optimization_inputs1 = models[1].optimization_inputs()

        calobject_height,calobject_width = optimization_inputs0['observations_board'].shape[1:3]
        calobject_spacing                = optimization_inputs0['calibration_object_spacing']

        # shape (Nh, Nw, 3)
        calibration_object0 = \
            mrcal.ref_calibration_object(calobject_width, calobject_height,
                                         calobject_spacing,
                                         calobject_warp = optimization_inputs0['calobject_warp'])
        calibration_object1 = \
            mrcal.ref_calibration_object(calobject_width, calobject_height,
                                         calobject_spacing,
                                         calobject_warp = optimization_inputs1['calobject_warp'])

        # shape (Nframes, Nh, Nw, 3)
        pcorners_ref0 = \
            mrcal.transform_point_rt( nps.mv( optimization_inputs0['frames_rt_toref'], -2, -4),
                                      calibration_object0 )
        pcorners_ref1 = \
            mrcal.transform_point_rt( nps.mv( optimization_inputs1['frames_rt_toref'], -2, -4),
                                      calibration_object1 )

        # shape (4,3)
        Rt_ref10 = mrcal.align_procrustes_points_Rt01(# shape (N,3)
                                                      nps.clump(pcorners_ref1, n=3),

                                                      # shape (N,3)
                                                      nps.clump(pcorners_ref0, n=3))

        # I have the ref-ref transform. I convert to a cam-cam transform

        icam_extrinsics0 = \
            mrcal.corresponding_icam_extrinsics(models[0].icam_intrinsics(),
                                                **optimization_inputs0)
        icam_extrinsics1 = \
            mrcal.corresponding_icam_extrinsics(models[1].icam_intrinsics(),
                                                **optimization_inputs1)

        if icam_extrinsics0 >= 0:
            Rt_cr0 = mrcal.Rt_from_rt(optimization_inputs0['extrinsics_rt_fromref'][icam_extrinsics0])
        else:
            Rt_cr0 = mrcal.identity_Rt()
        if icam_extrinsics1 >= 0:
            Rt_cr1 = mrcal.Rt_from_rt(optimization_inputs1['extrinsics_rt_fromref'][icam_extrinsics1])
        else:
            Rt_cr1 = mrcal.identity_Rt()

        implied_Rt10 = \
            mrcal.compose_Rt(Rt_cr1,
                             Rt_ref10,
                             mrcal.invert_Rt(Rt_cr0))

    else:

        # default method used in the uncertainty computation. compute the mean
        # of the frame points

        optimization_inputs0 = models[0].optimization_inputs()
        icam_intrinsics0     = models[0].icam_intrinsics()
        icam_extrinsics0     = \
            mrcal.corresponding_icam_extrinsics(icam_intrinsics0, **optimization_inputs0)
        if icam_extrinsics0 >= 0:
            Rt_rc0 = mrcal.invert_Rt(mrcal.Rt_from_rt(optimization_inputs0['extrinsics_rt_fromref'][icam_extrinsics0]))
        else:
            Rt_rc0 = mrcal.identity_Rt()
        Rt_fr0 = mrcal.invert_Rt(mrcal.Rt_from_rt(optimization_inputs0['frames_rt_toref']))

        optimization_inputs1 = models[1].optimization_inputs()
        icam_intrinsics1     = models[1].icam_intrinsics()
        icam_extrinsics1     = \
        mrcal.corresponding_icam_extrinsics(icam_intrinsics1, **optimization_inputs1)
        if icam_extrinsics1 >= 0:
            Rt_cr1 = mrcal.Rt_from_rt(optimization_inputs1['extrinsics_rt_fromref'][icam_extrinsics1])
        else:
            Rt_cr1 = mrcal.identity_Rt()
        Rt_rf1 = mrcal.Rt_from_rt(optimization_inputs1['frames_rt_toref'])

        # not a geometric transformation: the R is not in SO3
        Rt_r1r0 = np.mean( mrcal.compose_Rt(Rt_rf1, Rt_fr0), axis=-3)

        Rt_c1c0 = mrcal.compose_Rt( Rt_cr1, Rt_r1r0, Rt_rc0)


        q0 = models[0].imagersize()*2./5.
        v0_cam = mrcal.unproject(q0, optimization_inputs0['lensmodel'], optimization_inputs0['intrinsics'][icam_intrinsics0],
                                 normalize = True)
        p0_cam = v0_cam * (1e5 if distance is None else distance)

        # print(f"v0_cam = {v0_cam}")
        # print(f"reprojected = {mrcal.project(v0_cam, optimization_inputs0['lensmodel'], optimization_inputs0['intrinsics'][icam_intrinsics0])}")
        # print(f"reprojected other = {mrcal.project(np.array([-0.2471004,-0.21598248,0.9446126 ]), optimization_inputs0['lensmodel'], optimization_inputs0['intrinsics'][icam_intrinsics0])}")
        # print(f"reprojected other = {mrcal.project(np.array([-0.2471004,-0.21598248,0.9446126 ]), *models[0].intrinsics())}")
        # print(f"p0_cam = {p0_cam}")

        p0_ref = mrcal.transform_point_Rt(Rt_rc0, p0_cam)
        p0_frame  = mrcal.transform_point_Rt(Rt_fr0, p0_ref)
        p1_refall = mrcal.transform_point_Rt(Rt_rf1, p0_frame)
        p1_ref    = np.mean(p1_refall, axis=0)

        # print(f"p0_ref = {p0_ref}")
        # print(f"rt_rf0[0] = {optimization_inputs0['frames_rt_toref'][0]}")
        # print(f"Rt_fr0[0] = {Rt_fr0[0]}")
        # print(f"p0_frame = {p0_frame}")
        # print(f"p1_refall = {p1_refall}")
        # print(f"p1_ref = {p1_ref}")

        p1_cam = mrcal.transform_point_Rt(Rt_cr1, p1_ref)
        q1 = mrcal.project(p1_cam, *models[1].intrinsics())

        # print(f"p1_cam = {p1_cam}")
        # print(f"q1 = {q1}")
        # print(f"before:\n{implied_Rt10}")

        implied_Rt10 = Rt_r1r0

        # print(f"after:\n{implied_Rt10}")



        # print(f"--same-dance Rt10: {implied_Rt10}")
        # print(f"--same-dance Ninliers = {np.count_nonzero(idx_inliers[0]*idx_inliers[1])} Ntotal = {np.size(idx_inliers[0])}")

        # print(f"idx_inliers[0].shape: {idx_inliers[0].shape}")
        # import gnuplotlib as gp
        # gp.plot(nps.mag(calobjects[0] - calobjects[1]), wait=1)
        # # gp.plot( (calobjects[0] - calobjects[1],), tuplesize=-3, _with='points', square=1, _3d=1, xlabel='x', ylabel = 'y', zlabel = 'z')
        # # import IPython
        # # IPython.embed()
        # # sys.exit()

else:
    implied_Rt10 = None


plot,implied_Rt10 = mrcal.show_projection_diff(models,
                                               args.gridn[0], args.gridn[1],
                                               observations            = args.observations,
                                               valid_intrinsics_region = args.valid_intrinsics_region,
                                               distance                = distance,
                                               use_uncertainties       = not args.no_uncertainties,
                                               focus_center            = args.where,
                                               focus_radius            = args.radius,
                                               implied_Rt10            = implied_Rt10,
                                               vectorfield             = args.vectorfield,
                                               vectorscale             = args.vectorscale,
                                               hardcopy                = args.hardcopy,
                                               terminal                = args.terminal,
                                               cbmax                   = args.cbmax,
                                               extratitle              = args.extratitle,
                                               **plotkwargs_extra)

if implied_Rt10 is not None and implied_Rt10.shape == (4,3):
    rt10 = mrcal.rt_from_Rt(implied_Rt10)

    print(f"implied rotation cam1 <-- cam0:  rotation: {nps.mag(rt10[:3])*180./np.pi:.03f} degrees, translation: {rt10[3:]} m")

if args.hardcopy is None:
    plot.wait()
