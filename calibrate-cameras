#!/usr/bin/python2

r'''Calibrate some synchronized cameras

Synopsis:

  $ calibrate-cameras
      --dots-cache corners.vnl
      --focal 1700 --object-spacing 0.01 --object-width-n 10
      --out /tmp
      --distortion-model DISTORTION_OPENCV8
      --observed-pixel-uncertainty 0.5
      'left*.png' 'right*.png'

    ... lots of output as the solve runs ...
    Done!
    RMS reprojection error: 1.9 pixels
    Worst reprojection error: 7.8 pixels
    Noutliers: 319 out of 17100 total points: 1.9% of the data
    Expected projection uncertainty due to input pixel observations.
      This is an (Ncameras,5) matrix. For each camera we look at the
      (top-left, bottom-left, top-right, bottom-right, center) imager locations in order.
      The corners are 10% inside the image. The reported numbers are 'expected projection
      error', measured in pixels.
    [[8.9 8.7 7.5 8.3 0.8]]

    Wrote /tmp/camera0-0.cahvor
    Wrote /tmp/camera0-1.cahvor
    Wrote /tmp/camera0-0.cameramodel
    Wrote /tmp/camera0-1.cameramodel

This tool uses the generic mrcal platform to solve a common specific problem of
N-camera calibration using observations of a chessboard.

'''

import sys
import numpy as np
import numpysane as nps
import cv2
import re
import argparse
import os
import fnmatch
import subprocess
import pipes
import heapq
from tempfile import mkstemp
import shutil
import glob
import copy

import mrcal




def parse_args():

    def positive_float(string):
        try:
            value = float(string)
        except:
            raise argparse.ArgumentTypeError("argument MUST be a positive floating-point number. Got '{}'".format(string))
        if value <= 0:
            raise argparse.ArgumentTypeError("argument MUST be a positive floating-point number. Got '{}'".format(string))
        return value
    def positive_int(string):
        try:
            value = int(string)
        except:
            raise argparse.ArgumentTypeError("argument MUST be a positive integer. Got '{}'".format(string))
        if value <= 0 or abs(value-float(string)) > 1e-6:
            raise argparse.ArgumentTypeError("argument MUST be a positive integer. Got '{}'".format(string))
        return value


    parser = \
        argparse.ArgumentParser(description = __doc__,
                                formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--focal',
                        type=float,
                        default=1970,
                        required=True,
                        help='Initial estimate of the focal length, in pixels')
    parser.add_argument('--imagersize',
                        nargs=2,
                        type=int,
                        required=False,
                        help='''Size of the imager. This is only required if we pass --dots-cache AND if none
                        of the image files on disk actually exist''')
    parser.add_argument('--outdir',
                        type=lambda d: d if os.path.isdir(d) else \
                                parser.error("--outdir requires an existing directory as the arg, but got '{}'".format(d)),
                        default='.',
                        help='Directory for the output camera models')
    parser.add_argument('--object-spacing',
                        required=True,
                        type=float,
                        help='Width of each square in the calibration board, in meters')
    parser.add_argument('--object-width-n',
                        type=int,
                        required=True,
                        help='How many points the calibration board has per side')
    parser.add_argument('--distortion-model',
                        required=False,
                        default='DISTORTION_OPENCV4',
                        help='''Which distortion model we're using. By default I use DISTORTION_OPENCV4''')
    parser.add_argument('--roi',
                        nargs=4,
                        type=float,
                        action='append',
                        required=False,
                        help='''Region of interest of the calibration. This is the area in the imager we're
                        interested in. Errors in observations outside this area
                        will be attenuated significantly. If we want to use all
                        the data evenly, omit this argument. Otherwise pass 4
                        values for each --roi:
                        (x_center,y_center,x_radius,y_radius). The region is an
                        axis-aligned ellipsoid. If passing in ANY roi, you MUST
                        pass in the ROI for EACH camera; a separate '--roi' for
                        each one.''')
    parser.add_argument('--incremental',
                        required=False,
                        default=False,
                        action='store_true',
                        help='''If passed, we incrementally increase ROI and distortion model complexity
                        across multiple solves. In this mode the requested ROI
                        is a target, and the requested distortion model is the
                        upper bound. If we can get away with a simpler one, we
                        use that.''')
    parser.add_argument('--num-cross-validation-splits',
                        required=False,
                        default=1,
                        type=positive_int,
                        help='''If passed, we cross-validate the results with this many splits. This only
                        makes sense as an integer >1. THIS IS EXPERIMENTAL.''')
    parser.add_argument('--jobs', '-j',
                        type=int,
                        default=1,
                        help='''How much parallelization we want. Like GNU make. Affects only the chessboard
                        corner finder. If we are reading a cache file, this does nothing''')
    parser.add_argument('--dots-cache',
                        type=lambda f: f if os.path.isfile(f) or not os.path.isdir(f) else \
                                parser.error("--dots-cache requires an existing, readable file as the arg or a non-existing path, but got '{}'".format(f)),
                        required=False,
                        help='Path to read corner-finder data from or (if path does not exist) to write data to')

    parser.add_argument('--muse-extrinsics',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''Apply MUSE's non-identity rotation for camera0''')

    parser.add_argument('--skip-regularization',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we apply regularization to the solver. This option turns that
                        off''')

    parser.add_argument('--skip-outlier-rejection',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we throw out outliers. This option turns that off''')

    parser.add_argument('--verbose-solver',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default the final stage of the solver doesn't say much. This option turns
                        on verbosity to get lots of diagnostics.''')

    parser.add_argument('--explore',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''After the solve open an interactive shell to examine the solution''')
    parser.add_argument('--observed-pixel-uncertainty',
                        type=positive_float,
                        required=True,
                        help='''The standard deviation of x and y pixel coordinates of the input
                        observations. The distribution of the inputs is assumed
                        to be gaussian, with the standard deviation specified by
                        this argument. Note: this is the x and y standard
                        deviation, treated independently. If each of these is s,
                        then the LENGTH of the deviation of each pixel is a
                        Rayleigh distribution with expected value s*sqrt(pi/2) ~
                        s*1.25''')

    parser.add_argument('images',
                        type=str,
                        nargs='+',
                        help='''A glob-per-camera for the images. Include a glob for each camera. It is
                        assumed that the image filenames in each glob are of of
                        the form xxxNNNyyy where xxx and yyy are common to all
                        images in the set, and NNN varies. This NNN is a frame
                        number, and identical frame numbers across different
                        globs signify a time-synchronized observation. I.e. you
                        can pass 'left*.jpg' and 'right*.jpg' to find images
                        'left0.jpg', 'left1.jpg', ..., 'right0.jpg',
                        'right1.jpg', ...''')

    parser.add_argument('--cull-points-left-of',
                        required=False,
                        default=-1,
                        type=float,
                        help='''For testing. Throw out all observations with x < the given value''')
    parser.add_argument('--cull-points-rad-off-center',
                        required=False,
                        default=-1,
                        type=float,
                        help='''For testing. Throw out all observations with dist_from_center > the given
                        value''')
    parser.add_argument('--cull-random-observations-ratio',
                        required=False,
                        default=-1,
                        type=float,
                        help='''For testing. Throw out a random number of board observations. The ratio of
                        observations is given as the argument. 1.0 = throw out
                        ALL the observations; 0.0 = throw out NONE of the
                        observations''')



    return parser.parse_args()

def get_observations(Nw, Nh, globs, dots_vnl=None, jobs=1, exclude=set()):
    r'''Computes the point observations and returns them in a usable form

    We are given globs of images (one glob per camera), where the filenames
    encode the instantaneous frame numbers. This function invokes the chessboard
    finder to compute the point coordinates, and returns a tuple

      observations, indices_frame_camera, files_sorted

    where observations is an (N,object-width-n,object-width-n,2) array
    describing N board observations where the board has dimensions
    (object-width-n,object-width-n) and each point is an (x,y) pixel observation

    indices_frame_camera is an (N,2) array of integers where each observation is
    (index_frame,index_camera)

    files_sorted is a list of paths of images corresponding to the observations

    '''

    def get_dot_observations(Nw, Nh, globs, dots_vnl, exclude=set()):
        r'''Return dot observations, from a cache or from mrgingham

        Returns a dict mapping from filename to a numpy array with a full grid
        of dot observations. If no grid was observed in a particular image, the
        relevant dict entry is empty

        The dots_vnl argument is for caching corner-finder results. This can be
        None if we want to ignore this. Otherwise, this is treated as a path to
        a file on disk. If this file exists:

            The corner coordinates are read from this file instead of being
            computed. We don't need to actually have the images stored on disk.
            Any image filenames mentioned in this cache file are matched against
            the globs to decide which camera the image belongs to. If it matches
            none of the globs, that image filename is silently ignored

        If this file does not exist:

            We process the images to compute the corner coordinates. Before we
            compute the calibration off these coordinates, we create the cache
            file and store this data there. Thus a subsequent identical
            invocation of calibrate-cameras will see this file as existing, and
            will automatically use the data it contains instead of recomputing
            the corner coordinates
        '''

        Ncameras = len(globs)
        files_per_camera = []
        for i in xrange(Ncameras):
            files_per_camera.append([])

        # images in dots_vnl have paths relative to where the dots_vnl lives
        globs = [os.path.abspath(g) for g in globs]
        dots_dir = None if dots_vnl is None else os.path.dirname( dots_vnl )

        def accum_files(f):
            for i_camera in xrange(Ncameras):
                if fnmatch.fnmatch(f, globs[i_camera]):
                    files_per_camera[i_camera].append(f)
                    return True
            return False


        pipe_dots_write_fd          = None
        pipe_dots_write_tmpfilename = None
        if dots_vnl is not None and os.path.isdir(dots_vnl):
            raise Exception("Given cache path '{}' is a directory. Must be a file or must not exist". \
                            format(dots_vnl))
        if dots_vnl is None or not os.path.isfile(dots_vnl):
            # Need to compute the dot coords. And maybe need to save them into a
            # cache file too
            if Nw != 10 or Nh != 10:
                raise Exception("mrgingham currently accepts ONLY 10x10 grids")

            args_mrgingham = ['mrgingham', '--chessboard', '--blur', '3', '--clahe', '--jobs',
                              str(jobs)]
            args_mrgingham.extend(globs)

            sys.stderr.write("Computing chessboard corners by running:\n   {}\n". \
                             format(' '.join(pipes.quote(s) for s in args_mrgingham)))
            if dots_vnl is not None:
                # need to save the dots into a cache. I want to do this
                # atomically: if the dot-finding is interrupted I don't want to
                # be writing incomplete results, so I write to a temporary file
                # and then rename when done
                pipe_dots_write_fd,pipe_dots_write_tmpfilename = mkstemp('.vnl')
                sys.stderr.write("Will save corners to '{}'\n".format(dots_vnl))

            dots_output = subprocess.Popen(args_mrgingham, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            pipe_dots_read = dots_output.stdout
            computing_dots = True
        else:
            # Have an existing cache file. Just read it
            pipe_dots_read = open(dots_vnl, 'r')
            computing_dots = False


        mapping = {}
        context = {'f':    '',
                   'grid': np.array(())}

        def finish():
            if context['grid'].size:
                if Nw*Nh != context['grid'].size/2:
                    raise Exception("File '{}' expected to have {}*{}={} elements, but got {}". \
                                    format(context['f'], Nw,Nh,Nw*Nh, context['grid'].size/2))
                if context['f'] not in exclude:
                    if dots_dir is not None:
                        filename_absolute = os.path.abspath(os.path.join(dots_dir, context['f']))
                    else:
                        filename_absolute = os.path.normpath(context['f'])
                    if accum_files(filename_absolute):
                        mapping[filename_absolute] = context['grid']
                context['f']    = ''
                context['grid'] = np.array(())

        for line in pipe_dots_read:
            if pipe_dots_write_fd is not None:
                os.write(pipe_dots_write_fd, line)

            if line[0] == '#':
                continue
            m = re.match('(\S+)\s+(.*?)$', line)
            if m is None:
                raise Exception("Unexpected line in the dots output: '{}'".format(line))
            if m.group(2)[:2] == '- ':
                finish()
                continue
            if context['f'] != m.group(1):
                finish()
                context['f'] = m.group(1)

            context['grid'] = nps.glue(context['grid'],
                                       np.fromstring(m.group(2), sep=' ', dtype=np.float),
                                       axis=-2)
        finish()

        if computing_dots:
            sys.stderr.write("Done computing chessboard corners\n")

            if dots_output.wait() != 0:
                err = dots_output.stderr.read()
                raise Exception("mrgingham failed: {}".format(err))
            if pipe_dots_write_fd is not None:
                os.close(pipe_dots_write_fd)
                shutil.move(pipe_dots_write_tmpfilename, dots_vnl)
        else:
            pipe_dots_read.close()

        # I can't deal with cameras that have only one frame: the filenames
        # aren't enough to establish a pattern, so I ignore those. Which is
        # fine, since a single observation in a camera isn't enough to be useful
        for i_camera in xrange(len(files_per_camera)):
            N = len(files_per_camera[i_camera])
            if N < 2:
                raise Exception("Found too few ({}; need at least 2) images containing a calibration pattern in camera {}; glob '{}'". \
                                format(N, i_camera, globs[i_camera]))

        return mapping,files_per_camera


    indices_frame_camera = np.array((), dtype=np.int32)
    observations         = np.array((), dtype=float)

    # basic logic is this:
    #   for frames:
    #       for cameras:
    #           if have observation:
    #               push observations
    #               push indices_frame_camera

    # inputs[camera][image] = (image_filename, frame_number)
    mapping_file_dots,files_per_camera = get_dot_observations(Nw, Nh, globs, dots_vnl, exclude)
    mapping_file_framecamera,_,_       = mrcal.get_mapping_file_framecamera(files_per_camera)

    # I create a file list sorted by frame and then camera. So my for(frames)
    # {for(cameras) {}} loop will just end up looking at these files in order
    files_sorted = sorted(mapping_file_dots.keys(), key=lambda f: mapping_file_framecamera[f][1])
    files_sorted = sorted(files_sorted,             key=lambda f: mapping_file_framecamera[f][0])

    i_observation = 0

    i_frame_last = None
    index_frame  = -1
    for f in files_sorted:
        # The frame indices I return are consecutive starting from 0, NOT the
        # original frame numbers
        i_frame,i_camera = mapping_file_framecamera[f]
        if i_frame_last == None or i_frame_last != i_frame:
            index_frame += 1
            i_frame_last = i_frame

        indices_frame_camera = nps.glue(indices_frame_camera,
                                        np.array((index_frame, i_camera), dtype=np.int32),
                                        axis=-2)
        observations = nps.glue(observations,
                                mapping_file_dots[f].reshape(Nh,Nw,2),
                                axis=-4)

    return observations, indices_frame_camera, files_sorted


def estimate_local_calobject_poses( indices_frame_camera, \
                                    dots, dot_spacing, focal, imagersizes,
                                    Nwant):
    r"""Estimates pose of observed object in a single-camera view

    Given observations, and an estimate of camera intrinsics (focal lengths,
    imager size) computes an estimate of the pose of the calibration object in
    respect to the camera for each frame. This assumes that all frames are
    independent and all cameras are independent. This assumes a pinhole camera.

    This function is a wrapper around the solvePnP() openCV call, which does all
    the work.

    The observations are given in a numpy array with axes:

      (iframe, idot_x, idot_y, idot2d_xy)

    So as an example, the observed pixel coord of the dot (3,4) in frame index 5
    is the 2-vector dots[5,3,4,:]

    Missing observations are given as negative pixel coords.

    This function returns an (Nobservations,4,3) array, with the observations
    aligned with the dots and indices_frame_camera arrays. Each observation
    slice is (4,3) in glue(R, t, axis=-2)

    """

    Nobservations = indices_frame_camera.shape[0]

    # this wastes memory, but makes it easier to keep track of which data goes
    # with what
    Rt_all = np.zeros( (Nobservations, 4, 3), dtype=float)

    full_object = mrcal.get_ref_calibration_object(Nwant, Nwant, dot_spacing)

    for i_observation in xrange(Nobservations):

        i_camera   = indices_frame_camera[i_observation,1]
        imagersize = imagersizes[i_camera]
        camera_matrix = np.array((( focal, 0,        (imagersize[0] - 1)/2), \
                                  (        0, focal, (imagersize[1] - 1)/2), \
                                  (        0,        0,                 1)))
        d = dots[i_observation, ...]

        d = nps.clump( nps.glue(d, full_object, axis=-1), n=2)
        # d is (Nwant*Nwant,5); each row is an xy pixel observation followed by the xyz
        # coord of the point in the calibration object. I pick off those rows
        # where the observations are both >= 0. Result should be (N,5) where N
        # <= Nwant*Nwant
        i = (d[..., 0] >= 0) * (d[..., 1] >= 0)
        d = d[i,:]

        # copying because cv2.solvePnP() requires contiguous memory apparently
        observations = np.array(d[:,:2][..., np.newaxis])
        ref_object   = np.array(d[:,2:][..., np.newaxis])
        result,rvec,tvec = cv2.solvePnP(np.array(ref_object),
                                        np.array(observations),
                                        camera_matrix, None)
        if not result:
            raise Exception("solvePnP failed!")
        if tvec[2] <= 0:

            # The object ended up behind the camera. I flip it, and try to solve
            # again
            result,rvec,tvec = cv2.solvePnP(np.array(ref_object),
                                            np.array(observations),
                                            camera_matrix, None,
                                            rvec, -tvec,
                                            useExtrinsicGuess = True)
            if not result:
                raise Exception("retried solvePnP failed!")
            if tvec[2] <= 0:
                raise Exception("retried solvePnP says that tvec.z <= 0")


        Rt = mrcal.Rt_from_rt(nps.glue(rvec.ravel(), tvec.ravel(), axis=-1))

        # visualize the fit
        # x_cam    = nps.matmult(Rt[:3,:],ref_object)[..., 0] + Rt[3,:]
        # x_imager = x_cam[...,:2]/x_cam[...,(2,)] * focal + (imagersize-1)/2
        # import gnuplotlib as gp
        # gp.plot( (x_imager[:,0],x_imager[:,1], dict(legend='solved')),
        #          (observations[:,0,0],observations[:,1,0], dict(legend='observed')),
        #          square=1,xrange=(0,4000),yrange=(4000,0),
        #          wait=1)
        # import IPython
        # IPython.embed()
        # sys.exit()

        Rt_all[i_observation, :, :] = Rt


    return Rt_all

def estimate_camera_poses( calobject_poses_local_Rt, indices_frame_camera, \
                           dots, dot_spacing, Ncameras,
                           Nwant):
    r'''Estimate camera poses in respect to each other

    We are given poses of the calibration object in respect to each observing
    camera. We also have multiple cameras observing the same calibration object
    at the same time, and we have local poses for each. We can thus compute the
    relative camera pose from these observations.

    We have many frames that have different observations from the same set of
    fixed-relative-pose cameras, so we compute the relative camera pose to
    optimize the observations

    '''
    # I need to compute an estimate of the pose of each camera in the coordinate
    # system of camera0. This is only possible if there're enough overlapping
    # observations. For instance if camera1 has overlapping observations with
    # camera2, but neight overlap with camera0, then I can't relate camera1,2 to
    # camera0. However if camera2 has overlap with camera2, then I can compute
    # the relative pose of camera2 from its overlapping observations with
    # camera0. And I can compute the camera1-camera2 pose from its overlapping
    # data, and then transform to the camera0 coord system using the
    # previously-computed camera2-camera0 pose
    #
    # I do this by solving a shortest-path problem using Dijkstra's algorithm to
    # find a set of pair overlaps between cameras that leads to camera0. I favor
    # edges with large numbers of shared observed frames

    # list of camera-i to camera-0 transforms. I keep doing stuff until this
    # list is full of valid data
    Rt_0c = [None] * (Ncameras-1)

    def compute_pairwise_Rt(icam_to, icam_from):

        # I want to assume that icam_from > icam_to. If it's not true, compute the
        # opposite transform, and invert
        if icam_to > icam_from:
            Rt = compute_pairwise_Rt(icam_from, icam_to)
            return mrcal.invert_Rt(Rt)

        if icam_to == icam_from:
            raise Exception("Got icam_to == icam_from ( = {} ). This was probably a mistake".format(icam_to))

        # Now I KNOW that icam_from > icam_to


        Nobservations = indices_frame_camera.shape[0]

        # This is a hack. I look at the correspondence of camera0 to camera i for i
        # in 1:N-1. I ignore all correspondences between cameras i,j if i!=0 and
        # j!=0. Good enough for now
        full_object = mrcal.get_ref_calibration_object(Nwant, Nwant, dot_spacing)

        A = np.array(())
        B = np.array(())

        # I traverse my observation list, and pick out observations from frames
        # that had data from both my cameras
        i_frame_last = -1
        d0  = None
        d1  = None
        Rt0 = None
        Rt1 = None
        for i_observation in xrange(Nobservations):
            i_frame_this,i_camera_this = indices_frame_camera[i_observation, ...]
            if i_frame_this != i_frame_last:
                d0  = None
                d1  = None
                Rt0 = None
                Rt1 = None
                i_frame_last = i_frame_this

            # The cameras appear in order. And above I made sure that icam_from >
            # icam_to, so I take advantage of that here
            if i_camera_this == icam_to:
                if Rt0 is not None:
                    raise Exception("Saw multiple camera{} observations in frame {}".format(i_camera_this,
                                                                                            i_frame_this))
                Rt0 = calobject_poses_local_Rt[i_observation, ...]
                d0  = dots[i_observation, ...]
            elif i_camera_this == icam_from:
                if Rt0 is None: # have camera1 observation, but not camera0
                    continue

                if Rt1 is not None:
                    raise Exception("Saw multiple camera{} observations in frame {}".format(i_camera_this,
                                                                                            i_frame_this))
                Rt1 = calobject_poses_local_Rt[i_observation, ...]
                d1  = dots[i_observation, ...]



                # d looks at one frame and has shape (Nwant,Nwant,7). Each row is
                #   xy pixel observation in left camera
                #   xy pixel observation in right camera
                #   xyz coord of dot in the calibration object coord system
                d = nps.glue( d0, d1, full_object, axis=-1 )

                # squash dims so that d is (Nwant*Nwant,7)
                d = nps.clump(d, n=2)

                ref_object = nps.clump(full_object, n=2)

                # # It's possible that I could have incomplete views of the
                # # calibration object, so I pull out only those point
                # # observations that have a complete view. In reality, I
                # # currently don't accept any incomplete views, and much outside
                # # code would need an update to support that. This doesn't hurt, however

                # # d looks at one frame and has shape (10,10,7). Each row is
                # #   xy pixel observation in left camera
                # #   xy pixel observation in right camera
                # #   xyz coord of dot in the calibration object coord system
                # d = nps.glue( d0, d1, full_object, axis=-1 )

                # # squash dims so that d is (100,7)
                # d = nps.transpose(nps.clump(nps.mv(d, -1, -3), n=2))

                # # I pick out those points that have observations in both frames
                # i = (d[..., 0] >= 0) * (d[..., 1] >= 0) * (d[..., 2] >= 0) * (d[..., 3] >= 0)
                # d = d[i,:]

                # # ref_object is (N,3)
                # ref_object = d[:,4:]

                A = nps.glue(A, nps.matmult( ref_object, nps.transpose(Rt0[:3,:])) + Rt0[3,:],
                             axis = -2)
                B = nps.glue(B, nps.matmult( ref_object, nps.transpose(Rt1[:3,:])) + Rt1[3,:],
                             axis = -2)

        return mrcal.align3d_procrustes(A, B)


    def compute_connectivity_matrix():
        r'''Returns a connectivity matrix of camera observations

        Returns a symmetric (Ncamera,Ncamera) matrix of integers, where each
        entry contains the number of frames containing overlapping observations
        for that pair of cameras

        '''

        camera_connectivity = np.zeros( (Ncameras,Ncameras), dtype=int )
        def finish_frame(i0, i1):
            for ic0 in xrange(i0, i1):
                for ic1 in xrange(ic0+1, i1+1):
                    camera_connectivity[indices_frame_camera[ic0,1], indices_frame_camera[ic1,1]] += 1
                    camera_connectivity[indices_frame_camera[ic1,1], indices_frame_camera[ic0,1]] += 1

        f_current       = -1
        i_start_current = -1

        for i in xrange(len(indices_frame_camera)):
            f,c = indices_frame_camera[i]
            if f < f_current:
                raise Exception("I'm assuming the frame indices are increasing monotonically")
            if f > f_current:
                # first camera in this observation
                f_current = f
                if i_start_current >= 0:
                    finish_frame(i_start_current, i-1)
                i_start_current = i
        finish_frame(i_start_current, len(indices_frame_camera)-1)
        return camera_connectivity


    shared_frames = compute_connectivity_matrix()

    class Node:
        def __init__(self, camera_idx):
            self.camera_idx    = camera_idx
            self.from_idx      = -1
            self.cost_to_node  = None

        def __lt__(self, other):
            return self.cost_to_node < other.cost_to_node

        def visit(self):
            '''Dijkstra's algorithm'''
            self.finish()

            for neighbor_idx in xrange(Ncameras):
                if neighbor_idx == self.camera_idx                  or \
                   shared_frames[neighbor_idx,self.camera_idx] == 0:
                    continue
                neighbor = nodes[neighbor_idx]

                if neighbor.visited():
                    continue

                cost_edge = Node.compute_edge_cost(shared_frames[neighbor_idx,self.camera_idx])

                cost_to_neighbor_via_node = self.cost_to_node + cost_edge
                if not neighbor.seen():
                    neighbor.cost_to_node = cost_to_neighbor_via_node
                    neighbor.from_idx     = self.camera_idx
                    heapq.heappush(heap, neighbor)
                else:
                    if cost_to_neighbor_via_node < neighbor.cost_to_node:
                        neighbor.cost_to_node = cost_to_neighbor_via_node
                        neighbor.from_idx     = self.camera_idx
                        heapq.heapify(heap) # is this the most efficient "update" call?

        def finish(self):
            '''A shortest path was found'''
            if self.camera_idx == 0:
                # This is the reference camera. Nothing to do
                return

            Rt_fc = compute_pairwise_Rt(self.from_idx, self.camera_idx)

            if self.from_idx == 0:
                Rt_0c[self.camera_idx-1] = Rt_fc
                return

            Rt_0f = Rt_0c[self.from_idx-1]
            Rt_0c[self.camera_idx-1] = mrcal.compose_Rt( Rt_0f, Rt_fc)

        def visited(self):
            '''Returns True if this node went through the heap and has then been visited'''
            return self.camera_idx == 0 or Rt_0c[self.camera_idx-1] is not None

        def seen(self):
            '''Returns True if this node has been in the heap'''
            return self.cost_to_node is not None

        @staticmethod
        def compute_edge_cost(shared_frames):
            # I want to MINIMIZE cost, so I MAXIMIZE the shared frames count and
            # MINIMIZE the hop count. Furthermore, I really want to minimize the
            # number of hops, so that's worth many shared frames.
            cost = 100000 - shared_frames
            assert(cost > 0) # dijkstra's algorithm requires this to be true
            return cost



    nodes = [Node(i) for i in xrange(Ncameras)]
    nodes[0].cost_to_node = 0
    heap = []

    nodes[0].visit()
    while heap:
        node_top = heapq.heappop(heap)
        node_top.visit()

    if any([x is None for x in Rt_0c]):
        raise Exception("ERROR: Don't have complete camera observations overlap!\n" +
                        ("Past-camera-0 Rt:\n{}\n".format(Rt_0c))                   +
                        ("Shared observations matrix:\n{}\n".format(shared_frames)))


    return nps.cat(*Rt_0c)



def estimate_frame_poses(calobject_poses_local_Rt, camera_poses_Rt, indices_frame_camera, dot_spacing,
                         Nwant):
    r'''Estimate poses of the calibration object observations

    We're given

    calobject_poses_local_Rt:

      an array of dimensions (Nobservations,4,3) that contains a
      calobject-to-camera transformation estimate, for each observation of the
      board

    camera_poses_Rt:

      an array of dimensions (Ncameras-1,4,3) that contains a camerai-to-camera0
      transformation estimate. camera0-to-camera0 is the identity, so this isn't
      stored

    indices_frame_camera:

      an array of shape (Nobservations,2) that indicates which frame and which
      camera has observed the board

    With this data, I return an array of shape (Nframes,6) that contains an
    estimate of the pose of each frame, in the camera0 coord system. Each row is
    (r,t) where r is a Rodrigues rotation and t is a translation that map points
    in the calobject coord system to that of camera 0

    '''


    def process(i_observation0, i_observation1):
        R'''Given a range of observations corresponding to the same frame, estimate the
        frame pose'''

        def T_camera_board(i_observation):
            r'''Transform from the board coords to the camera coords'''
            i_frame,i_camera = indices_frame_camera[i_observation, ...]

            Rt_f = calobject_poses_local_Rt[i_observation, :,:]
            if i_camera == 0:
                return Rt_f

            # T_cami_cam0 T_cam0_board = T_cami_board
            Rt_cam = camera_poses_Rt[i_camera-1, ...]

            return mrcal.compose_Rt( Rt_cam, Rt_f)


        # frame poses should map FROM the frame coord system TO the ref coord
        # system (camera 0).

        # special case: if there's a single observation, I just use it
        if i_observation1 - i_observation0 == 1:
            return T_camera_board(i_observation0)

        # Multiple cameras have observed the object for this frame. I have an
        # estimate of these for each camera. I merge them in a lame way: I
        # average out the positions of each point, and fit the calibration
        # object into the mean point cloud
        obj = mrcal.get_ref_calibration_object(Nwant, Nwant, dot_spacing)

        sum_obj_unproj = obj*0
        for i_observation in xrange(i_observation0, i_observation1):
            Rt = T_camera_board(i_observation)
            sum_obj_unproj += mrcal.transform_point_Rt(obj, Rt)

        mean = sum_obj_unproj / (i_observation1 - i_observation0)

        # Got my point cloud. fit

        # transform both to shape = (N*N, 3)
        obj  = nps.clump(obj,  n=2)
        mean = nps.clump(mean, n=2)
        return mrcal.align3d_procrustes( mean, obj )





    frame_poses_rt = np.array(())

    i_frame_current          = -1
    i_observation_framestart = -1;

    for i_observation in xrange(indices_frame_camera.shape[0]):
        i_frame,i_camera = indices_frame_camera[i_observation, ...]

        if i_frame != i_frame_current:
            if i_observation_framestart >= 0:
                Rt = process(i_observation_framestart, i_observation)
                frame_poses_rt = nps.glue(frame_poses_rt, mrcal.rt_from_Rt(Rt), axis=-2)

            i_observation_framestart = i_observation
            i_frame_current = i_frame

    if i_observation_framestart >= 0:
        Rt = process(i_observation_framestart, indices_frame_camera.shape[0])
        frame_poses_rt = nps.glue(frame_poses_rt, mrcal.rt_from_Rt(Rt), axis=-2)

    return frame_poses_rt

def make_seed_no_distortion( imagersizes,
                             focal_estimate,
                             Ncameras,
                             indices_frame_camera,
                             dots,
                             dot_spacing,
                             object_width_n):
    r'''Generate a solution seed for a given input'''


    def make_intrinsics_vector(i_camera):
        imager_w,imager_h = imagersizes[i_camera]
        return np.array( (focal_estimate, focal_estimate,
                          float(imager_w-1)/2.,
                          float(imager_h-1)/2.))

    intrinsics_data = nps.cat( *[make_intrinsics_vector(i_camera) \
                                 for i_camera in xrange(Ncameras)] )

    # I compute an estimate of the poses of the calibration object in the local
    # coord system of each camera for each frame. This is done for each frame
    # and for each camera separately. This isn't meant to be precise, and is
    # only used for seeding.
    #
    # I get rotation, translation in a (4,3) array, such that R*calobject + t
    # produces the calibration object points in the coord system of the camera.
    # The result has dimensions (N,4,3)
    calobject_poses_local_Rt = \
        estimate_local_calobject_poses( indices_frame_camera,
                                        dots,
                                        dot_spacing,
                                        focal_estimate,
                                        imagersizes,
                                        object_width_n)
    # these map FROM the coord system of the calibration object TO the coord
    # system of this camera

    # I now have a rough estimate of calobject poses in the coord system of each
    # frame. One can think of these as two sets of point clouds, each attached to
    # their camera. I can move around the two sets of point clouds to try to match
    # them up, and this will give me an estimate of the relative pose of the two
    # cameras in respect to each other. I need to set up the correspondences, and
    # align3d_procrustes() does the rest
    #
    # I get transformations that map points in 1-Nth camera coord system to 0th
    # camera coord system. Rt have dimensions (N-1,4,3)
    camera_poses_Rt = estimate_camera_poses( calobject_poses_local_Rt,
                                             indices_frame_camera,
                                             dots,
                                             dot_spacing,
                                             Ncameras,
                                             object_width_n)

    if len(camera_poses_Rt):
        # extrinsics should map FROM the ref coord system TO the coord system of the
        # camera in question. This is backwards from what I have
        extrinsics = nps.atleast_dims( mrcal.rt_from_Rt(mrcal.invert_Rt(camera_poses_Rt)),
                                       -2 )
    else:
        extrinsics = np.zeros((0,6))

    frames = \
        estimate_frame_poses(calobject_poses_local_Rt, camera_poses_Rt,
                             indices_frame_camera,
                             dot_spacing,
                             object_width_n)
    return intrinsics_data,extrinsics,frames


def get_imagersize_one(g, args_imagersize):
    r'''Returns the imager size for a given image glob

    This reports the size for ONE camera. I only look at the first match. It is
    assumed that all the images matching this glob have the same imager size.

    If I have a dots cache, then this is the ONLY place where I'd need the
    images on disk at all. If the user passes --imagersize, then I really don't
    need the images.

    '''
    if args_imagersize is not None:
        return args_imagersize

    files = glob.glob(g)
    if len(files) == 0:
        raise Exception("Glob '{}' matched no files. I need this for the imager size".format(g))


    img = cv2.imread(files[0]);
    h,w = img.shape[:2]

    if args_imagersize is not None:
        if w != args_imagersize[0] or h != args_imagersize[1]:
            raise Exception("Inconsistent imager size. Cmdline says {}, but image says {}. Since the image exists on disk, you don't need to pass --imagesize at all".format(args_imagersize, [w,h]))
    return [w,h]


def make_cameramodel(i_camera, intrinsics, extrinsics, imagersizes,
                     covariance_intrinsics_full,
                     covariance_intrinsics_observations_only):
    r'''Assemble one cameramodel from a completed calibration

    The calibration routines treat the intrinsics and extrinsics for all cameras
    as a vector. This routine converts a single camera to a mrcal.cameramodel
    structure that can be fed to all the other routines.

    '''

    if args.muse_extrinsics:
        Rt_r0 = np.array([[ 0.,  0.,  1.],
                          [ 1.,  0.,  0.],
                          [ 0.,  1.,  0.],
                          [ 0.,  0.,  0.]])
    else:
        # identity
        Rt_r0 = np.array([[ 1.,  0.,  0.],
                          [ 0.,  1.,  0.],
                          [ 0.,  0.,  1.],
                          [ 0.,  0.,  0.]])

    if i_camera >= 1:
        rt_x0 = extrinsics[i_camera-1,:].ravel()
    else:
        rt_x0 = np.zeros(6)
    Rt_rx = mrcal.compose_Rt(Rt_r0,
                             mrcal.invert_Rt( mrcal.Rt_from_rt(rt_x0)))

    if covariance_intrinsics_full is not None:
        covariance_intrinsics_full = covariance_intrinsics_full[i_camera, ...]
    if covariance_intrinsics_observations_only is not None:
        covariance_intrinsics_observations_only = covariance_intrinsics_observations_only[i_camera, ...]
    return mrcal.cameramodel( intrinsics            = (intrinsics[0], intrinsics[1][i_camera,:]),
                              extrinsics_Rt_toref   = Rt_rx,
                              imagersize            = imagersizes[i_camera],
                              covariance_intrinsics_full              = covariance_intrinsics_full,
                              covariance_intrinsics_observations_only = covariance_intrinsics_observations_only)

def make_cameramodels(intrinsics, extrinsics, imagersizes,
                      covariance_intrinsics_full,
                      covariance_intrinsics_observations_only):
    r'''Assemble cameramodels from a completed calibration

    The calibration routines treat the intrinsics and extrinsics for all cameras
    as a vector. This routine converts those to a list of mrcal.cameramodel
    structures that can be fed to all the other routines.

    '''
    return [ make_cameramodel(i_camera,
                              intrinsics, extrinsics, imagersizes,
                              covariance_intrinsics_full,
                              covariance_intrinsics_observations_only) for i_camera in xrange(len(intrinsics[1])) ]


# # Test for this function
# Nobservations = 5
# indices = np.array((1,3,4), dtype=int)
# observations = np.arange(15).reshape(5,3)
# frames = np.array((10,11,12,13), dtype=int)
# indices_frame_camera = np.array(((0,100),
#                                  (1,200),
#                                  (2,300),
#                                  (3,900),
#                                  (3,800)),
#                                 dtype=int)
# paths = np.arange(Nobservations)
# outlier_indices=np.array((2,5, 205,208, 311,390), dtype=int)
# # observations 0xx and 2xx are skipped
# # observation 3xx is now observation 1xx
# # 111,190
# split_observations, split_indices_frame_camera, split_paths, split_frames, split_outlier_indices = \
#     get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths,
#                                          frames,
#                                          outlier_indices)
# print split_outlier_indices
def get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths,
                                         frames = None,
                                         outlier_indices = None):
    r'''Returns a subset of observations from observation indices

    Observations are stored across variables:

    - observations
    - indices_frame_camera
    - paths
    - frames
    - outlier_indices

    These must all be self-consistent. This function takes in the desired
    observation indices to keep, and returns copies of all the variables that
    contain the requested subset of data and are consistent with each other

    '''

    if len(indices) == 0:
        raise Exception("Selected subset of data is empty: I threw out everything!")

    observations_new         = observations        [indices, ...].copy()
    paths_new                = [paths[i] for i in indices]
    indices_frame_camera_new = indices_frame_camera[indices, ...].copy()

    # I now collapse newly-missing frames and build the frame indices
    indices_frames  = []
    iframe_old_last = -1
    iframe_new_last = -1

    if outlier_indices is not None:
        # I make a copy of the outlier indices array, and iterate through it. As I
        # go I copy indices from the back of the array to the front. Initially the
        # to/from pointers are identical, but as I skip observations I'm going to be
        # skipping outlier indices, and a gap will developt between the pointers
        outlier_indices = outlier_indices.copy()

        # Index into the outlier_indices array that I copy FROM
        i_outlier_indices_old = 0
        # Index into the outlier_indices array that I copy TO
        i_outlier_indices_new = 0


    Nfeatures_in_observation = args.object_width_n*args.object_width_n

    def outlier_index_next_bounds(i0, iobs):


        ifeature_threshold = iobs*Nfeatures_in_observation
        for i in xrange(i0,len(outlier_indices)):
            if outlier_indices[i] >= ifeature_threshold:
                break
        else:
            return len(outlier_indices),len(outlier_indices)

        # found beginning of the set of outliers for this observation (or
        # further ones). If these outliers are for THIS observation, find the
        # end of the outliers for this observation. Otherwise tell the caller
        i0 = i
        if int(outlier_indices[i]/Nfeatures_in_observation) != iobs:
            # I don't have any outliers for this observation
            return i0,i0

        ifeature_threshold += Nfeatures_in_observation
        for i in xrange(i0+1,len(outlier_indices)):
            if outlier_indices[i] >= ifeature_threshold:
                return i0,i

        return i0,len(outlier_indices)

    def outlier_indices_accept(iobs_old, iobs_new, i_outlier_indices_old,i_outlier_indices_new):

        # I need to grab outliers for this observation. These begin somewhere
        # at/after i_outlier_indices_old because I may have skipped some
        # observations. First I find where the observations I want begin
        iold0,iold1 = outlier_index_next_bounds(i_outlier_indices_old, iobs_old)
        if iold0 == iold1:
            # I don't have any outliers for this observation
            return iold1, i_outlier_indices_new

        Noutliers_here = iold1-iold0
        inew0 = i_outlier_indices_new
        inew1 = inew0 + Noutliers_here
        i_observations_offset = iobs_old-iobs_new

        outlier_indices[inew0:inew1] = outlier_indices[iold0:iold1] - i_observations_offset*Nfeatures_in_observation

        return iold1, i_outlier_indices_new + Noutliers_here


    for iobs_new in xrange(len(indices)):
        iobs_old   = indices[iobs_new]
        iframe_old = indices_frame_camera_new[iobs_new,0]
        if iframe_old != iframe_old_last:
            # Saw new frame. The iframe in the data is going to be
            # non-consecutive, so I adjust it to become consecutive. And I then
            # update the mapping
            iframe_new_last += 1
            iframe_old_last = iframe_old
            indices_frames.append(iframe_old)
        indices_frame_camera_new[iobs_new,0] = iframe_new_last

        if outlier_indices is not None:
            i_outlier_indices_old,i_outlier_indices_new = \
                outlier_indices_accept(iobs_old, iobs_new,
                                   i_outlier_indices_old,i_outlier_indices_new)


    if frames is not None:
        frames_new = frames[indices_frames, ...].copy()
    else:
        frames_new = None

    if outlier_indices is not None:
        outlier_indices = outlier_indices[:i_outlier_indices_new]
    return observations_new, indices_frame_camera_new, paths_new, frames_new, outlier_indices

def get_observation_subset__random(ratio_cull, observations, indices_frame_camera, paths):
    r'''Returns a random subset of observations'''

    # keep this many
    N = int(round((1.0 - ratio_cull) * len(observations)))

    indices = np.sort(np.random.choice(len(observations), N, replace=False))

    return get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths)

def get_observation_subset__right_of_threshold_and_within_center(point_x_threshold,
                                                                 rad_threshold,
                                                                 observations,
                                                                 imagersizes,
                                                                 indices_frame_camera, paths, object_width_n):
    r'''Returns a subset of observations

    This throws out all observations that lie COMPLETELY to the left of the
    given threshold or outside the given circle. The mrcal internals handle
    partial board observations

    '''

    # observations that have fewer than this many points are thrown out
    must_have_at_least_points = object_width_n*2

    def have_enough_points(i):
        x = None
        if point_x_threshold > 0:
            x = observations[i,:,:,0] >= point_x_threshold
        if rad_threshold > 0:
            y = nps.norm2(observations[i,...] - (imagersizes[indices_frame_camera[i,1]] - 1.)/2.) < rad_threshold*rad_threshold
            if x is None:
                x = y
            else:
                x = x*y

        return np.count_nonzero(x) >= must_have_at_least_points

    indices = np.array([i for i in xrange(len(observations)) if \
                        have_enough_points(i)],
                       dtype=int)
    return get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths)

def incremental_optimization_loop(args, imagersizes, observations, indices_frame_camera, outlier_indices, incremental):
    '''Solve an incrementally-expanding optimization problem in several passes

    The logic is this:

        m   = simplest_model
        roi = smallest region

        while roi<ROI:
            solve(m,roi)
            if(couldn't fit the data very well):
                if m < M:
                    m++
                else:
                    # I'm already at the most complex model
                    print "Given distortion model doesn't fit in the required ROI!"
                    break
            else:
                roi++

    I.e. I start with a smaller region-of-interest than what I actually care
    about, and with a simpler distortion model than what I was asked to use. I
    solve again and again, increasing the region-of-interest and distortion
    model complexity as I go, using the outlier counts to guide the process.

    have minimal m that works with ROI

    '''

    Ncameras = len(args.images)

    distortion_model = 'DISTORTION_NONE'
    intrinsics_data,extrinsics,frames = \
        make_seed_no_distortion(imagersizes          = imagersizes,
                                focal_estimate       = args.focal,
                                Ncameras             = Ncameras,
                                indices_frame_camera = indices_frame_camera,
                                dots                 = observations,
                                dot_spacing          = args.object_spacing,
                                object_width_n       = args.object_width_n)


    # done with everything. Run the calibration, in several passes
    sys.stderr.write("vvvvvvvvvvvvvvvvvvvv initial solve: geometry only\n")
    stats = mrcal.optimize(intrinsics_data, extrinsics, frames, None,
                           observations, indices_frame_camera,
                           None, None,
                           distortion_model,
                           imagersizes                       = imagersizes,
                           observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                           do_optimize_intrinsic_core        = False,
                           do_optimize_intrinsic_distortions = False,
                           calibration_object_spacing        = args.object_spacing,
                           calibration_object_width_n        = args.object_width_n,
                           skip_outlier_rejection            = True,
                           skip_regularization               = True,
                           outlier_indices                   = outlier_indices,
                           roi                               = args.roi,
                           get_invJtJ_intrinsics             = False,
                           VERBOSE                           = False)
    sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n\n".format(stats['rms_reproj_error__pixels']))

    sys.stderr.write("vvvvvvvvvvvvvvvvvvvv initial solve: geometry and intrinsic core only\n")
    stats = mrcal.optimize(intrinsics_data, extrinsics, frames, None,
                           observations, indices_frame_camera,
                           None, None,
                           distortion_model,
                           imagersizes                       = imagersizes,
                           observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                           do_optimize_intrinsic_core        = True,
                           do_optimize_intrinsic_distortions = False,
                           calibration_object_spacing        = args.object_spacing,
                           calibration_object_width_n        = args.object_width_n,
                           skip_outlier_rejection            = True,
                           skip_regularization               = True,
                           outlier_indices                   = outlier_indices,
                           roi                               = args.roi,
                           get_invJtJ_intrinsics             = False,
                           VERBOSE                           = False)
    sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n".format(stats['rms_reproj_error__pixels']))
    # I favor the center pixel at the center of the imager

    intrinsics_data[:,2:4] = (imagersizes - 1) / 2

    Nfeatures = args.object_width_n*args.object_width_n*len(observations)

    def get_scaled_roi(roi_final, iroi, Nroi):

        if Nroi == 1:
            if iroi != 0:
                raise Exception("get_scaled_roi(Nroi=1, iroi != 0) doesn't make any sense")
            return roi_final

        scale = float(iroi+1)/float(Nroi)
        return nps.glue(roi_final[:,:2],
                        roi_final[:,2:] * scale,
                        axis = -1)

    def expand_intrinsics(distortion_model, intrinsics_data):
        NnewDistortions = \
            mrcal.getNdistortionParams(distortion_model) - \
            (intrinsics_data.shape[1] - 4)
        newDistortions = \
            (np.random.random((Ncameras, NnewDistortions)) - 0.5)*2. *1e-6
        m = re.search("OPENCV([0-9]+)", distortion_model)
        if m:
            Nd = int(m.group(1))
            if Nd >= 8:
                # Push down the rational components of the seed. I'd like these all to
                # sit at 0 ideally. The radial distortion in opencv is x_distorted =
                # x*scale where r2 = norm2(xy - xyc) and
                #
                # scale = (1 + k0 r2 + k1 r4 + k4 r6)/(1 + k5 r2 + k6 r4 + k7 r6)
                #
                # Note that k2,k3 are tangential (NOT radial) distortion components.
                # Note that the r6 factor in the numerator is only present for
                # >=DISTORTION_OPENCV5. Note that the denominator is only present for >=
                # DISTORTION_OPENCV8. The danger with a rational model is that it's
                # possible to get into a situation where scale ~ 0/0 ~ 1. This would
                # have very poorly behaved derivatives. If all the rational coefficients
                # are ~0, then the denominator is always ~1, and this problematic case
                # can't happen. I favor that.
                newDistortions[5:8] *= 1e-3
        return nps.glue( intrinsics_data, newDistortions, axis=-1 )

    def eval_solution(stats, outside_ROI_indices__prevROI):

        Nfeatures = args.object_width_n*args.object_width_n*len(observations)
        x    = stats['x'][:Nfeatures*2]

        def makemask_inside(outside_indices):
            maskout = np.zeros(x.shape, dtype=bool)
            maskout[outside_indices*2 + 0] = True
            maskout[outside_indices*2 + 1] = True
            return ~maskout


        if outside_ROI_indices__prevROI is None:
            maskin = makemask_inside(stats['outside_ROI_indices'])
            s = np.std(x[maskin])

        else:
            maskold_only = makemask_inside(outside_ROI_indices__prevROI)
            masknew_only = \
                makemask_inside (stats['outside_ROI_indices']) * \
                ~maskold_only


            # It's possible that increasing the roi adds a SMALL NUMBER of
            # points total. If the model doesn't fit the new ROI well, these
            # points would have high errors, but since there aren't a lot of
            # them, this wouldn't reflect at all in the new distribution. I
            # re-weight the distribution of the NEW points to be equal to k
            # times the distribution of all the previous points in the set. If
            # k==1 then the set of the new points is equivalent in weight to the
            # set of the old points
            k = 1
            xold = x[maskold_only]
            xnew = x[masknew_only]
            if len(xnew) == 0:
                print "RMS error: {}".format(stats['rms_reproj_error__pixels'])
                return True,"Extended ROI contains no new data"

            wnew = k * len(xold)/len(xnew)

            mean = (np.sum( xold                  ) + wnew*np.sum( xnew                  )) / ((1. + k) * len(xold))
            var  = (np.sum((xold-mean)*(xold-mean)) + wnew*np.sum((xnew-mean)*(xnew-mean))) / ((1. + k) * len(xold))
            s    = np.sqrt(var)



        print "RMS error: {}".format(stats['rms_reproj_error__pixels'])
        print "In-ROI independent x,y stdev: {} (user says {})".format(s, args.observed_pixel_uncertainty)

        # If a model fits in a specific ROI, then (assuming no outliers) all the
        # error is attributable to input noise. I'm given an estimate of this
        # noise on the input, so I can check to see if this is true
        stdev_error_ratio = s / args.observed_pixel_uncertainty

        q_threshold = 1.5

        return stdev_error_ratio < q_threshold, "stdev_error_ratio={} (wanted < {})".format(stdev_error_ratio, q_threshold)


    # Alrighty. All the preliminary business is finished. I should have a usable
    # seed now. And thus I now run the main optimization loop
    if not incremental:
        # We're not doing the incremental loop. Just solve it once and call it good
        distortion_model = args.distortion_model
        intrinsics_data  = expand_intrinsics(distortion_model, intrinsics_data)
        stats = mrcal.optimize(intrinsics_data, extrinsics, frames, None,
                               observations, indices_frame_camera,
                               None, None,
                               distortion_model,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = True,
                               do_optimize_intrinsic_distortions = True,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = args.skip_outlier_rejection,
                               skip_regularization               = args.skip_regularization,
                               outlier_indices                   = outlier_indices,
                               roi                               = args.roi,
                               get_invJtJ_intrinsics             = False,
                               VERBOSE                           = args.verbose_solver)
        return "fixed solve", (distortion_model, intrinsics_data), extrinsics, frames, args.roi, stats




    Nroi = 8
    if args.roi is None:
        # no explicit region-of-interest given. I thus use the whole imager.
        # I use an ellipse with the imager's aspect ratio, passing through
        # the corner
        widths       = imagersizes.astype(float)-1
        centerpixels = widths / 2.
        roi_final = nps.glue(centerpixels, widths/2.*np.sqrt(2), axis=-1)
    else:
        roi_final = args.roi

    stats_best = None
    roi_best   = None

    iroi = 0
    outside_ROI_indices__prevROI = None
    while iroi<Nroi:
        roi = get_scaled_roi(roi_final, iroi, Nroi)

        print ""
        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv next distortion/ROI:\n")
        print "Distortion model: {}"         .format(distortion_model)
        print "ROI:              {}/{}  ({})".format(iroi+1, Nroi, roi)

        state = copy.deepcopy( (intrinsics_data, extrinsics, frames), )
        stats = mrcal.optimize(state[0], state[1], state[2], None,
                               observations, indices_frame_camera,
                               None, None,
                               distortion_model,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = True,
                               do_optimize_intrinsic_distortions = True,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = True,
                               skip_regularization               = args.skip_regularization,
                               outlier_indices                   = outlier_indices,
                               roi                               = roi,
                               get_invJtJ_intrinsics             = False,
                               VERBOSE                           = args.verbose_solver)

        solution_acceptable,solution_description = eval_solution(stats, outside_ROI_indices__prevROI)

        if solution_acceptable:
            # We found a good solution for this distortion model and ROI. Let's
            # expand the region of interest and go again

            # save the initial state. The last one of these chunks of data is
            # the best solution I got
            outlier_indices       = stats['outlier_indices']
            intrinsics_data       = state[0].copy()
            extrinsics            = state[1].copy()
            frames                = state[2].copy()
            stats_best            = copy.deepcopy(stats)
            roi_best              = copy.deepcopy(roi)
            distortion_model_best = copy.deepcopy(distortion_model)
            result                = 'Usable solve found at the full ROI'

            outside_ROI_indices__prevROI = stats['outside_ROI_indices']
            iroi += 1
            sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ {}: good solve! roi++\n".format(solution_description))
        else:
            # This solution wasn't very good. Let's try a richer distortion
            # model

            distortion_model1 = mrcal.getNextDistortionModel(distortion_model, args.distortion_model)

            if distortion_model1 == distortion_model:

                # we're already at the last model in the family, or at the
                # maximum model the user asked for. There's nowhere more to go,
                # so I guess I'm done
                sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ {}: ill-fitting solve, but no more distortion-models remaining. I'm done\n".format(solution_description))

                # # For testing. The distribution can be plotted thusly:
                # import gnuplotlib as gp
                # x    = stats['x']
                # maskout = np.zeros(x.shape, dtype=bool)
                # maskout[stats['outside_ROI_indices']*2 + 0] = True
                # maskout[stats['outside_ROI_indices']*2 + 1] = True
                # x = x[~maskout]
                # s    = np.std(x)
                # s2   = s*s
                # gp.plot(x, histogram='freq', binwidth=0.2,
                #         equation='1./sqrt(2.*pi*{s2})*exp(-x*x/(2.*{s2})) axis x1y2'.format(s2=s2),
                #         _xrange=[-5.*s,5.*s],
                #         ymin=0, y2min=0,
                #         hardcopy='/tmp/tst.gp')
                # import IPython
                # IPython.embed()
                # sys.exit()


                if stats_best is None:
                    # This is the best I got I guess
                    intrinsics_data       = state[0]
                    extrinsics            = state[1]
                    frames                = state[2]
                    stats_best            = stats
                    roi_best              = roi
                    distortion_model_best = distortion_model
                    result                = 'No usable solves found'
                else:
                    result                = 'Usable solves found, but not for the full ROI'
                break

            else:
                # I try the next model in the family, keeping the roi and
                # outlier list the same
                distortion_model = distortion_model1
                intrinsics_data  = expand_intrinsics(distortion_model, intrinsics_data)
                sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ {}: ill-fitting solve, distortion++\n".format(solution_description))

    return                                                                            \
        result,                                                                       \
        ( distortion_model_best,                                                      \
          intrinsics_data[:,:(4+mrcal.getNdistortionParams(distortion_model_best))]), \
         extrinsics,                                                                  \
         frames,                                                                      \
         roi_best,                                                                    \
         stats_best







args = parse_args()
# expand ~/ into $HOME/
args.images = [os.path.expanduser(g) for g in args.images]

Ncameras = len(args.images)
if Ncameras > 10:
    raise Exception("Got {} image globs. It should be one glob per camera, and this sounds like WAY too make cameras. Did you forget to escape your glob?". \
                    format(Ncameras))

# list of imager sizes; one per camera
imagersizes = np.array([get_imagersize_one(imagesglob, args.imagersize) for imagesglob in args.images],
                       dtype=np.int32)

if args.roi is not None:
    if len(args.roi) != Ncameras:
        raise Exception("Globs say we have {} cameras, but --roi suggests I have {}. These MUST match". \
                        format(Ncameras, len(args.roi)))
    try:
        args.roi = np.array(args.roi, dtype=float)
    except:
        sys.stderr.write("Couldn't interpret --roi as a numpy array")
        raise

observations, indices_frame_camera, paths = \
    get_observations(args.object_width_n,
                     args.object_width_n,
                     args.images,
                     args.dots_cache,
                     jobs = args.jobs)


if args.cull_random_observations_ratio >= 0:
    observations, indices_frame_camera, paths, _, _ = \
        get_observation_subset__random(args.cull_random_observations_ratio,
                                       observations, indices_frame_camera, paths)
outlier_indices = None
if args.cull_points_left_of > 0 or args.cull_points_rad_off_center > 0:

    # first cut off full observations
    observations, indices_frame_camera, paths, _, _ = \
        get_observation_subset__right_of_threshold_and_within_center( \
            args.cull_points_left_of,
            args.cull_points_rad_off_center,
            observations,
            imagersizes, indices_frame_camera, paths,
            args.object_width_n)

    # any observations that lie partially outside the threshold remain. I cut
    # out individual points as outliers
    if args.cull_points_left_of > 0:
        outlier_indices0 = set(np.flatnonzero(observations[...,0] < args.cull_points_left_of))
    else:
        outlier_indices0 = set()

    if args.cull_points_rad_off_center > 0:
        centerpixels = (imagersizes[ indices_frame_camera[:,1] ] - 1.)[:,np.newaxis,np.newaxis,:] / 2.
        radsq = args.cull_points_rad_off_center*args.cull_points_rad_off_center
        outlier_indices1 = set(np.flatnonzero(nps.norm2(observations - centerpixels) > radsq))
    else:
        outlier_indices1 = set()

    outlier_indices = np.array(sorted(list(outlier_indices0.union( outlier_indices1 ))), dtype=np.int32)


result,intrinsics,extrinsics,frames,roi,stats = \
    incremental_optimization_loop(args, imagersizes, observations, indices_frame_camera, outlier_indices, args.incremental)
if args.incremental:
    print ">>>>>>>>>>>>>>>>> " + result
    print "Final Distortion model: {}".format(intrinsics[0])
    print "Final ROI:              {}".format(roi)


if args.skip_outlier_rejection: print "We are NOT rejecting outliers"
else:                           print "We ARE rejecting outliers"
if args.skip_regularization:    print "We are NOT applying regularization in the solver"
else:                           print "We ARE applying regularization in the solver"


# I now optimize again, primarily to get covariance_intrinsics_observations_only and solver_context. This should be
# quick since I'm already at the optimum. This solve shouldn't move the
# operating point at all
solver_context = mrcal.SolverContext()




















if args.num_cross_validation_splits > 1:

    # THIS IS ALL VERY EXPERIMENTAL


    def cross_validation_makesplit(Nobservations, Nsplit):
        r'''Returns a random splitting of the data set

        This function returns a python list (of length Nsplit). Each contains a
        numpy array of sorted integer indices

        I have Nobservations observations, and I want to split them into Nsplit
        equal (and random) sets. If an even splitting isn't possible, the N
        stragglers are distributed amount the N trailing sets

        '''

        # I create a random list of indices, and take sequential subsets of it
        i_observations = np.arange(Nobservations, dtype=np.int32)
        np.random.shuffle(i_observations)

        # I could do this:
        #   s = [i_observations[isplit*N_insplit:(isplit+1)*N_insplit] for isplit in xrange(Nsplit)]
        # But then I need to deal with the remaining observations. For instance,
        # trying to split 14 into 4 groups would create 4 groups of 3, and 2
        # observations remaining. I want to distribute these 2 extra observations
        # one-at-a-time among my groups, hence this logic:

        s = [None] * Nsplit
        iobservation = 0
        for isplit in xrange(Nsplit):
            N_inthissplit = int( (Nobservations - iobservation) / (Nsplit - isplit))
            s[isplit] = i_observations[iobservation:iobservation+N_inthissplit]
            iobservation += N_inthissplit

        for i in s:
            i.sort()

        return s




    Nobservations = indices_frame_camera.shape[0]
    splits = cross_validation_makesplit(Nobservations, args.num_cross_validation_splits)
    for isplit in xrange(len(splits)):

        s = splits[isplit]

        split_observations, split_indices_frame_camera, split_paths, split_frames, split_outlier_indices = \
            get_observation_subset__from_indices(s, observations, indices_frame_camera, paths,
                                                 frames, stats['outlier_indices'])

        split_intrinsics = copy.deepcopy(intrinsics)
        split_extrinsics = copy.deepcopy(extrinsics)

        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv Evaluating split {}/{}\n".format(isplit+1, args.num_cross_validation_splits))
        stats = mrcal.optimize(split_intrinsics[1],
                               split_extrinsics,
                               split_frames,
                               None,
                               split_observations, split_indices_frame_camera,
                               None, None,
                               split_intrinsics[0],
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = True,
                               do_optimize_intrinsic_distortions = True,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = args.skip_outlier_rejection,
                               skip_regularization               = args.skip_regularization,
                               outlier_indices                   = split_outlier_indices,
                               roi                               = roi,
                               get_invJtJ_intrinsics             = True,
                               VERBOSE                           = False,
                               solver_context                    = solver_context)
        sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n".format(stats['rms_reproj_error__pixels']))

        try:
            covariance_intrinsics_observations_only = stats['invJtJ_intrinsics_observations_only']  \
                * args.observed_pixel_uncertainty \
                * args.observed_pixel_uncertainty
        except:
            covariance_intrinsics_observations_only = None

        report = "RMS reprojection error: {:.01f} pixels\n".format(stats['rms_reproj_error__pixels'])

        # Npoints = args.object_width_n*args.object_width_n*len(split_observations)

        # xyerr = stats['x'][:Npoints*2].reshape(Npoints,2)
        # worst_point_err = np.sqrt(np.max(nps.inner(xyerr,xyerr)))
        # report += "Worst reprojection error: {:.01f} pixels\n".format(worst_point_err)
        # report += "Noutliers: {} out of {} total points: {:.01f}% of the data\n". \
        #     format(stats['Noutliers'],
        #            args.object_width_n*args.object_width_n*len(split_observations),
        #            100.0 * stats['Noutliers'] / (args.object_width_n*args.object_width_n*len(split_observations)))
        # if covariance_intrinsics_observations_only is not None:
        #     report += "Expected projection uncertainty due to input pixel observations.\n"
        #     report += "  This is an (Ncameras,5) matrix. For each camera we look at the\n"
        #     report += "  (top-left, bottom-left, top-right, bottom-right, center) imager locations in order.\n"
        #     report += "  The corners are 10% inside the image. The reported numbers are 'expected projection\n"
        #     report += "  error', measured in pixels.\n"
        #     Expected_projection_shift = np.zeros((Ncameras, 5))
        #     for i_camera in xrange(Ncameras):

        #         v = np.array(((0.1*imagersizes[i_camera][0], 0.1*imagersizes[i_camera][1]),
        #                       (0.1*imagersizes[i_camera][0], 0.9*imagersizes[i_camera][1]),
        #                       (0.9*imagersizes[i_camera][0], 0.1*imagersizes[i_camera][1]),
        #                       (0.9*imagersizes[i_camera][0], 0.9*imagersizes[i_camera][1]),
        #                       (0.5*imagersizes[i_camera][0], 0.5*imagersizes[i_camera][1])))
        #         # 3D vectors we're projecting
        #         # shape (Ncameras, 5, 3)
        #         V = mrcal.unproject(v, intrinsics[0], intrinsics[1][i_camera])
        #         Expected_projection_shift[i_camera, :] = \
        #             mrcal.compute_intrinsics_uncertainty(V, intrinsics[0], intrinsics[1][i_camera], covariance_intrinsics_observations_only[i_camera])
        #     report += np.array2string(Expected_projection_shift, precision=2) + "\n"

        print report



    print "done!!!!!!"
    sys.exit()












sys.stderr.write("vvvvvvvvvvvvvvvvvvvv final, full re-optimization call to get covariance_intrinsics_observations_only and solver_context\n")
stats = mrcal.optimize(intrinsics[1],extrinsics,frames, None,
                       observations, indices_frame_camera,
                       None, None,
                       intrinsics[0],
                       imagersizes                       = imagersizes,
                       observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                       do_optimize_intrinsic_core        = True,
                       do_optimize_intrinsic_distortions = True,
                       calibration_object_spacing        = args.object_spacing,
                       calibration_object_width_n        = args.object_width_n,
                       skip_outlier_rejection            = args.skip_outlier_rejection,
                       skip_regularization               = args.skip_regularization,
                       outlier_indices                   = stats['outlier_indices'],
                       roi                               = roi,
                       get_invJtJ_intrinsics             = True,
                       VERBOSE                           = False,
                       solver_context                    = solver_context)
sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n".format(stats['rms_reproj_error__pixels']))

try:
    covariance_intrinsics_full = stats['invJtJ_intrinsics_full']  \
        * args.observed_pixel_uncertainty \
        * args.observed_pixel_uncertainty
except:
    covariance_intrinsics_full = None
try:
    covariance_intrinsics_observations_only = stats['invJtJ_intrinsics_observations_only']  \
        * args.observed_pixel_uncertainty \
        * args.observed_pixel_uncertainty
except:
    covariance_intrinsics_observations_only = None

report = "RMS reprojection error: {:.01f} pixels\n".format(stats['rms_reproj_error__pixels'])

Npoints = args.object_width_n*args.object_width_n*len(observations)
xyerr = stats['x'][:Npoints*2].reshape(Npoints,2)
worst_point_err = np.sqrt(np.max(nps.inner(xyerr,xyerr)))
report += "Worst reprojection error: {:.01f} pixels\n".format(worst_point_err)
report += "Noutliers: {} out of {} total points: {:.01f}% of the data\n". \
    format(stats['Noutliers'],
           args.object_width_n*args.object_width_n*len(observations),
           100.0 * stats['Noutliers'] / (args.object_width_n*args.object_width_n*len(observations)))
if covariance_intrinsics_observations_only is not None:
    report += "Expected projection uncertainty due to input pixel observations.\n"
    report += "  This is an (Ncameras,5) matrix. For each camera we look at the\n"
    report += "  (top-left, bottom-left, top-right, bottom-right, center) imager locations in order.\n"
    report += "  The corners are 10% inside the image. The reported numbers are 'expected projection\n"
    report += "  error', measured in pixels.\n"
    Expected_projection_shift = np.zeros((Ncameras, 5))
    for i_camera in xrange(Ncameras):

        v = np.array(((0.1*imagersizes[i_camera][0], 0.1*imagersizes[i_camera][1]),
                      (0.1*imagersizes[i_camera][0], 0.9*imagersizes[i_camera][1]),
                      (0.9*imagersizes[i_camera][0], 0.1*imagersizes[i_camera][1]),
                      (0.9*imagersizes[i_camera][0], 0.9*imagersizes[i_camera][1]),
                      (0.5*imagersizes[i_camera][0], 0.5*imagersizes[i_camera][1])))
        # 3D vectors we're projecting
        # shape (Ncameras, 5, 3)
        V = mrcal.unproject(v, intrinsics[0], intrinsics[1][i_camera])
        Expected_projection_shift[i_camera, :] = \
            mrcal.compute_intrinsics_uncertainty(V, intrinsics[0], intrinsics[1][i_camera], covariance_intrinsics_observations_only[i_camera])
    report += np.array2string(Expected_projection_shift, precision=2) + "\n"

print report





# Write the output models
models = make_cameramodels(intrinsics, extrinsics, imagersizes,
                           covariance_intrinsics_full,
                           covariance_intrinsics_observations_only)
# The note says how we ran this, and contains the commented-out report
note = \
    "generated with {}\n".format(sys.argv) + \
    re.sub(r"^(.)", r"# \1", report, flags=re.M)
for i_camera in xrange(len(models)):
    cahvorfile = '{}/camera-{}.cahvor'.format(args.outdir, i_camera)
    models[i_camera].write(cahvorfile, note)
    print "Wrote {}".format(cahvorfile)

    cameramodelfile = '{}/camera-{}.cameramodel'.format(args.outdir, i_camera)
    models[i_camera].write(cameramodelfile, note)
    print "Wrote {}".format(cameramodelfile)



if not args.explore:
    sys.exit(0)



# We're exploring!
import gnuplotlib as gp


print r'''Calibration results REPL.
Potential things to look at:

    show_reprojection_errors_worst(i_observation_in_order_from_worst)
    show_reprojection_errors(i_observation)
    show_intrinsics_uncertainty()
    show_errors('histogram',   i_camera, ignore_outliers=True)
    show_errors('vectorfield', i_camera, ignore_outliers=True)
    show_errors('heatmap',     i_camera, ignore_outliers=True)
    show_errors('radial',      i_camera, ignore_outliers=True)
    show_roi(i_camera)
    stats
    i_observations_worst
    rms_err_including_outliers_perimage
    rms_err_0_for_outliers_perimage
    paths[i_observations_worst[0]]
'''


projected = mrcal.calobservations_project(intrinsics[0], intrinsics[1], extrinsics, frames, args.object_spacing, args.object_width_n)

err_including_outliers,err_0_for_outliers = \
    mrcal.calobservations_compute_reproj_error(projected, observations,
                                               indices_frame_camera, args.object_width_n,
                                               stats['outlier_indices'])
rms_err_including_outliers_perimage = np.sqrt( nps.norm2( nps.clump(err_including_outliers,n=-3) ) /
                                               (args.object_width_n*args.object_width_n) )
rms_err_0_for_outliers_perimage     = np.sqrt( nps.norm2( nps.clump(err_0_for_outliers,    n=-3) ) /
                                               (args.object_width_n*args.object_width_n) )

i_observations_worst    = list(reversed(np.argsort(rms_err_0_for_outliers_perimage)))
i_observation_from_path = dict( [(paths[_i],_i) for _i in xrange(len(observations))] )

def show_reprojection_errors(observation, **kwargs):
    r'''Visualize calibration residuals

    Takes either an integer (observation index) or a string (path)

    '''

    if isinstance(observation, int):
        i_observation = observation
    elif isinstance(observation, str):
        i_observation = i_observation_from_path[observation]
    else:
        raise Exception("observation should be a string (image path) or an integer; got type(observation) = {}".format(type(observation)))

    ioutlier0 = np.searchsorted(stats['outlier_indices'], args.object_width_n*args.object_width_n*i_observation,     'left')
    ioutlier1 = np.searchsorted(stats['outlier_indices'], args.object_width_n*args.object_width_n*(i_observation+1), 'left')
    outlier_indices_thisobservation = stats['outlier_indices'][ioutlier0:ioutlier1] - args.object_width_n*args.object_width_n*i_observation

    obs              = nps.clump( observations[i_observation], n=2)
    i_frame,i_camera = indices_frame_camera[i_observation]
    reproj           = nps.clump( projected[i_frame,i_camera], n=2)

    # error per dot
    err = np.sqrt(nps.inner(reproj - obs,
                            reproj - obs))

    nonoutlier_indices_thisobservation = np.ones((args.object_width_n*args.object_width_n,),dtype=bool)
    nonoutlier_indices_thisobservation[outlier_indices_thisobservation] = False
    obs_ignoring_outliers = obs[nonoutlier_indices_thisobservation, :]

    imagepath = paths[i_observation]
    plotkwargs = \
        dict(square=1,cbmin=0,
             title='{}: i_observation={}, i_frame={}, i_camera={}, path={}, error_RMS_all_points={}, error_RMS_ignoring_outliers={}'. \
               format( intrinsics[0],
                       i_observation, i_frame, i_camera,
                       paths[i_observation],
                       rms_err_including_outliers_perimage[i_observation],
                       rms_err_0_for_outliers_perimage[i_observation]),
             **kwargs)
    if os.path.isfile(imagepath):
        # only plot an image overlay if the image exists
        plotkwargs['rgbimage'] = imagepath
        plotkwargs['set']      = 'autoscale noextend'
    else:
        W,H=imagersizes[i_camera]
        plotkwargs['xrange'] = [0,W-1]
        plotkwargs['yrange'] = [H-1,0]

    gp.plot( (obs_ignoring_outliers[:,0], obs_ignoring_outliers[:,1], err[nonoutlier_indices_thisobservation],
              {'with': 'points pt 7 ps 2 palette', 'legend': 'reprojection error', 'tuplesize': 3}),
             (obs   [:,0], obs   [:,1], {'with': 'points', 'legend': 'observed'}),
             (reproj[:,0], reproj[:,1], {'with': 'points', 'legend': 'hypothesis'}),
             **plotkwargs)

def show_reprojection_errors_worst(i, **kwargs):
    show_reprojection_errors( i_observations_worst[i], **kwargs )

def check_confidence_computations():
    r'''These all test the confidence computations using the debugging exports from
    computeConfidence_MMt() in mrcal.c. It's all for debugging.

    '''

    # E0 = nps.inner(x,x)
    # E0_rms = np.sqrt(E0/(x.shape[0]/2))
    # mu_sumofsquares = E0
    # s_sumofsquares  = 2*np.sqrt(E0)
    # mu_meanofsquares = mu_sumofsquares/(x.shape[0]/2)
    # s_meanofsquares  = s_sumofsquares /(x.shape[0]/2)

    # gp.plot( equation='1./sqrt(2.*pi*{var})*exp(-({x_meanofsquares}-{mu})**2. / (2.*{var}))*2*x'. \
    #          format(x_meanofsquares = '(x*x)',
    #                 mu  = mu_meanofsquares,
    #                 var = s_meanofsquares*s_meanofsquares),
    #          _xrange=[0,E0_rms*2],
    #          _set='samples 1000')

    i_camera = 0


    import IPython
    import numpy as np
    import numpysane as nps
    import gnuplotlib as gp

    global stats,observations,MMt

    raise Exception("I think this doesn't take into account the weights on x[] (that come from, for example, ROI)")

    x0            = stats['x']
    dm            = np.loadtxt("/tmp/dm")
    Jtdm          = np.loadtxt("/tmp/Jtdm")
    dp            = np.loadtxt("/tmp/dp")
    dx_hypothesis = np.loadtxt("/tmp/dx_hypothesis")
    dx            = np.loadtxt("/tmp/dx")

    observations += dm.reshape(116,10,10,2)
    intrinsics0 = np.copy(intrinsics[1])
    frames0     = np.copy(frames)
    p0          = nps.glue( intrinsics[1].ravel(),
                            frames.ravel(),
                            axis=-1)

    J      = np.fromfile("/tmp/J1_23200_704.dat").reshape(23200,704)
    M      = np.linalg.pinv(J)
    MMt_ref = nps.matmult(M,nps.transpose(M))
    Nintrinsics = intrinsics[1].shape[-1]
    print "MMt difference should be 0: {}".format(np.linalg.norm(MMt[i_camera]/args.observed_pixel_uncertainty/args.observed_pixel_uncertainty -
                                                                 MMt_ref[Nintrinsics*i_camera:Nintrinsics*(i_camera+1),
                                                                         Nintrinsics*i_camera:Nintrinsics*(i_camera+1)]))

    stats = mrcal.optimize(intrinsics[1], extrinsics, frames, None,
                           observations, indices_frame_camera,
                           None, None,
                           intrinsics[0],
                           imagersizes                       = imagersizes,
                           observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                           do_optimize_intrinsic_core        = True,
                           do_optimize_intrinsic_distortions = True,
                           calibration_object_spacing        = args.object_spacing,
                           calibration_object_width_n        = args.object_width_n,
                           VERBOSE                           = False,
                           skip_outlier_rejection            = True,
                           skip_regularization               = True)

    p1          = nps.glue( intrinsics[1].ravel(),
                            frames.ravel(),
                            axis=-1)
    x1 = stats['x']
    intrinsics1 = intrinsics[1]
    E0 = np.sqrt(nps.inner(x0,x0)/(x0.shape[0]/2))
    E1 = np.sqrt(nps.inner(x1,x1)/(x0.shape[0]/2))


    dp_observed = p1-p0
    dx_observed = x1-x0

    dp_ref = nps.matmult(M, nps.transpose(dm)).ravel()

    print "dp difference should be 0: {}".format(np.linalg.norm(dp - dp_observed))
    print "dp difference should be 0: {}".format(np.linalg.norm(dp - dp_ref))
    print "dx difference should be 0: {}".format(np.linalg.norm(dx - dx_observed))
    # gp.plot(nps.cat(dp,            dp_observed), legend=np.array(("computed",   "observed")), title="dp")
    # gp.plot(nps.cat(dp,            dp_ref),      legend=np.array(("computed",   "reference")),title="dp")
    # gp.plot(nps.cat(dx,            dx_observed), legend=np.array(("computed",   "observed")), title="dx")

    # unperturbed projection: q0
    # perturbed   projection: q1
    # If my math is right, and things are locally linear, I can predict q1-q0:
    # dq = F df + C dc + D dd =
    #    = (F Mf + C Mc + D Md) dm
    v    = np.array((-0.81691696, -0.02852554,  0.57604945))
    p    = mrcal.project(v, intrinsics[0], intrinsics0[i_camera], get_gradients=True)
    q0   = p[..., 0]
    F    = p[..., 1:3]
    C    = p[..., 3:5]
    D    = p[..., 5: ]
    q1   = mrcal.project(v, intrinsics[0], intrinsics1[i_camera], get_gradients=False)
    Mf = M[Nintrinsics*i_camera+0 : Nintrinsics*i_camera+2,   :]
    Mc = M[Nintrinsics*i_camera+2 : Nintrinsics*i_camera+4,   :]
    Md = M[Nintrinsics*i_camera+4 : Nintrinsics*(i_camera+1) ,:]
    dq = nps.matmult((nps.matmult(F, Mf) +
                      nps.matmult(C, Mc) +
                      nps.matmult(D, Md) ),
                     nps.transpose(dm)).ravel()
    dq_observed = q1-q0
    print "dq got, difference: {}, {}".format(dq, dq-dq_observed)



def show_errors(how, i_camera, focus_center=None, focus_radius=0, binwidth=0.02, ignore_outliers=True, **kwargs):

    r'''Visualize the optimized reprojection errors

    This function visualizes the solution in several ways, selected by the 'how'
    argument.

      if how == 'vectorfield': we plot a vectorfield, showing each observed
                               point, and its reprojection discrepancy

      elif how == 'heatmap':   we plot each observed point, but instead of showing
                               an error vector, we render a point that's
                               color-coded with its error

      elif how == 'histogram': we show a histogram of residuals and overlay it
                               with an idealized distribution. If the
                               optimization was successful, and if
                               observed_pixel_uncertainty was correct, the two
                               should line up.

      elif how == 'radial':    Plot residuals against distance from the center. If
                               focus_center is not None, we use that; otherwise
                               we use the imager center

    i_camera is the camera in question. <0 means "all cameras"

    if ignore_outliers: we show the distribution without outliers: this is the
    default, and this is what the optimizer actually ended up optimizing.

    '''


    # I have a bunch of errors in err_including_outliers. I need to pick out
    # - the ones for THIS camera (if requested)
    # - the non-outliers         (if requested)
    #
    # The "for this camera" part is specified in indices_frame_camera. This
    # indexes FRAMES
    #
    # The "outlier" part is given by stats['outlier_indices']. This indexes
    # FEATURES (each feature is 2 measurements: x,y).
    #
    # I construct a feature index map, fill it in with both filters, and use it
    # to pull out the correct data

    # all true by default, cutting out the last dimension: x,y
    idx = np.ones( err_including_outliers.shape[:-1], dtype=bool)

    if i_camera >= 0:
        idx[indices_frame_camera[:,1] != i_camera, ...] = False
    if ignore_outliers:
        nps.clump(idx, n=3)[stats['outlier_indices']] = False

    err = err_including_outliers[idx, ...]
    obs = observations          [idx, ...]

    W,H=imagersizes[i_camera]
    if focus_center is None:
        focus_center = (imagersizes[i_camera]-1.)/2.
    if focus_radius == 0:
        # I use all the data
        pass
    else:
        if focus_radius < 0:
            focus_radius = min(imagersizes[i_camera])/6
        idx = nps.norm2(obs - focus_center) < focus_radius*focus_radius
        obs = obs[idx, ...]
        err = err[idx, ...]

    if how == 'vectorfield':
        gp.plot( obs[:,0], obs[:,1],
                 err[:,0], err[:,1],
                 np.sqrt(nps.norm2(err)),
                 _with='vectors size screen 0.005,10 fixed filled palette',
                 tuplesize=5, square=1,
                 _xrange=[0,W], yrange=[H,0],
                 title = 'Fitted reprojection errors {}. Errors shown as vectors and colors'. \
                   format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                 xlabel = 'Imager x',
                 ylabel = 'Imager y',
                 **kwargs)
    elif how == 'heatmap':
        gp.plot( obs[:,0], obs[:,1], np.sqrt(nps.norm2(err)),
                 _with='points pt 7 palette',
                 tuplesize=3, square=1,
                 _xrange=[0,W], yrange=[H,0],
                 title = 'Fitted reprojection errors {}. Errors shown as colors'. \
                   format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                 xlabel = 'Imager x',
                 ylabel = 'Imager y',
                 **kwargs)

    elif how == 'histogram':
        sigma = args.observed_pixel_uncertainty
        var   = sigma*sigma
        from scipy.special import erf
        gp.plot(err.ravel(), histogram=1, binwidth=binwidth,
                equation_above='{k}*exp(-(x-{mean})*(x-{mean})/(2.*{var})) / sqrt(2.*pi*{var}) title "Expected distribution" with lines lw 2'. \
                  format(mean= 0,
                         var = var,
                         k   = err.size*erf(binwidth/(2.*np.sqrt(2)*sigma)) * np.sqrt(2.*np.pi*var)),
                title = 'Observed and expected distribution of fitted reprojection errors {}'. \
                   format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                xlabel = 'Reprojection error (pixels). x and y components of error are counted separately',
                ylabel = 'Observed frequency',
                **kwargs)

    elif how == 'radial':
        r = np.sqrt(nps.norm2(obs - focus_center))
        gp.plot( nps.transpose(nps.cat(r,r)).ravel(),
                 err.ravel(),
                 _with='points',
                 title = 'Fitted reprojection errors shown against distance from {}. Data from {}'. \
                   format( focus_center, 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                 xlabel = 'Distance from {} (pixels)'.format(focus_center),
                 ylabel = 'Reprojection error (pixels). x and y components of error are counted separately',
                 **kwargs)

    else:
        raise Exception("Unknown visualization method '{}'. I know of 'vectorfield' and 'heatmap' and 'histogram'". \
                        format(how))


plots_intrinsics_sensitivity             = [None] * Ncameras
plots_intrinsics_sensitivity_outlierness = [None] * Ncameras
plots_roi                                = [None] * Ncameras
def show_intrinsics_uncertainty(i_camera = None, outlierness = False, gridn_x = 60, gridn_y = 40, **kwargs):

    if covariance_intrinsics_observations_only is None:
        print "No intrinsics uncertainty was computed. You need to call mrcal.optimize(..., get_invJtJ_intrinsics = True) for this to work"
        return False


    global plots_intrinsics_sensitivity
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))
    for i_camera in i_camera_all:
        plots_intrinsics_sensitivity[i_camera] = \
            mrcal.show_intrinsics_uncertainty(intrinsics[0],
                                              intrinsics[1][i_camera],
                                              covariance_intrinsics_full[i_camera] if outlierness else covariance_intrinsics_observations_only[i_camera],
                                              imagersizes  [i_camera],
                                              outlierness,
                                              extratitle = "Camera {} with {}".format(i_camera, intrinsics[0]),
                                              gridn_x=gridn_x,
                                              gridn_y=gridn_y,
                                              cbmax=5,
                                              **kwargs)

def show_roi(i_camera = None, **kwargs):
    global plots_roi
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))

    NboardPoints     = args.object_width_n*args.object_width_n
    Nfeatures        = NboardPoints*len(observations)
    feats            = observations.reshape(Nfeatures,2)

    def append_icamera(iFeatures):
        '''input: (N,) array of feature indices; output: (2,N) array of feature,camera indices)'''
        iObservations = iFeatures / NboardPoints
        iObservations = iObservations.astype(int)
        iCamera = np.array([indices_frame_camera[iObs,1] for iObs in iObservations])
        return nps.cat(iFeatures, iCamera)

    iFeature_roi_out = append_icamera(stats['outside_ROI_indices'])
    iFeature_roi_in  = append_icamera(np.setdiff1d(np.arange(Nfeatures), iFeature_roi_out[0,:]))

    for i_camera in i_camera_all:

        iFeature_roi_in_thiscam  = iFeature_roi_in [ 0, iFeature_roi_in [1,:] == i_camera]
        iFeature_roi_out_thiscam = iFeature_roi_out[ 0, iFeature_roi_out[1,:] == i_camera]

        plots_intrinsics_sensitivity_outlierness[i_camera] = \
            gp.gnuplotlib(square=1, xrange=(0,imagersizes[i_camera,0]-1),yrange=(imagersizes[i_camera,1]-1,0), _with='points pt 7 ps 2',
                          **kwargs)
        plots_intrinsics_sensitivity_outlierness[i_camera]. \
            plot( (feats[iFeature_roi_in_thiscam, 0], feats[iFeature_roi_in_thiscam, 1], dict(legend='in' )),
                  (feats[iFeature_roi_out_thiscam,0], feats[iFeature_roi_out_thiscam,1], dict(legend='out')) )

import IPython
IPython.embed()
