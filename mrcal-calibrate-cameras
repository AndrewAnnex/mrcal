#!/usr/bin/python3

r'''Calibrate some synchronized, stationary cameras

SYNOPSIS

  $ mrcal-calibrate-cameras
      --corners-cache corners.vnl
      --focal 1700 --object-spacing 0.01 --object-width-n 10
      --outdir /tmp
      --lensmodel LENSMODEL_OPENCV8
      --observed-pixel-uncertainty 0.5
      --pairs
      'left*.png' 'right*.png'

    ... lots of output as the solve runs ...
    Done!
    RMS reprojection error: 1.9 pixels
    Worst reprojection error: 7.8 pixels
    Noutliers: 319 out of 17100 total points: 1.9% of the data

    Wrote /tmp/camera0-0.cameramodel
    Wrote /tmp/camera0-1.cameramodel

This tool uses the generic mrcal platform to solve a common specific problem of
N-camera calibration using observations of a chessboard.

TUTORIAL

If all you want to do is run a calibration, read this section first.

You need to get observations of a grid of points. This tool doesn't dictate
exactly how these observations are obtained, but the recommended way to do that
is to use mrgingham (http://github.com/dkogan/mrgingham). This documentation
assumes that's what is being done.

See the mrgingham documentation for a .pdf of a chessboard pattern. This pattern
should be printed (at some size; see below) and mounted onto a RIGID and FLAT
surface to produce the calibration object. The most useful observations are
close-ups: views that cover as much of the imager as possible. Thus you
generally a large printout of the chessboard pattern. If you're calibrating a
wide lens then this is especially true: the wider the lens, the larger an object
needs to be in order to cover the field of view.

Now that we have a calibration object, this object needs to be shown to the
camera(s) to produce the images that mrgingham will use to find the corner
coordinates, which mrcal will then use in its computations.

It is important that the images contain clear corners. If the image is badly
overexposed, the white chessboard squares will bleed into each other, the
adjoining black squares will no longer touch each other in the image, and there
would be no corner to detect. Conversely, if the image is badly underexposed,
the black squares will bleed into each other, which would also destroy the
corner. mrgingham tries to handle a variety of lighting conditions, including
varying illumination across the image, but the corners must exist in the image
in some form. A fundamental design decision in mrgingham is to only output
chessboards that we are very confident in, and a consequence of this is that
mrgingham requires the WHOLE chessboard to be visible in order to produce any
results. Thus it requires a bit of effort to produce any data at the edges and
in the corners of the imager: if even a small number of the chessboard corners
are out of bounds, mrgingham will not detect the chessboard at all. A live
preview of the calibration images being gathered is thus essential to aid the
user in obtaining good data. Another requirement due to the design of mrgingham
is that the board should be held with a flat edge parallel to the camera xz
plane (parallel to the ground, usually). mrgingham looks for vertical and
horizontal sequences of corners, but if the board is rotated diagonally, then
none of these sequences are "horizontal" or "vertical", but they're all
"diagonal", which isn't what mrgingham is looking for.

The most useful observations to gather are

- close-ups: the chessboard should fill the whole frame as much as possible

- oblique views: tilt the board forward/back and left/right. I generally tilt by
  more than 45 degrees. At a certain point the corners become indistinct and
  mrgingham starts having trouble, but depending on the lens, that point could
  come with quite a bit of tilt.

- If you are calibrating multiple cameras, and they are synchronized, you can
  calibrate them all at the same time, and obtain intrinsics AND extrinsics. In
  that case you want frames where multiple cameras see the calibration object at
  the same time. Depending on the geometry, it may be impossible to place a
  calibration object in a location where it's seen by all the cameras, AND where
  it's a close-up for all the cameras at the same time. In that case, get
  close-ups for each camera individually, and get observations common to
  multiple cameras, that aren't necessarily close-ups. The former will serve to
  define your camera intrinsics, and the latter will serve to define your
  extrinsics (geometry).

A dataset composed primarily of tilted closeups will produce good results. It is
better to have more data rather than less. mrgingham will throw away frames
where no chessboard can be found, so it is perfectly reasonable to grab too many
images with the expectation that they won't all end up being used in the
computation.

I usually aim for about 100 usable frames, but you can often get away with far
fewer. The mrcal confidence feedback (see below) will tell you if you need more
data.

Once we have gathered input images, we can run the calibration procedure:

  mrcal-calibrate-cameras
    --corners-cache corners.vnl
    -j 10
    --focal 2000
    --object-spacing 0.1
    --object-width-n 10
    --outdir /tmp
    --lensmodel LENSMODEL_OPENCV8
    --observed-pixel-uncertainty 1.0
    --explore
    'frame*-camera0.png' 'frame*-camera1.png' 'frame*-camera2.png'

You would adjust all the arguments for your specific case.

The first argument says that the chessboard corner coordinates live in a file
called "corners.vnl". If this file exists, we'll use that data. If that file
does not exist (which is what will happen the first time), mrgingham will be
invoked to compute the corners from the images, and the results will be written
to that file. So the same command is used to both compute the corners initially,
and to reuse the pre-computed corners with subsequent runs.

'-j 10' says to spread the mrgingham computation across 10 CPU cores. This
command controls mrgingham only; if 'corners.vnl' already exists, this option
does nothing.

'--focal 2000' says that the initial estimate for the camera focal lengths is
2000 pixels. This doesn't need to be precise at all, but do try to get this
roughly correct if possible. Simple geometry says that

  focal_length = imager_width / ( 2 tan (field_of_view_horizontal / 2) )

--object-spacing is the width of each square in your chessboard. This depends on
the specific chessboard object you are using. --object-width-n is the corner
count of the calibration object. Currently mrgingham more or less assumes that
this is 10.

--outdir specifies the directory where the output models will be written

--lensmodel specifies which lens model we're using for the cameras.
At this time all OpenCV lens models are supported, in addition to
LENSMODEL_CAHVOR. The CAHVOR model is there for legacy compatibility only. If
you're not going to be using these models in a system that only supports CAHVOR,
there's little reason to use it. If you use a model that is too lean
(LENSMODEL_PINHOLE or LENSMODEL_OPENCV4 maybe), the model will not fit the data,
especially at the edges; the tool will tell you this. If you use a model that is
too rich (something crazy like LENSMODEL_OPENCV12), then you will need much
more data than you normally would. Most lenses I've seen work well with
LENSMODEL_OPENCV4 or LENSMODEL_OPENCV5 or LENSMODEL_OPENCV8; wider lenses
need richer models.

'--observed-pixel-uncertainty 1.0' says that the x,y corner coordinates reported
by mrgingham are distributed normally, independently, and with the standard
deviation as given in this argument. There's a tool to compute this value
empirically, but it needs more validation. For now pick a value that seems
reasonable. 1.0 pixels or less usually makes sense.

--explore says that after the models are computed, a REPL should be open so that
the user can look at various metrics describing the output; more on this
later.

After all the options, globs describing the images are passed in. Note that
these are GLOBS, not FILENAMES. So you need to quote or escape each glob to
prevent the shell from expanding it. You want one glob per camera; in the above
example we have 3 cameras. The program will look for all files matching the
globs, and filenames with identical matched strings are assumed to have been
gathered at the same instant in time. I.e. if in the above example we found
frame003-camera0.png and frame003-camera1.png, we will assume that these two
images were time-synchronized. If your capture system doesn't have
fully-functional frame syncronization, you should run a series of monocular
calibrations. Otherwise the models won't fit well (high reprojection errors
and/or high outlier counts) and you might see a frame with systematic
reprojection errors where one supposedly-synchronized camera's observation pulls
the solution in one direction, and another camera's observation pulls it in
another.

When you run the program as given above, the tool will spend a bit of time
computing (usually 10-20 seconds is enough, but this is highly dependent on the
specific problem, the amount of data, and the computational hardware). When
finished, it will write the resulting models to disk, and open a REPL (if
--explore was given). The resulting filenames are "camera-N.cameramodel" where N
is the index of the camera, starting at 0. The models contain the intrinsics and
extrinsics, with camera-0 sitting at the reference coordinate system.

When the solve is completed, you'll see a summary such as this one:

    RMS reprojection error: 0.3 pixels
    Worst reprojection error: 4.0 pixels
    Noutliers: 7 out of 9100 total points: 0.1% of the data

The reprojection errors should look reasonable given your
--observed-pixel-uncertainty. Since any outliers will be thrown out, the
reported reprojection errors will be reasonable.

Higher outlier counts are indicative of some/all of these:

- Errors in the input data, such as incorrectly-detected chessboard corners, or
  unsynchronized cameras

- Badly-fitting lens model

A lens model that doesn't fit isn't a problem in itself. The results will
simply not be reliable everywhere in the imager, as indicated by the uncertainty
and residual metrics (see below)

With --explore you get a REPL, and a message that points out some useful
functions. Generally you want to start with

    show_residuals_observation_worst(0)

This will show you the worst-fitting chessboard observation with its observed
and predicted corners, as an error vector. The reprojection errors are given by
a colored dot. Corners thrown out as outliers will be missing their colored dot.
You want to make sure that this is reasonable. Incorrectly-detected corners will
be visible: they will be outliers or they will have a high error. The errors
should be higher towards the edge of the imager, especially with a wider lens. A
richer better-fitting model would reduce those errors. Past that, there should
be no pattern to the errors. If the camera synchronization was broken, you'll
see a bias in the error vectors, to compensate for the motion of the chessboard.

Next do this for each camera in your calibration set (icam is an index counting
up from 0):

    show_residuals_regional(icam)

Each of these will pop up 3 plots describing your distribution of errors. You
get

- a plot showing the mean reprojection error across the imager
- a plot showing the standard deviation of reprojection errors across the imager
- a plot showing the number of data points across the imager AFTER the outlier
  rejection

The intrinsics are reliable in areas that have

- a low mean error relative to --observed-pixel-uncertainty
- a standard deviation roughly similar to --observed-pixel-uncertainty
- have some data available

If you have too little data, you will be overfitting, so you'd be expalining the
signal AND the noise, and your reprojection errors will be too low. With enough
input data you'll be explaining the signal only: the noise is random and with
enough samples our model can't explain it. Another factor that controls this is
the model we're fitting. If we fit a richer model (LENSMODEL_OPENCV8 vs
LENSMODEL_OPENCV4 for instance), the extra parameters will allow us to fit the
data better, and to produce lower errors in more areas of the imager.

These are very rough guidelines; I haven't written the logic to automatically
interpret these yet. A common feature that these plots bring to light is a
poorly-fitting model at the edges of the imager. In that case you'll see higher
errors with a wider distribution towards the edge.

Finally run this:

    show_projection_uncertainty()

This will pop up a plot of projection uncertainties for each camera. The
uncertainties are shown as a color-map along with contours. These are the
expected value of projection based on noise in input corner observations. The
noise is assumed to be independent, 0-mean gaussian with a standard deviation of
--observed-pixel-uncertainty. You will see low uncertainties in the center of
the imager (this is the default focus point; a different one can be picked). As
you move away from the center, you'll see higher errors. You should decide how
much error is acceptable, and determine the usable area of the imager based on
this. These uncertainty metrics are complementary to the residual metrics
described above. If you have too little data, the residuals will be low, but the
uncertainties will be very high. The more data you gather, the lower the
uncertainties. A richer lens model lowers the residuals, but raises the
uncertainties. So with a richer model you need to get more data to get to the
same acceptable uncertainty level.

'''

import sys
import argparse
import re
import os

def parse_args():

    def positive_float(string):
        try:
            value = float(string)
        except:
            raise argparse.ArgumentTypeError("argument MUST be a positive floating-point number. Got '{}'".format(string))
        if value <= 0:
            raise argparse.ArgumentTypeError("argument MUST be a positive floating-point number. Got '{}'".format(string))
        return value
    def positive_int(string):
        try:
            value = int(string)
        except:
            raise argparse.ArgumentTypeError("argument MUST be a positive integer. Got '{}'".format(string))
        if value <= 0 or abs(value-float(string)) > 1e-6:
            raise argparse.ArgumentTypeError("argument MUST be a positive integer. Got '{}'".format(string))
        return value


    parser = \
        argparse.ArgumentParser(description = __doc__,
                                formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--focal',
                        type=float,
                        help='Initial estimate of the focal length, in pixels. Required unless --seed is given')
    parser.add_argument('--imagersize',
                        nargs=2,
                        type=int,
                        required=False,
                        help='''Size of the imager. This is only required if we pass --corners-cache AND if
                        none of the image files on disk actually exist and if we
                        don't have a --seed. If we do have a --seed, the
                        --imagersize values must match the --seed exactly''')
    parser.add_argument('--outdir',
                        type=lambda d: d if os.path.isdir(d) else \
                                parser.error("--outdir requires an existing directory as the arg, but got '{}'".format(d)),
                        default='.',
                        help='Directory for the output camera models')
    parser.add_argument('--object-spacing',
                        required=False,
                        type=float,
                        help='Width of each square in the calibration board, in meters')
    parser.add_argument('--object-width-n',
                        type=int,
                        default=10,
                        help='''How many points the calibration board has per horizontal side. If omitted we
                        default to 10''')
    parser.add_argument('--object-height-n',
                        type=int,
                        help='''How many points the calibration board has per vertical side. If omitted, we
                        assume a square object, setting height=width''')
    parser.add_argument('--lensmodel',
                        required=False,
                        help='''Which lens model we're using. This is required unless we have a
                        --seed''')
    parser.add_argument('--seed',
                        required=False,
                        type=str,
                        help='''A comma-separated whitespace-less list of camera model globs to use as a seed
                        for the intrinsics and extrinsics. The number of models
                        must match the number of cameras exactly. Expanded globs
                        are sorted alphanumerically. This is useful to bootstrap
                        the solve or to validate an existing set of models, or
                        to recompute just the extrinsics or just the intrinsics
                        of a solve. If omitted, we estimate a seed. Exclusive
                        with --focal. If given, --imagersize is omitted or it
                        must match EXACTLY with whatever is in the --seed
                        models''')
    parser.add_argument('--jobs', '-j',
                        type=int,
                        default=1,
                        help='''How much parallelization we want. Like GNU make. Affects only the chessboard
                        corner finder. If we are reading a cache file, this does nothing''')
    parser.add_argument('--corners-cache',
                        type=lambda f: f if os.path.isfile(f) or not os.path.isdir(f) else \
                                parser.error("--corners-cache requires an existing, readable file as the arg or a non-existing path, but got '{}'".format(f)),
                        required=False,
                        help='Path to read corner-finder data from or (if path does not exist) to write data to')
    parser.add_argument('--pairs',
                        action='store_true',
                        help='''By default, we are calibrating a set of N independent cameras. If we actually
                        have a number of stereo pairs, pass this argument. It
                        changes the filename format of the models written to
                        disk (cameraPAIR-INDEXINPAIR.cameramodel), and will
                        report some uncertainties about geometry inside each
                        pair. Consecutive cameras in the given list are paired
                        up, and an even number of cameras is required''')
    parser.add_argument('--skip-regularization',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we apply regularization in the solver in the final optimization.
                        This discourages obviously-wrong solutions, but can
                        introduce a bias. With this option, regularization isn't
                        applied''')
    parser.add_argument('--skip-outlier-rejection',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we throw out outliers. This option turns that off''')
    parser.add_argument('--skip-extrinsics-solve',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''Keep the seeded extrinsics, if given. Allowed only if --seed''')
    parser.add_argument('--skip-intrinsics-solve',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''Keep the seeded intrinsics, if given. Allowed only if --seed''')
    parser.add_argument('--skip-calobject-warp-solve',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we assume the calibration target is slightly deformed, and we
                        compute this deformation. If we want to assume that it
                        is flat, pass this option.''')

    parser.add_argument('--unweighted-corners',
                        action='store_true',
                        help='''By default we weight each corner error contribution using the uncertainty
                        from the corner detector. If we want to ignore this
                        information, and weigh them all equally, pass
                        --unweighted-corners.''')

    parser.add_argument('--valid-intrinsics-region-parameters',
                        nargs = 5,
                        default = (1, 0.5, 1.5, 3, 0),
                        type = float,

                        help='''For convenience we compute a valid-intrinsics region to describe the results
                        of the calibration. This is a watered-down
                        interpretation of the projection uncertainty that is
                        easy to interpret. The logic computing this is somewhat
                        crude, and may go away in the future. The defaults
                        should be reasonable, so if in doubt, leave these alone.
                        The intent is to produce usable output even if we're
                        using a lean lens model where the computed uncertainty
                        is always overly optimistic. We bin the observations
                        into a grid, and use report_residual_statistics() to get
                        the residual statistics in each bin. We then contour the
                        bins to produce the valid-intrinsics region. If we're
                        using a rich lens model (LENSMODEL_SPLINED_...), then we
                        only look at the uncertainty, and not at the other
                        statistics. This argument takes 5 parameters. The
                        uncertainty is computed at a range
                        valid_intrinsics_region_parameters[4]. If <= 0, I look
                        out to infinity. The default is 0. A region is valid
                        only if the projection uncertainty <
                        valid_intrinsics_region_parameters[0] *
                        observed_pixel_uncertainty. The default is 1. A region
                        is valid only if the mean-abs-residuals is <
                        valid_intrinsics_region_parameters[1] (only for lean
                        models). The default is 0.5. A region is valid only if
                        the residuals stdev is <
                        valid_intrinsics_region_parameters[2] *
                        observed_pixel_uncertainty (only for lean models). The
                        default is 1.5. A region is valid only if it contains at
                        least valid_intrinsics_region_parameters[3] observations
                        (only for lean models). The default is 3.''')

    parser.add_argument('--verbose-solver',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default the final stage of the solver doesn't say much. This option turns
                        on verbosity to get lots of diagnostics.''')

    parser.add_argument('--explore',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''After the solve open an interactive shell to examine the solution''')
    parser.add_argument('--observed-pixel-uncertainty',
                        type=positive_float,
                        required=True,
                        help='''The standard deviation of x and y pixel coordinates of the input
                        observations. The distribution of the inputs is assumed
                        to be gaussian, with the standard deviation specified by
                        this argument. Note: this is the x and y standard
                        deviation, treated independently. If each of these is s,
                        then the LENGTH of the deviation of each pixel is a
                        Rayleigh distribution with expected value s*sqrt(pi/2) ~
                        s*1.25''')

    parser.add_argument('images',
                        type=str,
                        nargs='+',
                        help='''A glob-per-camera for the images. Include a glob for each camera. It is
                        assumed that the image filenames in each glob are of of
                        the form xxxNNNyyy where xxx and yyy are common to all
                        images in the set, and NNN varies. This NNN is a frame
                        number, and identical frame numbers across different
                        globs signify a time-synchronized observation. I.e. you
                        can pass 'left*.jpg' and 'right*.jpg' to find images
                        'left0.jpg', 'left1.jpg', ..., 'right0.jpg',
                        'right1.jpg', ...''')

    return parser.parse_args()

args = parse_args()

# arg-parsing is done before the imports so that --help works without building
# stuff, so that I can generate the manpages and README


if args.object_spacing is None:
    print("WARNING: assuming default calibration-object spacing of 0.1m. If this is wrong, all distances will be off by a scale factor",
          file = sys.stdderr)
    args.object_spacing = 0.1

if args.object_height_n is None:
    args.object_height_n = args.object_width_n




import numpy as np
import scipy.linalg
import numpysane as nps
import cv2
import copy
import time
import glob

import mrcal

# wider printing is more convenient here
np.set_printoptions(linewidth=300)


def get_imagersize_one(icamera, indices_frame_camera, paths, args_imagersize, seedmodels):
    r'''Returns the imager size for a given camera

    This reports the size for ONE camera. I only look at the first match. It is
    assumed that all the images matching this glob have the same imager size.

    If I have a corners cache, then this is the ONLY place where I'd need the
    images on disk at all. If the user passes --imagersize, then I really don't
    need the images.

    '''
    if args_imagersize is not None:
        return args_imagersize
    if seedmodels is not None:
        return seedmodels[icamera].imagersize()

    try:
        iobservation0_thiscamera = next( i for i in range(len(paths)) if indices_frame_camera[i,1] == icamera )
    except:
        raise Exception("Couldn't find any images for camera '{}'".format(icamera))

    img = cv2.imread(paths[iobservation0_thiscamera])
    if img is None:
        raise Exception("I needed to read '{}' to get an imagersize, but couldn't open it, and get image dimensions from it. Make the images findable, or pass --imagersize". \
                        format(paths[iobservation0_thiscamera]))
    h,w = img.shape[:2]

    return [w,h]


def make_cameramodels(optimization_inputs):
    r'''Assemble cameramodels from a completed calibration

    The calibration routines treat the intrinsics and extrinsics for all cameras
    as a vector. This routine converts those to a list of mrcal.cameramodel
    structures that can be fed to all the other routines.

    '''
    return [ mrcal.cameramodel( \
                optimization_inputs = optimization_inputs,
                icam_intrinsics     = icam ) \

             for icam in range(len(optimization_inputs['intrinsics'])) ]


def solve_initial(args, seedmodels, imagersizes,
                  observations, indices_frame_camera):
    '''Solve an incrementally-expanding optimization problem in several passes

    observations[...,2] start out as the initial outlier set, and are modified
    by this function to represent the expanded outlier set

    '''

    Ncameras = len(args.images)
    indices_frame_camintrinsics_camextrinsics = \
        nps.glue(indices_frame_camera,
                 indices_frame_camera[:,(1,)]-1,
                 axis=-1)

    if seedmodels is None:
        # I have no seed. I compute a rough seed, and run a few preliminary,
        # incremental optimizations to get it reasonably-close to the right
        # answer
        intrinsics_data,extrinsics_rt_fromref,frames_rt_toref = \
            mrcal.make_seed_pinhole(imagersizes          = imagersizes,
                                    focal_estimate       = args.focal,
                                    indices_frame_camera = indices_frame_camera,
                                    observations         = observations,
                                    object_spacing       = args.object_spacing)

        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv initial solve: geometry only\n")
        lensmodel = 'LENSMODEL_STEREOGRAPHIC'
        stats = mrcal.optimize(intrinsics_data, extrinsics_rt_fromref, frames_rt_toref, None,
                               observations, indices_frame_camintrinsics_camextrinsics,
                               None, None,
                               lensmodel,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsics_core       = False,
                               do_optimize_intrinsics_distortions= False,
                               do_optimize_calobject_warp        = False,
                               calibration_object_spacing        = args.object_spacing,
                               do_apply_outlier_rejection        = False,
                               do_apply_regularization           = False,
                               verbose                           = False)
        sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n\n".format(stats['rms_reproj_error__pixels']))

        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv initial solve: geometry and intrinsic core only\n")
        stats = mrcal.optimize(intrinsics_data, extrinsics_rt_fromref, frames_rt_toref, None,
                               observations, indices_frame_camintrinsics_camextrinsics,
                               None, None,
                               lensmodel,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsics_core       = True,
                               do_optimize_intrinsics_distortions= False,
                               do_optimize_calobject_warp        = False,
                               calibration_object_spacing        = args.object_spacing,
                               do_apply_outlier_rejection        = False,
                               do_apply_regularization           = False,
                               verbose                           = False)
        sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n".format(stats['rms_reproj_error__pixels']))

        extrinsics_Rt_fromref = mrcal.Rt_from_rt( extrinsics_rt_fromref )

    else:

        # The caller made sure that all the models use the same lens model
        lensmodel = seedmodels[0].intrinsics()[0]
        intrinsics_data  = nps.cat( *[m.intrinsics()[1] for m in seedmodels])

        # I keep the relative camera poses constant, but place camera0 at the
        # origin
        Rt_r0 = seedmodels[0].extrinsics_Rt_toref()
        extrinsics_Rt_fromref = \
            nps.cat( *[ mrcal.compose_Rt( m.extrinsics_Rt_fromref(),Rt_r0)
                        for m in seedmodels[1:]])

        # I have a GOOD extrinsics estimate, so I could compute a GOOD frame
        # pose estimate by triangulating:
        #
        #   import deltapose_lite
        #   for corresponding images:
        #       for points in chessboard:
        #           lindstrom to get point in 3d
        #           procrustes fit to get frame transformation
        #
        # But this takes a lot of typing, and wouldn't handle special cases:
        # - what if for a given frame only 1 camera is observing the board?
        # - what if for a given frame more than 2 cameras are observing the board?
        #
        # So I do the less-accurate-but-more-robust thing using pinhole
        # monocular observations. This is what mrcal.make_seed_pinhole()
        # does in the no-seed-available case
        calobject_poses_local_Rt_cf = \
            mrcal.estimate_monocular_calobject_poses_Rt_tocam( indices_frame_camera,
                                                               observations,
                                                               args.object_spacing,
                                                               seedmodels)
        frames_rt_toref = \
            mrcal.estimate_joint_frame_poses(
                calobject_poses_local_Rt_cf, extrinsics_Rt_fromref,
                indices_frame_camera,
                args.object_width_n,args.object_height_n,
                args.object_spacing)

    def expand_intrinsics(lensmodel, intrinsics_data):
        NnewDistortions = \
            mrcal.lensmodel_num_params(lensmodel) - \
            intrinsics_data.shape[1]
        newDistortions = \
            (np.random.random((Ncameras, NnewDistortions)) - 0.5)*2. *1e-6
        m = re.search("OPENCV([0-9]+)", lensmodel)
        if m:
            Nd = int(m.group(1))
            if Nd >= 8:
                # Push down the rational components of the seed. I'd like these all to
                # sit at 0 ideally. The radial distortion in opencv is x_distorted =
                # x*scale where r2 = norm2(xy - xyc) and
                #
                # scale = (1 + k0 r2 + k1 r4 + k4 r6)/(1 + k5 r2 + k6 r4 + k7 r6)
                #
                # Note that k2,k3 are tangential (NOT radial) distortion components.
                # Note that the r6 factor in the numerator is only present for
                # >=LENSMODEL_OPENCV5. Note that the denominator is only present for >=
                # LENSMODEL_OPENCV8. The danger with a rational model is that it's
                # possible to get into a situation where scale ~ 0/0 ~ 1. This would
                # have very poorly behaved derivatives. If all the rational coefficients
                # are ~0, then the denominator is always ~1, and this problematic case
                # can't happen. I favor that.
                newDistortions[5:8] *= 1e-3
        return nps.glue( intrinsics_data, newDistortions, axis=-1 )


    # Alrighty. All the preliminary business is finished. I should have a usable
    # seed now. And thus I now run the main optimization loop
    lensmodel = args.lensmodel
    intrinsics_data  = expand_intrinsics(lensmodel, intrinsics_data)

    print("=================== optimizing everything{}from seeded intrinsics". \
          format(" except board warp " if not args.skip_calobject_warp_solve else " "))

    extrinsics_rt_fromref = mrcal.rt_from_Rt(extrinsics_Rt_fromref)

    # splined models have a core, but those variables are largely redundant with
    # the spline parameters. So I run another pre-solve to get reasonable values
    # for the core, and then I lock it down
    do_optimize_intrinsics_core = not args.skip_intrinsics_solve
    if re.match("LENSMODEL_SPLINED_STEREOGRAPHIC_", lensmodel):
        do_optimize_intrinsics_core = False

    optimization_inputs = \
        dict( intrinsics                                = intrinsics_data,
              extrinsics_rt_fromref                     = extrinsics_rt_fromref,
              frames_rt_toref                           = frames_rt_toref,
              points                                    = None,
              observations_board                        = observations,
              indices_frame_camintrinsics_camextrinsics = indices_frame_camintrinsics_camextrinsics,
              observations_point                        = None,
              indices_point_camintrinsics_camextrinsics = None,
              lensmodel                                 = lensmodel,
              imagersizes                               = imagersizes,
              calobject_warp                            = None,
              do_optimize_intrinsics_core               = do_optimize_intrinsics_core,
              do_optimize_intrinsics_distortions        = not args.skip_intrinsics_solve,
              do_optimize_extrinsics                    = not args.skip_extrinsics_solve,
              do_optimize_frames                        = True,
              do_optimize_calobject_warp                = False,
              calibration_object_spacing                = args.object_spacing,
              do_apply_outlier_rejection                = not args.skip_outlier_rejection,
              observed_pixel_uncertainty                = args.observed_pixel_uncertainty,
              do_apply_regularization                   = True,
              verbose                                   = False)

    mrcal.optimize( **optimization_inputs )
    return optimization_inputs







# expand ~/ into $HOME/
args.images = [os.path.expanduser(g) for g in args.images]

Ncameras = len(args.images)
if Ncameras > 10:
    raise Exception("Got {} image globs. It should be one glob per camera, and this sounds like WAY too make cameras. Did you forget to escape your glob?". \
                    format(Ncameras))

if args.pairs and Ncameras % 2:
    raise Exception("With --pairs I must have gotten an even number of cameras, but instead got {}".format(Ncameras))

if args.seed:

    if args.focal:
        raise Exception("Exactly one of --focal and --seed MUST be given")


    def seedmodels_iterator():
        for g in args.seed.split(','):
            globbed_filenames = sorted(glob.glob(g))
            if 0 == len(globbed_filenames):
                raise Exception("seed glob '{}' matched no files!".format(g))
            for f in globbed_filenames:
                yield mrcal.cameramodel(f)
    seedmodels = list(seedmodels_iterator())

    if Ncameras != len(seedmodels):
        raise Exception("I saw {} image globs, but {} --seed models. Both represent cameras, so I should have identical counts". \
                        format(Ncameras, len(seedmodels)))

    if args.imagersize is not None:
        for m in seedmodels:
            if args.imagersize != m.imagersize():
                raise Exception("Both --seed and --imagersize were given, so they must match exactly. But I had --imagersize {} and one model has imagersize() = {}". \
                                format(args.imagersize, m.imagersize()))
    lensmodel = seedmodels[0].intrinsics()[0]
    for m in seedmodels[1:]:
        if lensmodel != m.intrinsics()[0]:
            raise Exception("I expect all cameras to use the same lens model, but --seed saw {} and {}". \
                            format(lensmodel,
                                   m.intrinsics()[0]))

    if args.lensmodel is None:
        args.lensmodel = lensmodel


else:
    if not args.focal:
        raise Exception("Exactly one of --focal and --seed MUST be given")

    if not args.lensmodel:
        raise Exception("--lensmodel is required if no --seed")

    if args.skip_extrinsics_solve:
        raise Exception("--skip-extrinsics-solve requires --seed")
    if args.skip_intrinsics_solve:
        raise Exception("--skip-intrinsics-solve requires --seed")

    seedmodels = None



observations, indices_frame_camera, paths = \
    mrcal.compute_chessboard_corners(args.object_width_n,
                                     args.object_height_n,
                                     args.images,
                                     args.corners_cache,
                                     jobs = args.jobs,
                                     weighted = not args.unweighted_corners)

Nobservations = len(observations)

# list of imager sizes; one per camera
imagersizes = np.array([get_imagersize_one(icamera,
                                           indices_frame_camera,
                                           paths,
                                           args.imagersize,
                                           seedmodels) for icamera in range(Ncameras)],
                       dtype=np.int32)

optimization_inputs = \
    solve_initial(args, seedmodels,
                  imagersizes,
                  observations, indices_frame_camera)

if not args.skip_calobject_warp_solve:
    calobject_warp = np.array((0,0), dtype=float)
else:
    calobject_warp = None

print("vvvvvvvvvvvvvvvvvvvv final, full re-optimization call to get board warp",
      file=sys.stderr)

optimization_inputs['calobject_warp']             = calobject_warp
optimization_inputs['do_optimize_calobject_warp'] = not args.skip_calobject_warp_solve
optimization_inputs['do_apply_regularization']    = not args.skip_regularization
optimization_inputs['observed_pixel_uncertainty'] = args.observed_pixel_uncertainty
optimization_inputs['do_apply_outlier_rejection'] = not args.skip_outlier_rejection
optimization_inputs['verbose']                    = args.verbose_solver

# If we're skipping the regularization step, I do EVERYTHING else before the
# final regularization-free step. Turning that off allows the solution to
# wander, and I want to help it as much as possible to not do that
if not optimization_inputs['do_apply_regularization']:
    optimization_inputs['do_apply_regularization']= True
    optimization_inputs['verbose']                = False

    stats = mrcal.optimize(**optimization_inputs)

    optimization_inputs['do_apply_regularization']= False
    optimization_inputs['verbose']                = args.verbose_solver

stats = mrcal.optimize(**optimization_inputs)
sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n".format(stats['rms_reproj_error__pixels']))

report = "RMS reprojection error: {:.01f} pixels\n".format(stats['rms_reproj_error__pixels'])

Npoints_chessboard = args.object_width_n*args.object_height_n*Nobservations

# shape (Nobservations,Nheight,Nwidth,2)
measurements_0_for_outliers = \
    stats['x'][:Npoints_chessboard*2]. \
    reshape(Nobservations, args.object_height_n, args.object_width_n, 2)
worst_point_err = np.sqrt(np.max(nps.norm2( nps.clump(measurements_0_for_outliers, n=3) )))
report += "Worst reprojection error (by measurement): {:.01f} pixels\n".format(worst_point_err)
if not args.skip_outlier_rejection:
    report += "Noutliers: {} out of {} total points: {:.01f}% of the data\n". \
        format(stats['Noutliers'],
               args.object_height_n*args.object_width_n*len(observations),
               100.0 * stats['Noutliers'] / (args.object_height_n*args.object_width_n*len(observations)))
if calobject_warp is not None:
    report += "calobject_warp = {}\n".format(calobject_warp)

print(report)

models = make_cameramodels(optimization_inputs)



# shape (Nobservations,Nheight,Nwidth)
non_outlier_mask = np.ones( (Nobservations,
                             args.object_height_n,
                             args.object_width_n), dtype=bool)
non_outlier_mask[observations[...,2] < 0.0] = False
non_outliers_per_observation = np.sum( nps.clump(non_outlier_mask, n=-2).astype(int),
                                       axis=-1)

# shape (Nobservations,)
rms_measurements_0_for_outliers_perobservation   = \
    np.sqrt( nps.norm2( nps.clump(measurements_0_for_outliers,n=-3) ) /
             non_outliers_per_observation )


i_observations_worst    = list(reversed(np.argsort(rms_measurements_0_for_outliers_perobservation)))
i_observation_from_path = dict( [(paths[_i],_i) for _i in range(len(observations))] )





def report_residual_statistics( icamera,
                                observations,
                                error,
                                indices_frame_camera,
                                imagersize,
                                gridn_width  = 20,
                                gridn_height = None):

    r'''Reports fit statistics for regions across the imager

SYNOPSIS

    print( observations.shape )
    ===> (101, 9, 10, 3)

    print( error.shape )
    ===> (18180,)

    mean, stdev, count, using = \
        mrcal.report_residual_statistics(icamera,
                                         observations,
                                         error,
                                         indices_frame_camera,
                                         imagersize,
                                         gridn_width = 30)

    import gnuplotlib as gp
    W,H = imagersize
    gp.plot( np.abs(mean),
             tuplesize = 3,
             _with     = 'image',
             ascii     = True,
             square    = True,
             using     = using)

The mrcal solver optimizes reprojection errors for ALL the observations in ALL
cameras at the same time. It is useful to evaluate the optimal solution by
examining reprojection errors in subregions of the imager, which is accomplished
by this function. All the observations and reprojection errors and subregion
gridding are given. The mean and standard derivation of the reprojection errors
and a point count are returned for each subregion cell. A "using" expression for
plotting is reported as well.

After a problem-free solve, the error distributions in each area of the imager
should be similar, and should match the error distribution of the pixel
observations. If the lens model doesn't fit the data, the statistics will not be
consistent across the region: the residuals would be heteroscedastic.

ARGUMENTS

- icamera: the index of the camera we're looking at. I select the observations
  and errors for this camera only by consulting the observations indicated by
  indices_frame_camera

- observations: an array of shape (Nobservations, calibration_object_height_n,
  calibration_object_width_n, 3) of observed points. Each row is an (x,y,weight)
  tuple. weight<=0 means "outlier". This function ignores those. I flatten the
  leading dimensions. This is optimization_inputs["observations_board"]

- error: an array of measurement errors corresponding to each row in the
  "observations". Trailing elements are ignored (there are generally the points
  or regularization terms). This is the array of errors reported by the
  optimization

- indices_frame_camera is an (N,2) array of contiguous, sorted integers where
  each observation is (index_frame,index_camera). Each row corresponds to the
  leading dimension of observations

- imagersize: a len-2 iterable: width,height of the imager. With a
  mrcal.cameramodel object this is model.imagersize()

- gridn_width: how many points along the horizontal gridding dimension

- gridn_height: how many points along the vertical gridding dimension. If None,
  we compute an integer gridn_height to maintain a square-ish grid:
  gridn_height/gridn_width ~ imager_height/imager_width

RETURNED VALUES

This function returns a tuple

- mean: an array of shape (gridn_height,gridn_width). Contains the mean of
  the residuals in the corresponding cell

- stdev: an array of shape (gridn_height,gridn_width). Contains the standard
  deviation of the residuals in the corresponding cell

- count: an array of shape (gridn_height,gridn_width). Contains the count of
  observations in the corresponding cell

- using: is a "using" keyword for plotting the output matrices with gnuplotlib.
  See the docstring for imagergrid_using() for details

    '''

    W,H=imagersize

    if gridn_height is None:
        gridn_height = int(round(H/W*gridn_width))

    # shape: (Nheight,Nwidth,2). Contains (x,y) rows
    q_cell_center = mrcal.sample_imager(gridn_width, gridn_height, W, H)

    wcell = float(W-1) / (gridn_width -1)
    hcell = float(H-1) / (gridn_height-1)
    rcell = np.array((wcell,hcell), dtype=float) / 2.

    @nps.broadcast_define( (('N',2), ('N',2), (2,)),
                           (3,) )
    def stats(q, err, q_cell_center):
        r'''Compute the residual statistics in a single cell

        '''

        # boolean (x,y separately) map of observations that are within a cell
        idx = np.abs(q - q_cell_center) < rcell

        # join x,y: both the x,y must be within a cell for the observation to be
        # within a cell
        idx = idx[:,0] * idx[:,1]

        err = err[idx, ...].ravel()
        if len(err) <= 5:
            # we have too little data in this cell
            return np.array((0.,0.,len(err)))

        mean   = np.mean(err)
        stdev  = np.std(err)
        return np.array((mean,stdev,len(err)))


    Nobs,Nh,Nw = observations.shape[:3]
    error = error[:Nobs*Nh*Nw*2].reshape(Nobs,Nh,Nw,2)

    iobservation = (indices_frame_camera[:,1] == icamera)

    # shape (N,3)
    observations = nps.clump(observations[iobservation,...], n=3)

    # shape (N,)
    weight       = observations[:, 2]
    # shape (N,2)
    observations = observations[:,:2]
    error        = nps.clump(error[iobservation,:], n=3)

    # ignore outliers
    idx = weight>0
    observations = observations[idx, :]
    error        = error       [idx, :]

    # Each has shape (Nheight,Nwidth)
    mean,stdev,count = nps.mv( stats(observations, error, q_cell_center),
                               -1, 0)
    return mean,stdev,count,mrcal.imagergrid_using(imagersize, gridn_width, gridn_height)


def get_valid_intrinsics_region(model, icam):
    r'''Returns the valid-intrinsics region for camera icam

This is a closed contour, in an (N,2) numpy array. None means "no
valid-intrinsics region computed". An empty array of shape (0,2) means "the
region was computed and it is empty"

    '''

    if args.skip_intrinsics_solve or args.valid_intrinsics_region_parameters is None:
        return None

    gridn_width,gridn_height = 30,20

    # Each has shape (Nheight,Nwidth)
    mean,stdev,count,using = \
        report_residual_statistics(icam,
                                   observations,
                                   stats['x'],
                                   indices_frame_camera,
                                   model.imagersize(),
                                   gridn_width  = gridn_width,
                                   gridn_height = gridn_height)

    q    = mrcal.sample_imager( gridn_width, gridn_height, *model.imagersize() )
    pcam = mrcal.unproject(q, *model.intrinsics(),
                           normalize = True)

    if args.valid_intrinsics_region_parameters[4] <= 0:
        atinfinity = True
    else:
        atinfinity = False
        pcam *= args.valid_intrinsics_region_parameters[4]

    uncertainty = mrcal.projection_uncertainty(pcam,
                                               model      = model,
                                               atinfinity = atinfinity,
                                               what       = 'worstdirection-stdev' )

    # shape (Nheight,Nwidth).
    im = \
        (uncertainty < args.valid_intrinsics_region_parameters[0] * args.observed_pixel_uncertainty)

    if not re.match('LENSMODEL_SPLINED_', model.intrinsics()[0]):
        im *= \
            (mean        < args.valid_intrinsics_region_parameters[1]) * \
            (stdev       < args.valid_intrinsics_region_parameters[2] * args.observed_pixel_uncertainty) * \
            (count       > args.valid_intrinsics_region_parameters[3])

    # I compute the contour. OpenCV can't process binary images, so I need
    # to convert to a different image type first. AND findContours() reports
    # the coordinates in the opposite order as how they're given (image is
    # given as y,x; returned coords are x,y). This is what I want, but feels
    # conterintuitive

    # This is a hoaky mess. I ignore all the topological corner cases, and just
    # grab the contour with the biggest area
    contours = \
        cv2.findContours(im.astype(np.uint8),
                         cv2.RETR_EXTERNAL,
                         cv2.CHAIN_APPROX_SIMPLE)[-2]

    areas = np.array([ cv2.contourArea(c) for c in contours ])
    contour = contours[np.argmax(areas)][:,0,:].astype(float)

    contour = mrcal.close_contour(contour)
    if contour.ndim != 2 or contour.shape[0] < 4:
        # I have a closed contour, so the only way for it to not be
        # degenerate is to include at least 4 points
        return np.zeros((0,2)) # empty valid-intrinsics region

    # I convert the contours back to the full-res image coordinate. The grid
    # mapping is based on the corner pixels
    W,H = model.imagersize()
    contour[:,0] *= float(W-1)/(gridn_width -1)
    contour[:,1] *= float(H-1)/(gridn_height-1)

    return contour.round().astype(np.int32)





for i in range(Ncameras):
    models[i].valid_intrinsics_region(get_valid_intrinsics_region(models[i], i))


# The note says how we ran this, and contains the commented-out report
note = \
    "generated on {} with   {}\n".format(time.strftime("%Y-%m-%d %H:%M:%S"),
                                           ' '.join(mrcal.shellquote(s) for s in sys.argv)) + \
    re.sub(r"^(.)", r"# \1", report, flags=re.M)
for icam in range(len(models)):

    filename_base = \
        '{}/camera{}-{}'.format(args.outdir, icam//2, icam%2) \
        if args.pairs \
        else '{}/camera-{}'.format(args.outdir, icam)

    cameramodelfile = filename_base + '.cameramodel'
    models[icam].write(cameramodelfile, note)
    print("Wrote {}".format(cameramodelfile))



if not args.explore:
    sys.exit(0)



# We're exploring!
import gnuplotlib as gp


print(r'''Solution-examination REPL.
Potential things to look at:

    show_geometry()
    show_residuals_observation_worst(i_observation_in_order_from_worst)
    show_residuals_observation(i_observation, vectorscale=20)
    show_projection_uncertainty(icam)
    show_projection_uncertainty_xydist(icam)
    show_valid_intrinsics_region(icam)
    show_residuals_vectorfield(    icam)
    show_residuals_heatmap(        icam)
    show_residuals_directions(     icam)
    show_residuals_histogram(      icam)
    show_residuals_radial(         icam)
    show_residuals_regional(       icam)
    show_distortion_off_pinhole('heatmap',    icam)
    show_distortion_off_pinhole('vectorfield',icam)
    show_distortion_off_pinhole('radial',     icam)
    show_splined_model_surface(    icam, xy)
    stats
    i_observations_worst
    rms_measurements_0_for_outliers_perobservation
    paths[i_observations_worst[0]]
    calobject_warp
''')



def show_residuals_observation(i_observation, vectorscale = 1.0, **kwargs):
    r'''Visualize calibration residuals for a single observation

    Given a single observation, plots the chessboard image overlaid with its
    residuals. Each residual is plotted as a circle, color-coded by the error
    size, and with a vector showing the error itself. If a point was thrown out
    as an outlier, the vector is shown, but the circle is omitted.

    The observation is given in the first argument as either an integer
    (observation index) or a string (path).

    Usually the errors are small, and hard to see. So for legibility the error
    vectors can be scaled up by passing in a 'vectorscale' argument.

    All kwargs are passed on to the gnuplotlib constructor to control the
    generated plot.

    '''

    if isinstance(i_observation, (int,np.integer)):
        pass # already have the observation index
    elif isinstance(i_observation, str):
        i_observation = i_observation_from_path[i_observation]
    else:
        raise Exception(f"i_observation should be a string (image path) or an integer; got type(i_observation) = {type(i_observation)}")



    object_ref = \
        mrcal.transform_point_rt( optimization_inputs['frames_rt_toref'][iframe],
                                  mrcal.ref_calibration_object(args.object_width_n,
                                                               args.object_height_n,
                                                               args.object_spacing,
                                                               optimization_inputs['calobject_warp']) )
    if icam == 0:
        object_cam = object_ref
    else:
        object_cam =  \
            mrcal.transform_point_rt( optimization_inputs['extrinsics_rt_fromref'][icam-1],
                                      object_ref )
    # shape (Nheight*Nwidth, 2)
    q_hypothesis = \
        nps.clump( mrcal.project( object_cam,
                                  optimization_inputs['lensmodel'],
                                  optimization_inputs['intrinsics'][icam] ),
                   n = 2 )

    # shape (Nheight*Nwidth, 2)
    obs         = nps.clump( observations[i_observation, ..., :2], n=2)
    iframe,icam = indices_frame_camera[i_observation]

    # Residual per point. These may or may not have been thrown out as outliers.
    # And these may have been scaled in the measurement vector
    err = q_hypothesis - obs


    # non_outlier_mask[i_observation] is dtype=bool, shape=(Nheight,Nwidth), so I
    # can use it as an index. measurements_0_for_outliers has shape
    # (Nobservations,Nheight,Nwidth,2)
    # This thing has shape (Nvalidpoints,2)
    measurements_no_outliers = \
        measurements_0_for_outliers[i_observation,
                                    non_outlier_mask[i_observation],
                                    :]
    obs_ignoring_outliers = obs[non_outlier_mask[i_observation].ravel(), :]

    imagepath = paths[i_observation]
    plotkwargs = \
        dict(square=1,cbmin=0,
             title='{}: i_observation={}, iframe={}, icam={}, path={}, RMS_error={:.2f}'. \
               format( args.lensmodel,
                       i_observation, iframe, icam,
                       paths[i_observation],
                       rms_measurements_0_for_outliers_perobservation[i_observation]),
             **kwargs)
    if os.path.isfile(imagepath):
        # only plot an image overlay if the image exists
        plotkwargs['rgbimage'] = imagepath
        plotkwargs['_set']     = 'autoscale noextend'
    else:
        W,H=imagersizes[icam]
        plotkwargs['xrange'] = [0,W-1]
        plotkwargs['yrange'] = [H-1,0]

    gp.plot( # points. weights. throwing out outliers
             (obs_ignoring_outliers[:,0], obs_ignoring_outliers[:,1], np.sqrt(nps.norm2(measurements_no_outliers)),
              dict(_with     = 'points pt 7 ps 2 palette',
                   legend    = 'fitted residual',
                   tuplesize = 3)),

             # vectors. unweighted reprojection errors. Including outliers
             (obs[:,0], obs[:,1], vectorscale*err[:,0], vectorscale*err[:,1],
              dict(_with     = 'vectors size screen 0.01,20 fixed filled lw 2',
                   legend    = 'observed',
                   tuplesize = 4)),

             **plotkwargs)


def show_residuals_observation_worst(i, **kwargs):
    show_residuals_observation( i_observations_worst[i], **kwargs )

def _get_show_residuals_data(icam):
    r'''Return the data used by the various show_residuals_...() functions'''


    # all true by default, cutting out the last dimension: x,y
    idx = np.ones( observations.shape[:-1], dtype=bool)
    idx[indices_frame_camera[:,1] != icam, ...] = False

    idx[ observations[...,2] < 0.0 ] = False
    err = measurements_0_for_outliers[idx, ...]

    obs = observations[idx, ..., :2]

    legend = "Valid-intrinsics region"
    valid_region = models[icam].valid_intrinsics_region()

    if valid_region.size == 0:
        valid_region = np.zeros((1,2))
        legend += ": empty"

    valid_intrinsics_region_plotarg_3d = \
        (valid_region[:,0],
         valid_region[:,1],
         np.zeros(valid_region.shape[-2]),
         dict(_with  = 'lines lw 3',
              legend = legend))
    valid_intrinsics_region_plotarg_2d = \
        (valid_region[:,0],
         valid_region[:,1],
         dict(_with  = 'lines lw 3',
              legend = legend))

    return err,obs,valid_intrinsics_region_plotarg_2d,valid_intrinsics_region_plotarg_3d


plots_residuals_vectorfield = None
def show_residuals_vectorfield(icam = 0,
                               vectorscale = 1.0,
                               **kwargs):

    r'''Visualize the optimized residuals as a vector field

    We plot a vectorfield, showing each observed point, and its reprojection
    discrepancy

    icam is the camera in question. First camera by default

    '''

    global plots_residuals_vectorfield
    if plots_residuals_vectorfield is None:
        plots_residuals_vectorfield = [None] * Ncameras

    err,obs, \
    valid_intrinsics_region_plotarg_2d, \
    valid_intrinsics_region_plotarg_3d = \
        _get_show_residuals_data(icam)

    W,H = imagersizes[icam]
    plots_residuals_vectorfield[icam] = \
        gp.gnuplotlib( square=1,
                       _xrange=[0,W], yrange=[H,0],
                       title = 'Fitted residuals. Errors shown as vectors and colors',
                       xlabel = 'Imager x',
                       ylabel = 'Imager y',
                       **kwargs)
    plot_data_args = [(obs[:,0], obs[:,1],
                       vectorscale*err[:,0], vectorscale*err[:,1],
                       np.sqrt(nps.norm2(err)),
                       dict(_with='vectors size screen 0.01,20 fixed filled palette',
                            tuplesize=5))]
    if valid_intrinsics_region_plotarg_2d is not None:
        plot_data_args.append(valid_intrinsics_region_plotarg_2d)
    plots_residuals_vectorfield[icam].plot(*plot_data_args)

plots_residuals_heatmap = None
def show_residuals_heatmap(icam = 0,
                           vectorscale = 1.0,
                           **kwargs):

    r'''Visualize the optimized residuals as a heat map

    We plot each observed point, but instead of showing an error vector, we
    render a point that's color-coded with its error

    icam is the camera in question. First camera by default

    '''

    global plots_residuals_heatmap
    if plots_residuals_heatmap is None:
        plots_residuals_heatmap = [None] * Ncameras

    err,obs, \
    valid_intrinsics_region_plotarg_2d, \
    valid_intrinsics_region_plotarg_3d = \
        _get_show_residuals_data(icam)

    W,H = imagersizes[icam]
    plots_residuals_heatmap[icam] = \
        gp.gnuplotlib( square=1,
                       _xrange=[0,W], yrange=[H,0],
                       title = 'Fitted residuals. Errors shown as colors',
                       xlabel = 'Imager x',
                       ylabel = 'Imager y',
                       **kwargs)
    plot_data_args = [( obs[:,0], obs[:,1], np.sqrt(nps.norm2(err)),
                        dict(_with='points pt 7 palette',
                             tuplesize=3))]
    if valid_intrinsics_region_plotarg_2d is not None:
        plot_data_args.append(valid_intrinsics_region_plotarg_2d)
    plots_residuals_heatmap[icam].plot(*plot_data_args)

plots_residuals_directions = None
def show_residuals_directions(icam = 0,
                              vectorscale = 1.0,
                              **kwargs):

    r'''Visualize the optimized residuals as color-coded directions

    We plot each observed point, but instead of showing an error vector, we show
    the color-coded direction of the error. The error magnitude is ignored. This
    is useful to see systematic patterns in the error surface

    icam is the camera in question. First camera by default

    '''


    global plots_residuals_directions
    if plots_residuals_directions is None:
        plots_residuals_directions = [None] * Ncameras

    err,obs, \
    valid_intrinsics_region_plotarg_2d, \
    valid_intrinsics_region_plotarg_3d = \
        _get_show_residuals_data(icam)

    W,H = imagersizes[icam]
    plots_residuals_directions[icam] = \
        gp.gnuplotlib( square=1,
                       _xrange=[0,W], yrange=[H,0],
                       title = 'Fitted residuals. Directions shown as colors. Magnitudes ignored',
                       xlabel = 'Imager x',
                       ylabel = 'Imager y',

                       # Use an maximum-saturation, maximum-value HSV
                       # palette where the hue encodes the error direction.
                       # The direction is periodic, as is the hue
                       _set='palette defined ( 0 "#00ffff", 0.5 "#80ffff", 1 "#ffffff") model HSV',
                       cbrange = [-180., 180.],
                       **kwargs)
    plot_data_args = [( obs[:,0], obs[:,1], 180./np.pi * np.arctan2(err[...,1], err[...,0]),
                        dict(_with='points pt 7 palette',
                             tuplesize=3))]
    if valid_intrinsics_region_plotarg_2d is not None:
        plot_data_args.append(valid_intrinsics_region_plotarg_2d)
    plots_residuals_directions[icam].plot(*plot_data_args)

plots_residuals_radial = None
def show_residuals_radial(icam = 0, **kwargs):

    r'''Visualize the optimized residuals, looking at distance-from-center

    Plot residuals against distance from the center. icam is the camera in
    question. First camera by default

    '''

    global plots_residuals_radial
    if plots_residuals_radial is None:
        plots_residuals_radial = [None] * Ncameras

    err,obs, \
    valid_intrinsics_region_plotarg_2d, \
    valid_intrinsics_region_plotarg_3d = \
        _get_show_residuals_data(icam)

    r = np.sqrt(nps.norm2(obs - (imagersizes[icam]-1.)/2.))
    plots_residuals_radial[icam] = \
        gp.gnuplotlib(
            title = 'Fitted residuals shown against distance from the center',
            xlabel = 'Distance from the center (pixels)',
            ylabel = 'Residual (pixels). x and y components of error are counted separately',
            **kwargs)
    plots_residuals_radial[icam]. \
        plot( nps.transpose(nps.cat(r,r)).ravel(),
              err.ravel(),
              _with='points')


plots_residuals_regional = None
def show_residuals_regional(icam = 0, **kwargs):

    r'''Visualize the optimized residuals, broken up by region

    Plots residuals grouped by discrete regions of the image. Useful to see
    specifically where the fit is poor

    icam is the camera in question. First camera by default

    '''

    global plots_residuals_regional
    if plots_residuals_regional is None:
        plots_residuals_regional = [None] * Ncameras

    err,obs, \
    valid_intrinsics_region_plotarg_2d, \
    valid_intrinsics_region_plotarg_3d = \
        _get_show_residuals_data(icam)


    # Each has shape (Nheight,Nwidth)
    mean,stdev,count,using = \
        report_residual_statistics(icam,
                                   observations,
                                   stats['x'],
                                   indices_frame_camera,
                                   imagersizes[icam])
    def mkplot(x, title, **kwargs_here):
        kwargs_here.update(kwargs)
        if 'hardcopy' in kwargs_here:
            what = re.sub('[^a-zA-Z0-9_-]+', '_', title)
            kwargs_here['hardcopy'] = re.sub(r'(\.[^\.]+$)', '.' + what + r'\1', kwargs_here['hardcopy'])

        W,H = imagersizes[icam]
        p = gp.gnuplotlib( _3d=1,
                           ascii=1,
                           unset='grid',
                           _xrange=[0,W], _yrange=[H,0],
                           _set = ['xrange [:] noextend',
                                   'yrange [:] noextend reverse',
                                   'view equal xy',
                                   'view map'],
                           title = title,
                           **kwargs_here)
        plot_data_args = [( x,
                            dict(tuplesize=3,
                                 _with='image',
                                 using=using))]
        if valid_intrinsics_region_plotarg_3d is not None:
            plot_data_args.append(valid_intrinsics_region_plotarg_3d)
        p.plot(*plot_data_args)
        return p

    plots_residuals_regional[icam] = [ mkplot(np.abs(mean), 'abs(mean)'),
                                           mkplot(stdev,        'stdev'),
                                           mkplot(count,        'count', cbrange = (0, 20)) ]


plots_residuals_histogram = None
def show_residuals_histogram(icam = 0, binwidth=0.02,
                             **kwargs):

    r'''Visualize the histogram of the optimized residuals

    We show a histogram of residuals and overlay it with an idealized
    distribution. If the optimization was successful, and if
    observed_pixel_uncertainty was correct, the two should line up.

    icam is the camera in question. First camera by default

    '''

    global plots_residuals_histogram
    if plots_residuals_histogram is None:
        plots_residuals_histogram = [None] * Ncameras

    err,obs, \
    valid_intrinsics_region_plotarg_2d, \
    valid_intrinsics_region_plotarg_3d = \
        _get_show_residuals_data(icam)

    x = err.ravel()
    N = len(x)

    sigma_expected = args.observed_pixel_uncertainty
    sigma_observed = np.std(x)
    from scipy.special import erf

    def make_gaussian(sigma,title):
        # I want to plot a PDF of a normal distribution together with the
        # histogram to get a visual comparison. This requires a scaling on
        # either the PDF or the histogram. I plot a scaled pdf:
        #
        #   f = k*pdf = k * exp(-x^2 / (2 s^2)) / sqrt(2*pi*s^2)
        #
        # I match up the size of the central bin of the histogram (-binwidth/2,
        # binwidth/2):
        #
        #   bin(0) ~ k*pdf(0) ~ pdf(0) * N * binwidth
        #
        # So k = N*binwdith should work. I can do this more precisely:
        #
        #   bin(0) ~ k*pdf(0) ~
        #     = N * integral( pdf(x) dx,                                -binwidth/2, binwidth/2)
        #     = N * integral( exp(-x^2 / (2 s^2)) / sqrt( 2*pi*s^2) dx, -binwidth/2, binwidth/2)
        # ->k = N * integral( exp(-x^2 / (2 s^2)) / sqrt( 2*pi*s^2) dx, -binwidth/2, binwidth/2) / pdf(0)
        #     = N * integral( exp(-x^2 / (2 s^2)) dx,                   -binwidth/2, binwidth/2)
        #     = N * integral( exp(-(x/(sqrt(2) s))^2) dx )
        #
        # Let u  = x/(sqrt(2) s)
        #     du = dx/(sqrt(2) s)
        #     u(x = binwidth/2) = binwidth/(s 2sqrt(2)) ->
        #
        #   k = N * sqrt(2) s * integral( exp(-u^2) du )
        #     = N*sqrt(2pi) s * erf(binwidth / (s 2*sqrt(2)))
        #
        # for low x erf(x) ~ 2x/sqrt(pi). So if binwidth << sigma
        # k = N*sqrt(2pi) s * erf(binwidth / (s 2*sqrt(2)))
        #   ~ N*sqrt(2pi) s * (binwidth/(s 2*sqrt(2))) *2 / sqrt(pi)
        #   ~ N binwidth
        return \
            '{k}*exp(-(x-{mean})*(x-{mean})/(2.*{var})) / sqrt(2.*pi*{var}) title "{title}" with lines lw 2'. \
            format(mean= 0,
                   var = sigma*sigma,
                   title = title,
                   k   = N * np.sqrt(2.*np.pi) * sigma * erf(binwidth/(2.*np.sqrt(2)*sigma)))

    equations = [make_gaussian(sigma,title) for sigma,title in \
                 ( (sigma_expected, 'Normal distribution of residuals with expected stdev: {:.02f} pixels'.format(sigma_expected)),
                   (sigma_observed, 'Normal distribution of residuals with observed stdev: {:.02f} pixels'.format(sigma_observed)))]
    plots_residuals_histogram[icam] = \
        gp.gnuplotlib(equation_above = equations,
                      title = 'Observed and expected distribution of fitted residuals',
                      xlabel = 'Residuals (pixels). x and y components of error are counted separately',
                      ylabel = 'Observed frequency',
                      **kwargs)
    plots_residuals_histogram[icam].plot(x, histogram=1, binwidth=binwidth,)


plots_projection_uncertainty = [None] * Ncameras
def show_projection_uncertainty(icam = None, gridn_width = 60, gridn_height = 40, **kwargs):

    global plots_projection_uncertainty
    icam_all = (icam,) if icam is not None else range(Ncameras)
    for icam in icam_all:
        plots_projection_uncertainty[icam] = \
            mrcal.show_projection_uncertainty(models[icam],
                                              extratitle = "Camera {} with {}".format(icam, args.lensmodel),
                                              gridn_width  = gridn_width,
                                              gridn_height = gridn_height,
                                              **kwargs)
plots_projection_uncertainty_xydist = [None] * Ncameras
def show_projection_uncertainty_xydist(icam = None, gridn_width = 15, gridn_height = 10, **kwargs):

    global plots_projection_uncertainty_xydist
    icam_all = (icam,) if icam is not None else range(Ncameras)
    for icam in icam_all:
        plots_projection_uncertainty_xydist[icam] = \
            mrcal.show_projection_uncertainty_xydist(models[icam],
                                                     extratitle = "Camera {} with {}".format(icam, args.lensmodel),
                                                     gridn_width  = gridn_width,
                                                     gridn_height = gridn_height,
                                                     **kwargs)
plots_valid_intrinsics_region = [None] * Ncameras
def show_valid_intrinsics_region(icam = None, **kwargs):
    global plots_valid_intrinsics_region
    icam_all = (icam,) if icam is not None else range(Ncameras)
    for icam in icam_all:
        plots_valid_intrinsics_region[icam] = \
            mrcal.show_valid_intrinsics_region(models[icam],
                                               title = "Valid-intrinsics region for camera {}".format(icam),
                                               **kwargs)

plots_distortion_off_pinhole = [None] * Ncameras
def show_distortion_off_pinhole(mode, icam = None, gridn_width = 60, gridn_height = 40, **kwargs):

    global plots_distortion_off_pinhole
    icam_all = (icam,) if icam is not None else range(Ncameras)
    for icam in icam_all:
        plots_distortion_off_pinhole[icam] = \
            mrcal.show_distortion_off_pinhole(models[icam],
                                              mode,
                                              extratitle = "camera {}".format(icam),
                                              gridn_width  = gridn_width,
                                              gridn_height = gridn_height,
                                              **kwargs)

plots_splined_model_surface = [None] * Ncameras
def show_splined_model_surface(icam = None, xy='x', **kwargs):

    global plots_splined_model_surface
    icam_all = (icam,) if icam is not None else range(Ncameras)
    for icam in icam_all:
        plots_splined_model_surface[icam] = \
            mrcal.show_splined_model_surface(models[icam], xy,
                                             extratitle = "camera {}".format(icam),
                                             **kwargs)

plot_calibration_geometry = None
def show_geometry(**kwargs):
    global plot_calibration_geometry
    plot_calibration_geometry = \
        mrcal.show_geometry(models,
                            cameranames = [f"camera {i}" for i in range(len(models))])

import IPython
IPython.embed()
