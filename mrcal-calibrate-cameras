#!/usr/bin/python3

r'''Calibrate some synchronized cameras

SYNOPSIS

  $ mrcal-calibrate-cameras
      --corners-cache corners.vnl
      --focal 1700 --object-spacing 0.01 --object-width-n 10
      --outdir /tmp
      --lensmodel LENSMODEL_OPENCV8
      --observed-pixel-uncertainty 0.5
      --pairs
      'left*.png' 'right*.png'

    ... lots of output as the solve runs ...
    Done!
    RMS reprojection error: 1.9 pixels
    Worst reprojection error: 7.8 pixels
    Noutliers: 319 out of 17100 total points: 1.9% of the data

    Wrote /tmp/camera0-0.cameramodel
    Wrote /tmp/camera0-1.cameramodel

This tool uses the generic mrcal platform to solve a common specific problem of
N-camera calibration using observations of a chessboard.


TUTORIAL

If all you want to do is run a calibration, read this section first.

You need to get observations of a grid of points. This tool doesn't dictate
exactly how these observations are obtained, but the recommended way to do that
is to use mrgingham (http://github.com/dkogan/mrgingham). This documentation
assumes that's what is being done.

See the mrgingham documentation for a .pdf of a chessboard pattern. This pattern
should be printed (at some size; see below) and mounted onto a RIGID and FLAT
surface to produce the calibration object. The most useful observations are
close-ups: views that cover as much of the imager as possible. Thus you
generally a large printout of the chessboard pattern. If you're calibrating a
wide lens then this is especially true: the wider the lens, the larger an object
needs to be in order to cover the field of view.

Now that we have a calibration object, this object needs to be shown to the
camera(s) to produce the images that mrgingham will use to find the corner
coordinates, which mrcal will then use in its computations.

It is important that the images contain clear corners. If the image is badly
overexposed, the white chessboard squares will bleed into each other, the
adjoining black squares will no longer touch each other in the image, and there
would be no corner to detect. Conversely, if the image is badly underexposed,
the black squares will bleed into each other, which would also destroy the
corner. mrgingham tries to handle a variety of lighting conditions, including
varying illuination across the image, but the corners must exist in the image in
some form. A fundamental design decision in mrgingham is to only output
chessboards that we are very confident in, and a consequence of this is that
mrgingham requires the WHOLE chessboard to be visible in order to produce any
results. Thus it requires a bit of effort to produce any data at the edges and
in the corners of the imager: if even a small number of the chessboard corners
are out of bounds, mrgingham will not detect the chessboard at all. A live
preview of the calibration images being gathered is thus essential to aid the
user in obtaining good data. Another requirement due to the design of mrgingham
is that the board should be held with a flat edge parallel to the camera xz
plane (parallel to the ground, usually). mrgingham looks for vertical and
horizontal sequences of corners, but if the board is rotated in this way, then
none of these sequences are "horizontal" or "vertical", but they're all
"diagonal", which isn't what mrgingham is looking for.

The most useful observations to gather are

- close-ups: the chessboard should fill the whole frame as much as possible

- oblique views: tilt the board forward/back and left/right. I generally tilt by
  more than 45 degrees. At a certain point the corners become indistinct and
  mrgingham starts having trouble, but depending on the lens, that point could
  come with quite a bit of tilt.

- If you are calibrating multiple cameras, and they are synchronized, you can
  calibrate them all at the same time, and obtain intrinsics AND extrinsics. In
  that case you want frames where multiple cameras see the calibration object at
  the same time. Depending on the geometry, it may be impossible to place a
  calibration object in a location where it's seen by all the cameras, AND where
  it's a close-up for all the cameras at the same time. In that case, get
  close-ups for each camera individually, and get observations common to
  multiple cameras, that aren't necessarily close-ups. The former will serve to
  define your camera intrinsics, and the latter will serve to define your
  extrinsics (geometry).

A dataset composed primarily of tilted closeups will produce good results. It is
better to have more data rather than less. mrgingham will throw away frames
where no chessboard can be found, so it is perfectly reasonable to grab too many
images with the expectation that they won't all end up being used in the
computation.

I usually aim for about 100 usable frames, but you can often get away with far
fewer. The mrcal confidence feedback (see below) will tell you if you need more
data.

Once we have gathered input images, we can run the calibration procedure:

  mrcal-calibrate-cameras
    --corners-cache corners.vnl
    -j 10
    --focal 2000
    --object-spacing 0.1
    --object-width-n 10
    --outdir /tmp
    --lensmodel LENSMODEL_OPENCV8
    --observed-pixel-uncertainty 1.0
    --explore
    'frame*-camera0.png' 'frame*-camera1.png' 'frame*-camera2.png'

You would adjust all the arguments for your specific case.

The first argument says that the chessboard corner coordinates live in a file
called "corners.vnl". If this file exists, we'll use that data. If that file
does not exist (which is what will happen the first time), mrgingham will be
invoked to compute the corners from the images, and the results will be written
to that file. So the same command is used to both compute the corners initially,
and to reuse the pre-computed corners with subsequent runs.

'-j 10' says to spread the mrgingham computation across 10 CPU cores. This
command controls mrgingham only; if 'corners.vnl' exists, this option does
nothing.

'--focal 2000' says that the initial estimate for the camera focal lengths is
2000 pixels. This doesn't need to be precise at all, but do try to get this
roughly correct if possible. Simple geometry says that

  focal_length = imager_width / ( 2 tan (field_of_view_horizontal / 2) )

--object-spacing is the width of each square in your chessboard. This depends on
the specific chessboard object you are using. --object-width-n is the corner
count of the calibration object. Currently mrgingham more or less assumes that
this is 10.

--outdir specifies the directory where the output models will be written

--lensmodel specifies which lens model we're using for the cameras.
At this time all OpenCV lens models are supported, in addition to
LENSMODEL_CAHVOR. The CAHVOR model is there for legacy compatibility only. If
you're not going to be using these models in a system that only supports CAHVOR,
there's little reason to use it. If you use a model that is too lean
(LENSMODEL_PINHOLE or LENSMODEL_OPENCV4 maybe), the model will not fit the data,
especially at the edges; the tool will tell you this. If you use a model that is
too rich (something crazy like LENSMODEL_OPENCV14), then you will need much
more data than you normally would. Most lenses I've seen work well with
LENSMODEL_OPENCV4 or LENSMODEL_OPENCV5 or LENSMODEL_OPENCV8; wider lenses
need richer models.

'--observed-pixel-uncertainty 1.0' says that the x,y corner coordinates reported
by mrgingham are distributed normally, independently, and with the standard
deviation as given in this argument. There's a tool to compute this value
empirically, but it needs more validation. For now pick a value that seems
reasonable. 1.0 pixels or less usually makes sense.

--explore says that after the models are computed, a REPL should be open so that
the user can look at various metrics describing the output; more on this
later.

After all the options, globs describing the images are passed in. Note that
these are GLOBS, not FILENAMES. So you need to quote or escape each glob to
prevent the shell from expanding it. You want one glob per camera; in the above
example we have 3 cameras. The program will look for all files matching the
globs, and filenames with identical matched strings are assumed to have been
gathered at the same instant in time. I.e. if in the above example we found
frame003-camera0.png and frame003-camera1.png, we will assume that these two
images were time-synchronized. If your capture system doesn't have
fully-functional frame syncronization, you should run a series of monocular
calibrations. Otherwise the models won't fit well (high reprojection errors
and/or high outlier counts) and you might see a frame with systematic
reprojection errors where one supposedly-synchronized camera's observation pulls
the solution in one direction, and another camera's observation pulls it in
another.

When you run the program as given above, the tool will spend a bit of time
computing (usually 10-20 seconds is enough, but this is highly dependent on the
specific problem, the amount of data, and the computational hardware). When
finished, it will write the resulting models to disk, and open a REPL (if
--explore was given). The resulting filenames are "camera-N.cameramodel" where N
is the index of the camera, starting at 0. The models contain the intrinsics and
extrinsics, with camera-0 sitting at the reference coordinate system.

When the solve is completed, you'll see a summary such as this one:

    RMS reprojection error: 0.3 pixels
    Worst reprojection error: 4.0 pixels
    Noutliers: 7 out of 9100 total points: 0.1% of the data

The reprojection errors should look reasonable given your
--observed-pixel-uncertainty. Since any outliers will be thrown out, the
reported reprojection errors will be reasonable.

Higher outlier counts are indicative of some/all of these:

- Errors in the input data, such as incorrectly-detected chessboard corners, or
  unsynchronized cameras

- Badly-fitting lens model

A lens model that doesn't fit isn't a problem in itself. The results will
simply not be reliable everywhere in the imager, as indicated by the uncertainty
and residual metrics (see below)

With --explore you get a REPL, and a message that points out some useful
functions. Generally you want to start with

    show_residuals_observation_worst(0)

This will show you the worst-fitting chessboard observation with its observed
and predicted corners, as an error vector. The reprojection errors are given by
a colored dot. Corners thrown out as outliers will be missing their colored dot.
You want to make sure that this is reasonable. Incorrectly-detected corners will
be visible: they will be outliers or they will have a high error. The errors
should be higher towards the edge of the imager, especially with a wider lens. A
richer better-fitting model would reduce those errors. Past that, there should
be no pattern to the errors. If the camera synchronization was broken, you'll
see a bias in the error vectors, to compensate for the motion of the chessboard.

Next do this for each camera in your calibration set (i_camera is an index
counting up from 0):

    show_residuals_regional(i_camera)

Each of these will pop up 3 plots describing your distribution of errors. You
get

- a plot showing the mean reprojection error across the imager
- a plot showing the standard deviation of reprojection errors across the imager
- a plot showing the number of data points across the imager AFTER the outlier
  rejection

The intrinsics are reliable in areas that have

- a low mean error relative to --observed-pixel-uncertainty
- a standard deviation roughly similar to --observed-pixel-uncertainty
- have some data available

If you have too little data, you will be overfitting, so you'd be expalining the
signal AND the noise, and your reprojection errors will be too low. With enough
input data you'll be explaining the signal only: the noise is random and with
enough samples our model can't explain it. Another factor that controls this is
the model we're fitting. If we fit a richer model (LENSMODEL_OPENCV8 vs
LENSMODEL_OPENCV4 for instance), the extra parameters will allow us to fit the
data better, and to produce lower errors in more areas of the imager.

These are very rough guidelines; I haven't written the logic to automatically
interpret these yet. A common feature that these plots bring to light is a
poorly-fitting model at the edges of the imager. In that case you'll see higher
errors with a wider distribution towards the edge.

Finally run this:

    show_intrinsics_uncertainty()

This will pop up a plot of projection uncertainties for each camera. The
uncertainties are shown as a color-map along with contours. These are the
expected value of projection based on noise in input corner observations. The
noise is assumed to be independent, 0-mean gaussian with a standard deviation of
--observed-pixel-uncertainty. You will see low uncertainties in the center of
the imager (this is the default focus point; a different one can be picked). As
you move away from the center, you'll see higher errors. You should decide how
much error is acceptable, and determine the usable area of the imager based on
this. These uncertainty metrics are complementary to the residual metrics
described above. If you have too little data, the residuals will be low, but the
uncertainties will be very high. The more data you gather, the lower the
uncertainties. A richer lens model lowers the residuals, but raises the
uncertainties. So with a richer model you need to get more data to get to the
same acceptable uncertainty level. The uncertainties are all determined relative
to some focus point. If you care about the calibration accuracy in a particular
area of the imager, do something like this instead:

    show_intrinsics_uncertainty( focus_center = np.array((1000,2000))) )

'''

from __future__ import print_function

import sys
import argparse
import re
import os

def parse_args():

    def positive_float(string):
        try:
            value = float(string)
        except:
            raise argparse.ArgumentTypeError("argument MUST be a positive floating-point number. Got '{}'".format(string))
        if value <= 0:
            raise argparse.ArgumentTypeError("argument MUST be a positive floating-point number. Got '{}'".format(string))
        return value
    def positive_int(string):
        try:
            value = int(string)
        except:
            raise argparse.ArgumentTypeError("argument MUST be a positive integer. Got '{}'".format(string))
        if value <= 0 or abs(value-float(string)) > 1e-6:
            raise argparse.ArgumentTypeError("argument MUST be a positive integer. Got '{}'".format(string))
        return value


    parser = \
        argparse.ArgumentParser(description = __doc__,
                                formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--focal',
                        type=float,
                        help='Initial estimate of the focal length, in pixels. Required unless --seed is given')
    parser.add_argument('--imagersize',
                        nargs=2,
                        type=int,
                        required=False,
                        help='''Size of the imager. This is only required if we pass --corners-cache AND if
                        none of the image files on disk actually exist and if we
                        don't have a --seed. If we do have a --seed, the
                        --imagersize values must match the --seed exactly''')
    parser.add_argument('--outdir',
                        type=lambda d: d if os.path.isdir(d) else \
                                parser.error("--outdir requires an existing directory as the arg, but got '{}'".format(d)),
                        default='.',
                        help='Directory for the output camera models')
    parser.add_argument('--object-spacing',
                        required=False,
                        type=float,
                        help='Width of each square in the calibration board, in meters')
    parser.add_argument('--object-width-n',
                        type=int,
                        default=10,
                        help='How many points the calibration board has per side')
    parser.add_argument('--lensmodel',
                        required=False,
                        help='''Which lens model we're using. This is required unless we have a
                        --seed''')
    parser.add_argument('--roi',
                        nargs=4,
                        type=float,
                        action='append',
                        required=False,
                        help='''Region of interest of the calibration. This is the area in the imager we're
                        interested in. Errors in observations outside this area
                        will be attenuated significantly. If we want to use all
                        the data evenly, omit this argument. Otherwise pass 4
                        values for each --roi:
                        (x_center,y_center,x_radius,y_radius). The region is an
                        axis-aligned ellipsoid. If passing in ANY roi, you MUST
                        pass in the ROI for EACH camera; a separate '--roi' for
                        each one.''')
    parser.add_argument('--incremental',
                        required=False,
                        default=False,
                        action='store_true',
                        help='''THIS IS HIGHLY EXPERIMENTAL; maybe don't use it yet. If passed, we
                        incrementally increase ROI and lens model
                        complexity across multiple solves. In this mode the
                        requested ROI is a target, and the requested distortion
                        model is the upper bound. If we can get away with a
                        simpler one, we use that.''')
    parser.add_argument('--seed',
                        required=False,
                        type=str,
                        help='''A comma-separated whitespace-less list of camera model globs to use as a seed
                        for the intrinsics and extrinsics. The number of models
                        must match the number of cameras exactly. Expanded globs
                        are sorted alphanumerically. This is useful to bootstrap
                        the solve or to validate an existing set of models, or
                        to recompute just the extrinsics or just the intrinsics
                        of a solve. If omitted, we estimate a seed. Exclusive
                        with --focal. If given, --imagersize is omitted or it
                        must match EXACTLY with whatever is in the --seed
                        models''')
    parser.add_argument('--num-cross-validation-splits',
                        required=False,
                        default=1,
                        type=positive_int,
                        help='''If passed, we cross-validate the results with this many splits. This only
                        makes sense as an integer >1. THIS IS EXPERIMENTAL.''')
    parser.add_argument('--jobs', '-j',
                        type=int,
                        default=1,
                        help='''How much parallelization we want. Like GNU make. Affects only the chessboard
                        corner finder. If we are reading a cache file, this does nothing''')
    parser.add_argument('--corners-cache',
                        type=lambda f: f if os.path.isfile(f) or not os.path.isdir(f) else \
                                parser.error("--corners-cache requires an existing, readable file as the arg or a non-existing path, but got '{}'".format(f)),
                        required=False,
                        help='Path to read corner-finder data from or (if path does not exist) to write data to')
    parser.add_argument('--pairs',
                        action='store_true',
                        help='''By default, we are calibrating a set of N independent cameras. If we actually
                        have a number of stereo pairs, pass this argument. It
                        changes the filename format of the models written to
                        disk (cameraPAIR-INDEXINPAIR.cameramodel), and will
                        report some uncertainties about geometry inside each
                        pair. Consecutive cameras in the given list are paired
                        up, and an even number of cameras is required''')

    parser.add_argument('--skip-regularization',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we apply regularization to the solver. This option turns that
                        off''')
    parser.add_argument('--skip-outlier-rejection',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we throw out outliers. This option turns that off''')
    parser.add_argument('--skip-extrinsics-solve',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''Keep the seeded extrinsics, if given. Allowed only if --seed''')
    parser.add_argument('--skip-intrinsics-solve',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''Keep the seeded intrinsics, if given. Allowed only if --seed''')

    parser.add_argument('--unweighted-corners',
                        action='store_true',
                        help='''By default we weight each corner error contribution using information from
                        mrgingham. If we want to ignore this information, and
                        weigh them all the same, pass --unweighted-corners.''')

    parser.add_argument('--verbose-solver',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default the final stage of the solver doesn't say much. This option turns
                        on verbosity to get lots of diagnostics.''')

    parser.add_argument('--optimize-calobject-warp',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we assume the calibration target is flat. If it isn't and we want
                        to compute it, pass this option.''')

    parser.add_argument('--explore',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''After the solve open an interactive shell to examine the solution''')
    parser.add_argument('--observed-pixel-uncertainty',
                        type=positive_float,
                        required=True,
                        help='''The standard deviation of x and y pixel coordinates of the input
                        observations. The distribution of the inputs is assumed
                        to be gaussian, with the standard deviation specified by
                        this argument. Note: this is the x and y standard
                        deviation, treated independently. If each of these is s,
                        then the LENGTH of the deviation of each pixel is a
                        Rayleigh distribution with expected value s*sqrt(pi/2) ~
                        s*1.25''')

    parser.add_argument('images',
                        type=str,
                        nargs='+',
                        help='''A glob-per-camera for the images. Include a glob for each camera. It is
                        assumed that the image filenames in each glob are of of
                        the form xxxNNNyyy where xxx and yyy are common to all
                        images in the set, and NNN varies. This NNN is a frame
                        number, and identical frame numbers across different
                        globs signify a time-synchronized observation. I.e. you
                        can pass 'left*.jpg' and 'right*.jpg' to find images
                        'left0.jpg', 'left1.jpg', ..., 'right0.jpg',
                        'right1.jpg', ...''')

    parser.add_argument('--cull-points-left-of',
                        required=False,
                        default=-1,
                        type=float,
                        help='''For testing. Throw out all observations with x < the given value''')
    parser.add_argument('--cull-points-rad-off-center',
                        required=False,
                        default=-1,
                        type=float,
                        help='''For testing. Throw out all observations with dist_from_center > the given
                        value''')
    parser.add_argument('--cull-random-observations-ratio',
                        required=False,
                        default=-1,
                        type=float,
                        help='''For testing. Throw out a random number of board observations. The ratio of
                        observations is given as the argument. 1.0 = throw out
                        ALL the observations; 0.0 = throw out NONE of the
                        observations''')



    return parser.parse_args()

args = parse_args()

# arg-parsing is done before the imports so that --help works without building
# stuff, so that I can generate the manpages and README


if args.object_spacing is None:
    sys.stderr.write("Warning: assuming default calibration-object spacing of 0.1m. If this is wrong, all distances will be off by a scale factor\n")
    args.object_spacing = 0.1





import numpy as np
import scipy.linalg
import numpysane as nps
import cv2
import copy
import time
import glob

import mrcal

# wider printing is more convenient here
np.set_printoptions(linewidth=300)


def get_imagersize_one(icamera, indices_frame_camera, paths, args_imagersize, seedmodels):
    r'''Returns the imager size for a given camera

    This reports the size for ONE camera. I only look at the first match. It is
    assumed that all the images matching this glob have the same imager size.

    If I have a corners cache, then this is the ONLY place where I'd need the
    images on disk at all. If the user passes --imagersize, then I really don't
    need the images.

    '''
    if args_imagersize is not None:
        return args_imagersize
    if seedmodels is not None:
        return seedmodels[icamera].imagersize()

    try:
        iobservation0_thiscamera = next( i for i in range(len(paths)) if indices_frame_camera[i,1] == icamera )
    except:
        raise Exception("Couldn't find any images for camera '{}'".format(icamera))

    try:
        img = cv2.imread(paths[iobservation0_thiscamera]);
        h,w = img.shape[:2]
    except:
        raise Exception("I needed to read '{}' to get an imagersize, but couldn't open it, and get image dimensions from it. Make the images findable, or pass --imagersize". \
                        format(paths[iobservation0_thiscamera]))

    return [w,h]


def make_cameramodel(i_camera, intrinsics, extrinsics, imagersizes,
                     observed_pixel_uncertainty,
                     covariance_intrinsics,
                     valid_intrinsics_region = None):
    r'''Assemble one cameramodel from a completed calibration

    The calibration routines treat the intrinsics and extrinsics for all cameras
    as a vector. This routine converts a single camera to a mrcal.cameramodel
    structure that can be fed to all the other routines.

    '''

    if i_camera >= 1:
        rt_x0 = extrinsics[i_camera-1,:].ravel()
    else:
        rt_x0 = np.zeros(6)
    Rt_rx = mrcal.invert_Rt( mrcal.Rt_from_rt(rt_x0))

    if covariance_intrinsics is not None:
        covariance_intrinsics = covariance_intrinsics[i_camera, ...]
    if valid_intrinsics_region is not None:
        valid_intrinsics_region = valid_intrinsics_region[i_camera]

    return mrcal.cameramodel( intrinsics                 = (intrinsics[0], intrinsics[1][i_camera,:]),
                              extrinsics_Rt_toref        = Rt_rx,
                              imagersize                 = imagersizes[i_camera],
                              observed_pixel_uncertainty = observed_pixel_uncertainty,
                              covariance_intrinsics      = covariance_intrinsics,
                              valid_intrinsics_region    = valid_intrinsics_region)

def make_cameramodels(intrinsics, extrinsics, imagersizes,
                      observed_pixel_uncertainty,
                      covariance_intrinsics,
                      valid_intrinsics_region = None):
    r'''Assemble cameramodels from a completed calibration

    The calibration routines treat the intrinsics and extrinsics for all cameras
    as a vector. This routine converts those to a list of mrcal.cameramodel
    structures that can be fed to all the other routines.

    '''
    return [ make_cameramodel(i_camera,
                              intrinsics, extrinsics, imagersizes,
                              observed_pixel_uncertainty,
                              covariance_intrinsics,
                              valid_intrinsics_region) for i_camera in range(len(intrinsics[1])) ]


# # Test for this function
# Nobservations = 5
# indices = np.array((1,3,4), dtype=int)
# observations = np.arange(15).reshape(5,3)
# frames = np.array((10,11,12,13), dtype=int)
# indices_frame_camera = np.array(((0,100),
#                                  (1,200),
#                                  (2,300),
#                                  (3,900),
#                                  (3,800)),
#                                 dtype=int)
# paths = np.arange(Nobservations)
# outlier_indices=np.array((2,5, 205,208, 311,390), dtype=int)
# # observations 0xx and 2xx are skipped
# # observation 3xx is now observation 1xx
# # 111,190
# split_observations, split_indices_frame_camera, split_paths, split_frames, split_outlier_indices = \
#     get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths,
#                                          frames,
#                                          outlier_indices)
# print split_outlier_indices
def get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths,
                                         frames = None,
                                         outlier_indices = None):
    r'''Returns a subset of observations from observation indices

    Observations are stored across variables:

    - observations
    - indices_frame_camera
    - paths
    - frames
    - outlier_indices

    These must all be self-consistent. This function takes in the desired
    observation indices to keep, and returns copies of all the variables that
    contain the requested subset of data and are consistent with each other

    '''

    if len(indices) == 0:
        raise Exception("Selected subset of data is empty: I threw out everything!")

    observations_new         = observations        [indices, ...].copy()
    paths_new                = [paths[i] for i in indices]
    indices_frame_camera_new = indices_frame_camera[indices, ...].copy()

    # I now collapse newly-missing frames and build the frame indices
    indices_frames  = []
    iframe_old_last = -1
    iframe_new_last = -1

    if outlier_indices is not None:
        # I make a copy of the outlier indices array, and iterate through it. As I
        # go I copy indices from the back of the array to the front. Initially the
        # to/from pointers are identical, but as I skip observations I'm going to be
        # skipping outlier indices, and a gap will developt between the pointers
        outlier_indices = outlier_indices.copy()

        # Index into the outlier_indices array that I copy FROM
        i_outlier_indices_old = 0
        # Index into the outlier_indices array that I copy TO
        i_outlier_indices_new = 0


    Nfeatures_in_observation = args.object_width_n*args.object_width_n

    def outlier_index_next_bounds(i0, iobs):


        ifeature_threshold = iobs*Nfeatures_in_observation
        for i in range(i0,len(outlier_indices)):
            if outlier_indices[i] >= ifeature_threshold:
                break
        else:
            return len(outlier_indices),len(outlier_indices)

        # found beginning of the set of outliers for this observation (or
        # further ones). If these outliers are for THIS observation, find the
        # end of the outliers for this observation. Otherwise tell the caller
        i0 = i
        if int(outlier_indices[i]/Nfeatures_in_observation) != iobs:
            # I don't have any outliers for this observation
            return i0,i0

        ifeature_threshold += Nfeatures_in_observation
        for i in range(i0+1,len(outlier_indices)):
            if outlier_indices[i] >= ifeature_threshold:
                return i0,i

        return i0,len(outlier_indices)

    def outlier_indices_accept(iobs_old, iobs_new, i_outlier_indices_old,i_outlier_indices_new):

        # I need to grab outliers for this observation. These begin somewhere
        # at/after i_outlier_indices_old because I may have skipped some
        # observations. First I find where the observations I want begin
        iold0,iold1 = outlier_index_next_bounds(i_outlier_indices_old, iobs_old)
        if iold0 == iold1:
            # I don't have any outliers for this observation
            return iold1, i_outlier_indices_new

        Noutliers_here = iold1-iold0
        inew0 = i_outlier_indices_new
        inew1 = inew0 + Noutliers_here
        i_observations_offset = iobs_old-iobs_new

        outlier_indices[inew0:inew1] = outlier_indices[iold0:iold1] - i_observations_offset*Nfeatures_in_observation

        return iold1, i_outlier_indices_new + Noutliers_here


    for iobs_new in range(len(indices)):
        iobs_old   = indices[iobs_new]
        iframe_old = indices_frame_camera_new[iobs_new,0]
        if iframe_old != iframe_old_last:
            # Saw new frame. The iframe in the data is going to be
            # non-consecutive, so I adjust it to become consecutive. And I then
            # update the mapping
            iframe_new_last += 1
            iframe_old_last = iframe_old
            indices_frames.append(iframe_old)
        indices_frame_camera_new[iobs_new,0] = iframe_new_last

        if outlier_indices is not None:
            i_outlier_indices_old,i_outlier_indices_new = \
                outlier_indices_accept(iobs_old, iobs_new,
                                   i_outlier_indices_old,i_outlier_indices_new)


    if frames is not None:
        frames_new = frames[indices_frames, ...].copy()
    else:
        frames_new = None

    if outlier_indices is not None:
        outlier_indices = outlier_indices[:i_outlier_indices_new]
    return observations_new, indices_frame_camera_new, paths_new, frames_new, outlier_indices

def get_observation_subset__random(ratio_cull, observations, indices_frame_camera, paths):
    r'''Returns a random subset of observations'''

    # keep this many
    N = int(round((1.0 - ratio_cull) * len(observations)))

    indices = np.sort(np.random.choice(len(observations), N, replace=False))

    return get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths)

def get_observation_subset__right_of_threshold_and_within_center(point_x_threshold,
                                                                 rad_threshold,
                                                                 observations,
                                                                 imagersizes,
                                                                 indices_frame_camera, paths, object_width_n):
    r'''Returns a subset of observations

    This throws out all observations that lie COMPLETELY to the left of the
    given threshold or outside the given circle. The mrcal internals handle
    partial board observations

    '''

    # observations that have fewer than this many points are thrown out
    must_have_at_least_points = object_width_n*2

    def have_enough_points(i):
        x = None
        if point_x_threshold > 0:
            x = observations[i,:,:,0] >= point_x_threshold
        if rad_threshold > 0:
            y = nps.norm2(observations[i, ..., :2] - (imagersizes[indices_frame_camera[i,1]] - 1.)/2.) < rad_threshold*rad_threshold
            if x is None:
                x = y
            else:
                x = x*y

        return np.count_nonzero(x) >= must_have_at_least_points

    indices = np.array([i for i in range(len(observations)) if \
                        have_enough_points(i)],
                       dtype=int)
    return get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths)

def incremental_optimization_loop(args, seedmodels, imagersizes, observations, indices_frame_camera,
                                  outlier_indices, incremental):
    '''Solve an incrementally-expanding optimization problem in several passes

    The logic is this:

        m   = simplest_model
        roi = smallest region

        while roi<ROI:
            solve(m,roi)
            if(couldn't fit the data very well):
                if m < M:
                    m++
                else:
                    # I'm already at the most complex model
                    print("Given lens model doesn't fit in the required ROI!")
                    break
            else:
                roi++

    I.e. I start with a smaller region-of-interest than what I actually care
    about, and with a simpler lens model than what I was asked to use. I
    solve again and again, increasing the region-of-interest and distortion
    model complexity as I go, using the outlier counts to guide the process.

    have minimal m that works with ROI

    '''

    Ncameras = len(args.images)
    indices_frame_camintrinsics_camextrinsics = \
        nps.glue(indices_frame_camera,
                 indices_frame_camera[:,(1,)]-1,
                 axis=-1)

    if seedmodels is None:
        # I have no seed. I compute a rough seed, and run a few preliminary,
        # incremental optimizations to get it reasonably-close to the right
        # answer
        intrinsics_data,extrinsics,frames = \
            mrcal.make_seed_no_distortion(imagersizes          = imagersizes,
                                          focal_estimate       = args.focal,
                                          Ncameras             = Ncameras,
                                          indices_frame_camera = indices_frame_camera,
                                          observations         = observations,
                                          object_spacing       = args.object_spacing,
                                          object_width_n       = args.object_width_n)

        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv initial solve: geometry only\n")
        lensmodel = 'LENSMODEL_STEREOGRAPHIC'
        stats = mrcal.optimize(intrinsics_data, extrinsics, frames, None,
                               observations, indices_frame_camintrinsics_camextrinsics,
                               None, None,
                               lensmodel,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = False,
                               do_optimize_intrinsic_distortions = False,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = True,
                               skip_regularization               = True,
                               outlier_indices                   = outlier_indices,
                               roi                               = args.roi,
                               get_covariances                   = False,
                               verbose                           = False)
        sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n\n".format(stats['rms_reproj_error__pixels']))

        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv initial solve: geometry and intrinsic core only\n")
        stats = mrcal.optimize(intrinsics_data, extrinsics, frames, None,
                               observations, indices_frame_camintrinsics_camextrinsics,
                               None, None,
                               lensmodel,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = True,
                               do_optimize_intrinsic_distortions = False,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = True,
                               skip_regularization               = True,
                               outlier_indices                   = outlier_indices,
                               roi                               = args.roi,
                               get_covariances                   = False,
                               verbose                           = False)
        sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n".format(stats['rms_reproj_error__pixels']))

    else:

        # The caller made sure that all the models use the same lens model
        lensmodel = seedmodels[0].intrinsics()[0]
        intrinsics_data  = nps.cat( *[m.intrinsics()[1] for m in seedmodels])

        # I keep the relative camera poses constant, but place camera0 at the
        # origin
        Rt_r0 = seedmodels[0].extrinsics_Rt_toref()
        extrinsics = \
            nps.cat( *[ mrcal.rt_from_Rt( mrcal.compose_Rt( m.extrinsics_Rt_fromref(),Rt_r0))
                        for m in seedmodels[1:]])

        # I have a GOOD extrinsics estimate, so I could compute a GOOD frame
        # pose estimate by triangulating:
        #
        #   import deltapose_lite
        #   for corresponding images:
        #       for points in chessboard:
        #           lindstrom to get point in 3d
        #           procrustes fit to get frame transformation
        #
        # But this takes a lot of typing, and wouldn't handle special cases:
        # - what if for a given frame only 1 camera is observing the board?
        # - what if for a given frame more than 2 cameras are observing the board?
        #
        # So I do the less-accurate-but-more-robust thing using pinhole
        # monocular observations. This is what mrcal.make_seed_no_distortion()
        # does in the no-seed-available case
        calobject_poses_local_Rt_cf = \
            mrcal.estimate_local_calobject_poses( indices_frame_camera,
                                                  observations,
                                                  args.object_spacing, args.object_width_n,
                                                  seedmodels)
        frames = \
            mrcal.estimate_frame_poses_from_monocular_views(
                calobject_poses_local_Rt_cf, extrinsics,
                indices_frame_camera,
                args.object_spacing, args.object_width_n)


    def get_scaled_roi(roi_final, iroi, Nroi):

        if Nroi == 1:
            if iroi != 0:
                raise Exception("get_scaled_roi(Nroi=1, iroi != 0) doesn't make any sense")
            return roi_final

        scale = float(iroi+1)/float(Nroi)
        return nps.glue(roi_final[:,:2],
                        roi_final[:,2:] * scale,
                        axis = -1)

    def expand_intrinsics(lensmodel, intrinsics_data):
        NnewDistortions = \
            mrcal.getNlensParams(lensmodel) - \
            intrinsics_data.shape[1]
        newDistortions = \
            (np.random.random((Ncameras, NnewDistortions)) - 0.5)*2. *1e-6
        m = re.search("OPENCV([0-9]+)", lensmodel)
        if m:
            Nd = int(m.group(1))
            if Nd >= 8:
                # Push down the rational components of the seed. I'd like these all to
                # sit at 0 ideally. The radial distortion in opencv is x_distorted =
                # x*scale where r2 = norm2(xy - xyc) and
                #
                # scale = (1 + k0 r2 + k1 r4 + k4 r6)/(1 + k5 r2 + k6 r4 + k7 r6)
                #
                # Note that k2,k3 are tangential (NOT radial) distortion components.
                # Note that the r6 factor in the numerator is only present for
                # >=LENSMODEL_OPENCV5. Note that the denominator is only present for >=
                # LENSMODEL_OPENCV8. The danger with a rational model is that it's
                # possible to get into a situation where scale ~ 0/0 ~ 1. This would
                # have very poorly behaved derivatives. If all the rational coefficients
                # are ~0, then the denominator is always ~1, and this problematic case
                # can't happen. I favor that.
                newDistortions[5:8] *= 1e-3
        return nps.glue( intrinsics_data, newDistortions, axis=-1 )

    def eval_solution(stats, outside_ROI_indices__prevROI):

        Nfeatures = args.object_width_n*args.object_width_n*len(observations)
        x    = stats['x'][:Nfeatures*2]

        def makemask_inside(outside_indices):
            maskout = np.zeros(x.shape, dtype=bool)
            maskout[outside_indices*2 + 0] = True
            maskout[outside_indices*2 + 1] = True
            return ~maskout


        if outside_ROI_indices__prevROI is None:
            maskin = makemask_inside(stats['outside_ROI_indices'])
            s = np.std(x[maskin])

        else:
            maskold_only = makemask_inside(outside_ROI_indices__prevROI)
            masknew_only = \
                makemask_inside (stats['outside_ROI_indices']) * \
                ~maskold_only


            # It's possible that increasing the roi adds a SMALL NUMBER of
            # points total. If the model doesn't fit the new ROI well, these
            # points would have high errors, but since there aren't a lot of
            # them, this wouldn't reflect at all in the new distribution. I
            # re-weight the distribution of the NEW points to be equal to k
            # times the distribution of all the previous points in the set. If
            # k==1 then the set of the new points is equivalent in weight to the
            # set of the old points
            k = 1
            xold = x[maskold_only]
            xnew = x[masknew_only]
            if len(xnew) == 0:
                print("RMS error: {}".format(stats['rms_reproj_error__pixels']))
                return True,"Extended ROI contains no new data"

            wnew = k * len(xold)/len(xnew)

            mean = (np.sum( xold                  ) + wnew*np.sum( xnew                  )) / ((1. + k) * len(xold))
            var  = (np.sum((xold-mean)*(xold-mean)) + wnew*np.sum((xnew-mean)*(xnew-mean))) / ((1. + k) * len(xold))
            s    = np.sqrt(var)



        print("RMS error: {}".format(stats['rms_reproj_error__pixels']))
        print("In-ROI independent x,y stdev: {} (user says {})".format(s, args.observed_pixel_uncertainty))

        # If a model fits in a specific ROI, then (assuming no outliers) all the
        # error is attributable to input noise. I'm given an estimate of this
        # noise on the input, so I can check to see if this is true
        stdev_error_ratio = s / args.observed_pixel_uncertainty

        q_threshold = 1.5

        return stdev_error_ratio < q_threshold, "stdev_error_ratio={} (wanted < {})".format(stdev_error_ratio, q_threshold)






    # Alrighty. All the preliminary business is finished. I should have a usable
    # seed now. And thus I now run the main optimization loop
    if not incremental:
        # We're not doing the incremental loop. Just solve it once and call it good
        lensmodel = args.lensmodel
        intrinsics_data  = expand_intrinsics(lensmodel, intrinsics_data)

        print("=================== optimizing everything{}from seeded intrinsics". \
              format(" except board warp " if args.optimize_calobject_warp else " "))

        stats = mrcal.optimize(intrinsics_data, extrinsics, frames, None,
                               observations, indices_frame_camintrinsics_camextrinsics,
                               None, None,
                               lensmodel,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = not args.skip_intrinsics_solve,
                               do_optimize_intrinsic_distortions = not args.skip_intrinsics_solve,
                               do_optimize_extrinsics            = not args.skip_extrinsics_solve,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = args.skip_outlier_rejection,
                               skip_regularization               = args.skip_regularization,
                               outlier_indices                   = outlier_indices,
                               roi                               = args.roi,
                               get_covariances                   = False,
                               verbose                           = args.verbose_solver)
        return "fixed solve", (lensmodel, intrinsics_data), extrinsics, frames, args.roi, stats




    if seedmodels is not None:
        # What do I do here? Probably I want to start out at the seeded
        # lens model? This maybe just works, actually, but somebody needs
        # to think about it. This currently doesn't touch
        # --skip-extrinsics-solve,--skip-intrinsics-solve
        raise Exception("--seed and --incremental are currently not supported together")


    # I favor the center pixel at the center of the imager
    intrinsics_data[:,2:4] = (imagersizes - 1) / 2

    Nroi = 8
    if args.roi is None:
        # no explicit region-of-interest given. I thus use the whole imager.
        # I use an ellipse with the imager's aspect ratio, passing through
        # the corner
        widths       = imagersizes.astype(float)-1
        centerpixels = widths / 2.
        roi_final = nps.glue(centerpixels, widths/2.*np.sqrt(2), axis=-1)
    else:
        roi_final = args.roi

    stats_best = None
    roi_best   = None

    iroi = 0
    outside_ROI_indices__prevROI = None
    while iroi<Nroi:
        roi = get_scaled_roi(roi_final, iroi, Nroi)

        print("")
        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv next distortion/ROI:\n")
        print("lens model: {}"         .format(lensmodel))
        print("ROI:        {}/{}  ({})".format(iroi+1, Nroi, roi))

        state = copy.deepcopy( (intrinsics_data, extrinsics, frames), )
        stats = mrcal.optimize(state[0], state[1], state[2], None,
                               observations, indices_frame_camintrinsics_camextrinsics,
                               None, None,
                               lensmodel,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = True,
                               do_optimize_intrinsic_distortions = True,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = True,
                               skip_regularization               = args.skip_regularization,
                               outlier_indices                   = outlier_indices,
                               roi                               = roi,
                               get_covariances                   = False,
                               verbose                           = args.verbose_solver)

        solution_acceptable,solution_description = eval_solution(stats, outside_ROI_indices__prevROI)

        if solution_acceptable:
            # We found a good solution for this lens model and ROI. Let's
            # expand the region of interest and go again

            # save the initial state. The last one of these chunks of data is
            # the best solution I got
            outlier_indices       = stats['outlier_indices']
            intrinsics_data       = state[0].copy()
            extrinsics            = state[1].copy()
            frames                = state[2].copy()
            stats_best            = copy.deepcopy(stats)
            roi_best              = copy.deepcopy(roi)
            lensmodel_best = copy.deepcopy(lensmodel)
            result                = 'Usable solve found at the full ROI'

            outside_ROI_indices__prevROI = stats['outside_ROI_indices']
            iroi += 1
            sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ {}: good solve! roi++\n".format(solution_description))
        else:
            # This solution wasn't very good. Let's try a richer distortion
            # model

            lensmodel1 = mrcal.getNextLensModel(lensmodel, args.lensmodel)

            if lensmodel1 == lensmodel:

                # we're already at the last model in the family, or at the
                # maximum model the user asked for. There's nowhere more to go,
                # so I guess I'm done
                sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ {}: ill-fitting solve, but no more lens-models remaining. I'm done\n".format(solution_description))

                # # For testing. The distribution can be plotted thusly:
                # import gnuplotlib as gp
                # x    = stats['x']
                # maskout = np.zeros(x.shape, dtype=bool)
                # maskout[stats['outside_ROI_indices']*2 + 0] = True
                # maskout[stats['outside_ROI_indices']*2 + 1] = True
                # x = x[~maskout]
                # s    = np.std(x)
                # s2   = s*s
                # gp.plot(x, histogram='freq', binwidth=0.2,
                #         equation='1./sqrt(2.*pi*{s2})*exp(-x*x/(2.*{s2})) axis x1y2'.format(s2=s2),
                #         _xrange=[-5.*s,5.*s],
                #         ymin=0, y2min=0,
                #         hardcopy='/tmp/tst.gp')
                # import IPython
                # IPython.embed()
                # sys.exit()


                if stats_best is None:
                    # This is the best I got I guess
                    intrinsics_data       = state[0]
                    extrinsics            = state[1]
                    frames                = state[2]
                    stats_best            = stats
                    roi_best              = roi
                    lensmodel_best = lensmodel
                    result                = 'No usable solves found'
                else:
                    result                = 'Usable solves found, but not for the full ROI'
                break

            else:
                # I try the next model in the family, keeping the roi and
                # outlier list the same
                lensmodel = lensmodel1
                intrinsics_data  = expand_intrinsics(lensmodel, intrinsics_data)
                sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ {}: ill-fitting solve, distortion++\n".format(solution_description))

    return                                                                            \
        result,                                                                       \
        ( lensmodel_best,                                                      \
          intrinsics_data[:,:mrcal.getNlensParams(lensmodel_best)]), \
         extrinsics,                                                                  \
         frames,                                                                      \
         roi_best,                                                                    \
         stats_best







# expand ~/ into $HOME/
args.images = [os.path.expanduser(g) for g in args.images]

Ncameras = len(args.images)
if Ncameras > 10:
    raise Exception("Got {} image globs. It should be one glob per camera, and this sounds like WAY too make cameras. Did you forget to escape your glob?". \
                    format(Ncameras))

if args.pairs and Ncameras % 2:
    raise Exception("With --pairs I must have gotten an even number of cameras, but instead got {}".format(Ncameras))

if args.seed:

    if args.focal:
        raise Exception("Exactly one of --focal and --seed MUST be given")


    def seedmodels_iterator():
        for g in args.seed.split(','):
            globbed_filenames = sorted(glob.glob(g))
            if 0 == len(globbed_filenames):
                raise Exception("seed glob '{}' matched no files!".format(g))
            for f in globbed_filenames:
                yield mrcal.cameramodel(f)
    seedmodels = list(seedmodels_iterator())

    if Ncameras != len(seedmodels):
        raise Exception("I saw {} image globs, but {} --seed models. Both represent cameras, so I should have identical counts". \
                        format(Ncameras, len(seedmodels)))

    if args.imagersize is not None:
        for m in seedmodels:
            if args.imagersize != m.imagersize():
                raise Exception("Both --seed and --imagersize were given, so they must match exactly. But I had --imagersize {} and one model has imagersize() = {}". \
                                format(args.imagersize, m.imagersize()))
    lensmodel = seedmodels[0].intrinsics()[0]
    for m in seedmodels[1:]:
        if lensmodel != m.intrinsics()[0]:
            raise Exception("I expect all cameras to use the same lens model, but --seed saw {} and {}". \
                            format(lensmodel,
                                   m.intrinsics()[0]))

    if args.lensmodel is None:
        args.lensmodel = lensmodel


else:
    if not args.focal:
        raise Exception("Exactly one of --focal and --seed MUST be given")

    if not args.lensmodel:
        raise Exception("--lensmodel is required if no --seed")

    if args.skip_extrinsics_solve:
        raise Exception("--skip-extrinsics-solve requires --seed")
    if args.skip_intrinsics_solve:
        raise Exception("--skip-intrinsics-solve requires --seed")

    seedmodels = None



if args.roi is not None:
    if len(args.roi) != Ncameras:
        raise Exception("Globs say we have {} cameras, but --roi suggests I have {}. These MUST match". \
                        format(Ncameras, len(args.roi)))
    try:
        args.roi = np.array(args.roi, dtype=float)
    except:
        sys.stderr.write("Couldn't interpret --roi as a numpy array")
        raise

observations, indices_frame_camera, paths = \
    mrcal.get_chessboard_observations(args.object_width_n,
                                      args.object_width_n,
                                      args.images,
                                      args.corners_cache,
                                      jobs = args.jobs,
                                      weighted = not args.unweighted_corners)

Nobservations = len(observations)

# list of imager sizes; one per camera
imagersizes = np.array([get_imagersize_one(icamera,
                                           indices_frame_camera,
                                           paths,
                                           args.imagersize,
                                           seedmodels) for icamera in range(Ncameras)],
                       dtype=np.int32)

if args.cull_random_observations_ratio >= 0:
    observations, indices_frame_camera, paths, _, _ = \
        get_observation_subset__random(args.cull_random_observations_ratio,
                                       observations, indices_frame_camera, paths)
outlier_indices = None
if args.cull_points_left_of > 0 or args.cull_points_rad_off_center > 0:

    # first cut off full observations
    observations, indices_frame_camera, paths, _, _ = \
        get_observation_subset__right_of_threshold_and_within_center( \
            args.cull_points_left_of,
            args.cull_points_rad_off_center,
            observations,
            imagersizes, indices_frame_camera, paths,
            args.object_width_n)

    # any observations that lie partially outside the threshold remain. I cut
    # out individual points as outliers
    if args.cull_points_left_of > 0:
        outlier_indices0 = set(np.flatnonzero(observations[..., 0] < args.cull_points_left_of))
    else:
        outlier_indices0 = set()

    if args.cull_points_rad_off_center > 0:
        centerpixels = (imagersizes[ indices_frame_camera[:,1] ] - 1.)[:,np.newaxis,np.newaxis,:] / 2.
        radsq = args.cull_points_rad_off_center*args.cull_points_rad_off_center
        outlier_indices1 = set(np.flatnonzero(nps.norm2(observations[..., :2] - centerpixels) > radsq))
    else:
        outlier_indices1 = set()

    outlier_indices = np.array(sorted(list(outlier_indices0.union( outlier_indices1 ))), dtype=np.int32)


result,intrinsics,extrinsics,frames,roi,stats = \
    incremental_optimization_loop(args, seedmodels, imagersizes, observations, indices_frame_camera, outlier_indices, args.incremental)
if args.incremental:
    print(">>>>>>>>>>>>>>>>> " + result)
    print("Final lens model: {}".format(intrinsics[0]))
    print("Final ROI:        {}".format(roi))


if args.skip_outlier_rejection: print("We are NOT rejecting outliers")
else:                           print("We ARE rejecting outliers")
if args.skip_regularization:    print("We are NOT applying regularization in the solver")
else:                           print("We ARE applying regularization in the solver")


solver_context = mrcal.SolverContext()




















if args.num_cross_validation_splits > 1:

    # THIS IS ALL VERY EXPERIMENTAL


    def cross_validation_makesplit(Nobservations, Nsplit):
        r'''Returns a random splitting of the data set

        This function returns a python list (of length Nsplit). Each contains a
        numpy array of sorted integer indices

        I have Nobservations observations, and I want to split them into Nsplit
        equal (and random) sets. If an even splitting isn't possible, the N
        stragglers are distributed amount the N trailing sets

        '''

        # I create a random list of indices, and take sequential subsets of it
        i_observations = np.arange(Nobservations, dtype=np.int32)
        np.random.shuffle(i_observations)

        # I could do this:
        #   s = [i_observations[isplit*N_insplit:(isplit+1)*N_insplit] for isplit in range(Nsplit)]
        # But then I need to deal with the remaining observations. For instance,
        # trying to split 14 into 4 groups would create 4 groups of 3, and 2
        # observations remaining. I want to distribute these 2 extra observations
        # one-at-a-time among my groups, hence this logic:

        s = [None] * Nsplit
        iobservation = 0
        for isplit in range(Nsplit):
            N_inthissplit = int( (Nobservations - iobservation) / (Nsplit - isplit))
            s[isplit] = i_observations[iobservation:iobservation+N_inthissplit]
            iobservation += N_inthissplit

        for i in s:
            i.sort()

        return s




    splits = cross_validation_makesplit(Nobservations, args.num_cross_validation_splits)

    cross_validation_models = []

    for isplit in range(len(splits)):

        s = splits[isplit]

        split_observations, split_indices_frame_camera, split_paths, split_frames, split_outlier_indices = \
            get_observation_subset__from_indices(s, observations, indices_frame_camera, paths,
                                                 frames, stats['outlier_indices'])

        split_indices_frame_camintrinsics_camextrinsics = \
            nps.glue(split_indices_frame_camera,
                     indices_frame_camera[:,(1,)]-1,
                     axis=-1)

        split_intrinsics = copy.deepcopy(intrinsics)
        split_extrinsics = copy.deepcopy(extrinsics)

        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv Evaluating split {}/{}\n".format(isplit+1, args.num_cross_validation_splits))
        stats = mrcal.optimize(split_intrinsics[1],
                               split_extrinsics,
                               split_frames,
                               None,
                               split_observations, split_indices_frame_camintrinsics_camextrinsics,
                               None, None,
                               split_intrinsics[0],
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = not args.skip_intrinsics_solve,
                               do_optimize_intrinsic_distortions = not args.skip_intrinsics_solve,
                               do_optimize_extrinsics            = not args.skip_extrinsics_solve,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = args.skip_outlier_rejection,
                               skip_regularization               = args.skip_regularization,
                               outlier_indices                   = split_outlier_indices,
                               roi                               = roi,
                               get_covariances                   = True,
                               verbose                           = False,
                               solver_context                    = solver_context)

        covariance_intrinsics = stats.get('covariance_intrinsics')

        report = "RMS reprojection error: {} pixels\n".format(stats['rms_reproj_error__pixels'])
        sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ \n" + report)

        raise Exception("This make_cameramodels() call has bit-rotted. Fix if you need it")
        cross_validation_models.append( make_cameramodels(split_intrinsics, split_extrinsics) )
    # for i_camera in range(len(intrinsics[1]):
    i_camera = 0
    if roi is None:
        focus_center = None
        focus_radius = min(imagersizes[i_camera])/6
    else:
        focus_center = roi[i_camera,:2]
        focus_radius = min(roi[i_camera,2:])
    plot = \
        mrcal.show_intrinsics_diff([models[i_camera] for models in cross_validation_models],
                                   focus_center = focus_center,
                                   focus_radius = focus_radius)

    plot.wait()

    print("done!!!!!!")
    sys.exit()











indices_frame_camintrinsics_camextrinsics = \
    nps.glue(indices_frame_camera,
             indices_frame_camera[:,(1,)]-1,
             axis=-1)

if args.optimize_calobject_warp:
    calobject_warp = np.array((0,0), dtype=float)
else:
    calobject_warp = None

sys.stderr.write("vvvvvvvvvvvvvvvvvvvv final, full re-optimization call to get board warp, covariance_intrinsics and solver_context\n")
stats = mrcal.optimize(intrinsics[1],extrinsics,frames, None,
                       observations, indices_frame_camintrinsics_camextrinsics,
                       None, None,
                       intrinsics[0],
                       do_optimize_calobject_warp        = args.optimize_calobject_warp,
                       calobject_warp                    = calobject_warp,
                       imagersizes                       = imagersizes,
                       observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                       do_optimize_intrinsic_core        = not args.skip_intrinsics_solve,
                       do_optimize_intrinsic_distortions = not args.skip_intrinsics_solve,
                       do_optimize_extrinsics            = not args.skip_extrinsics_solve,
                       calibration_object_spacing        = args.object_spacing,
                       calibration_object_width_n        = args.object_width_n,
                       skip_outlier_rejection            = True, # use outliers in outlier_indices
                       skip_regularization               = args.skip_regularization,
                       outlier_indices                   = stats['outlier_indices'],
                       roi                               = roi,
                       get_covariances                   = True,
                       verbose                           = args.verbose_solver,
                       solver_context                    = solver_context)
sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n".format(stats['rms_reproj_error__pixels']))


if args.skip_intrinsics_solve:
    covariance_intrinsics      = None
else:
    covariance_intrinsics      = stats.get('covariance_intrinsics')
if args.skip_extrinsics_solve:
    covariance_extrinsics      = None
else:
    covariance_extrinsics      = stats.get('covariance_extrinsics')

report = "RMS reprojection error: {:.01f} pixels\n".format(stats['rms_reproj_error__pixels'])

Npoints_chessboard = args.object_width_n*args.object_width_n*Nobservations

# shape (Nobservations,Nwant,Nwant,2)
measurements_0_for_outliers = \
    stats['x'][:Npoints_chessboard*2]. \
    reshape(Nobservations, args.object_width_n, args.object_width_n, 2)
worst_point_err = np.sqrt(np.max(nps.norm2( nps.clump(measurements_0_for_outliers, n=3) )))
report += "Worst reprojection error (by measurement): {:.01f} pixels\n".format(worst_point_err)
if not args.skip_outlier_rejection:
    report += "Noutliers: {} out of {} total points: {:.01f}% of the data\n". \
        format(stats['Noutliers'],
               args.object_width_n*args.object_width_n*len(observations),
               100.0 * stats['Noutliers'] / (args.object_width_n*args.object_width_n*len(observations)))
if calobject_warp is not None:
    report += "calobject_warp = {}\n".format(calobject_warp)

if args.pairs:
    # Most of this derivation is described in compute_intrinsics_uncertainty():
    #
    # I have dp = M dqref
    #
    # yaw_pair0 = rt1[1] -> dyaw_pair0 = M[1,:] dqref
    # Var(yaw_pair0) = M[1,:] Var(dqref) M[1,:]t = covariance(yaw,yaw)
    #
    # yaw_pair1 = compose_rt( rt3, invert_rt(rt2))[1]. I linearize: yaw_pair1 ~
    # ... + inner(u, drt23) = ... + inner(u, M[irt23, :] dqref) ->
    # Var(yaw_pair1) = ut M[irt23,:] M[irt23,:]t u s^2 = ut covariance(irt23,irt23) u
    for i_pair in range(Ncameras//2):
        if i_pair == 0:
            stdev_yaw   = np.sqrt(stats['covariance_extrinsics'][1,1])
            rt_1r = extrinsics[i_pair*2]
            Rt_1r = mrcal.Rt_from_rt(rt_1r)
            Rt_10 = Rt_1r
            baseline = np.sqrt(nps.norm2(Rt_10[3,:]))
        else:
            rt_0r = extrinsics[i_pair*2-1]
            rt_1r = extrinsics[i_pair*2  ]
            ir0   = (i_pair*2-1)*6
            ir1   = (i_pair*2  )*6

            Rt_0r = mrcal.Rt_from_rt(rt_0r)
            Rt_1r = mrcal.Rt_from_rt(rt_1r)
            Rt_10 = mrcal.compose_Rt(Rt_1r, mrcal.invert_Rt(Rt_0r))
            baseline = np.sqrt(nps.norm2(Rt_10[3,:]))

            # I only care about the rotation components of these transformations
            R_0r, dR_0r__dr_0r = cv2.Rodrigues(rt_0r[:3])
            dR_0r__dr_0r = nps.transpose(dR_0r__dr_0r) # fix opencv's weirdness. Now shape=(9,3)

            R_1r, dR_1r__dr_1r = cv2.Rodrigues(rt_1r[:3])
            dR_1r__dr_1r = nps.transpose(dR_1r__dr_1r) # fix opencv's weirdness. Now shape=(9,3)

            R_r0 = nps.transpose(R_0r)
            dR_r0__dr_0r = nps.xchg(dR_0r__dr_0r.reshape(3,3,3),
                                    0,1).reshape(9,3)

            R_10 = nps.matmult(R_1r, R_r0)

            # 00 10 20 ... ...
            # 01 11 21 ... ...
            # 02 12 22 ... ...
            # ... 00 10 20 ...
            # ... 01 11 21 ...
            # ... 02 12 22 ...
            # ... ... 00 10 20
            # ... ... 01 11 21
            # ... ... 02 12 22
            dR_10__dR_1r = scipy.linalg.block_diag(nps.transpose(R_r0),
                                                   nps.transpose(R_r0),
                                                   nps.transpose(R_r0),)
            # 00 . . 01 . . 02 . .
            # . 00 . . 01 . . 02 .
            # . . 00 . . 01 . . 02
            # 10 . . 11 . . 12 . .
            # . 10 . . 11 . . 12 .
            # . . 10 . . 11 . . 12
            # 20 . . 21 . . 22 . .
            # . 20 . . 21 . . 22 .
            # . . 20 . . 21 . . 22
            dR_10__dR_r0 = nps.reorder(nps.dummy(nps.dummy(R_1r, -1), -1) * np.eye(3), 0,2,1,3).reshape(9,9)

            r_10, dr_10__dR_10 = cv2.Rodrigues(R_10)
            r_10 = r_10.ravel()                       # fix opencv's weirdness
            dr_10__dR_10= nps.transpose(dr_10__dR_10) # fix opencv's weirdness

            dyaw__dR10  = dr_10__dR_10[1,:]
            dyaw__dr_0r = nps.matmult(dyaw__dR10, dR_10__dR_r0, dR_r0__dr_0r)
            dyaw__dr_1r = nps.matmult(dyaw__dR10, dR_10__dR_1r, dR_1r__dr_1r)

            # finally, got the linear map between rotations and relative yaw
            u = nps.glue(dyaw__dr_0r, dyaw__dr_1r, axis=-1)


            # This computation of u was very complex. A test:
            # delta = np.random.random(6) * 1e-6
            # yaw0 = mrcal.compose_rt(rt_1r, mrcal.invert_rt (rt_0r))[1]
            # rt_0r_shifted = rt_0r.copy()
            # rt_0r_shifted[:3] += delta[:3]
            # rt_1r_shifted = rt_1r.copy()
            # rt_1r_shifted[:3] += delta[3:]
            # yaw1 = mrcal.compose_rt(rt_1r_shifted, mrcal.invert_rt (rt_0r_shifted))[1]
            # print(f"Gradient testing: saw dyaw: {yaw1-yaw0}, expected dyaw {nps.inner(u,delta)} err: {yaw1-yaw0 - nps.inner(u,delta)}")


            # Get the slice of covariance for the rotations-only: r_01 and r_1r
            A = stats['covariance_extrinsics'][ir0:ir0+3,ir0:ir0+3]
            B = stats['covariance_extrinsics'][ir0:ir0+3,ir1:ir1+3]
            C = stats['covariance_extrinsics'][ir1:ir1+3,ir0:ir0+3]
            D = stats['covariance_extrinsics'][ir1:ir1+3,ir1:ir1+3]
            covariance_slice = nps.glue( nps.glue(A,B, axis=-1),
                                         nps.glue(C,D, axis=-1),
                                        axis=-2 )

            stdev_yaw   = np.sqrt(nps.inner( u, nps.inner(u, covariance_slice) ))

        report += "Pair{} baseline: {:.2f}m\n".format(i_pair, baseline)
        report += "Pair{} 1-stdev yaw uncertainty: {:.3f} degrees. Expected resulting range error at 1000m: {:.1f}m\n". \
            format(i_pair,
                   stdev_yaw*180./np.pi,
                   stdev_yaw / baseline * 1000 * 1000 )

print(report)

# shape (Nframes,Ncameras,Nwant,Nwant,2)
projected = \
    mrcal.calobservations_project(intrinsics[0], intrinsics[1],
                                  extrinsics, frames,
                                  args.object_spacing, args.object_width_n, calobject_warp)

# Each has shape (Nobservations,Nwant,Nwant,2)
reproj_err_including_outliers, reproj_err_0_for_outliers = \
    mrcal.calobservations_compute_reproj_error(projected, observations,
                                               indices_frame_camera, args.object_width_n,
                                               stats['outlier_indices'])



def get_valid_intrinsics_region(i_camera,
                                ignore_outliers = True,
                                focus_center = None, focus_radius = -1):

    '''THIS FUNCTION IS MADE UP. PLEASE FIX'''

    if args.skip_intrinsics_solve:
        return None


    idx = np.ones( reproj_err_including_outliers.shape[:-1], dtype=bool)

    if i_camera >= 0:
        idx[indices_frame_camera[:,1] != i_camera, ...] = False
    if ignore_outliers:
        nps.clump(idx, n=3)[stats['outlier_indices']] = False

    err = reproj_err_including_outliers[idx, ...]
    obs = observations                 [idx, ..., :2]

    W,H=imagersizes[i_camera]
    if focus_center is None:
        focus_center = (imagersizes[i_camera]-1.)/2.

    gridn_x,gridn_y = 20,10
    # This looks at reprojection errors EVEN FOR POINTS THROWN OUT AS OUTLIERS
    # This IGNORES measurement weighting
    mean,stdev,count,using = \
        mrcal.report_residual_statistics(obs,err, imagersizes[i_camera],
                                         gridn_x = gridn_x,
                                         gridn_y = gridn_y)

    if covariance_intrinsics is None:
        raise Exception("No intrinsics uncertainty was computed. You need to call mrcal.optimize(..., get_covariance_intrinsics = True) for this to work")

    covariance_intrinsics_here = None
    if covariance_intrinsics is not None:
        covariance_intrinsics_here = covariance_intrinsics[i_camera, ...]
    model = \
        mrcal.cameramodel( intrinsics                 = (intrinsics[0], intrinsics[1][i_camera,:]),
                           extrinsics_rt_toref        = np.zeros(6,dtype=float),
                           imagersize                 = imagersizes[i_camera],
                           observed_pixel_uncertainty = args.observed_pixel_uncertainty,
                           covariance_intrinsics      = covariance_intrinsics_here)
    v,_ = mrcal.sample_imager_unproject(gridn_x, gridn_y,
                                        intrinsics[0], intrinsics[1][i_camera,:],
                                        *imagersizes[i_camera])

    err = mrcal.compute_intrinsics_uncertainty(model, v,
                                               focus_center = focus_center,
                                               focus_radius = focus_radius)

    try:

        sys.stderr.write("These thresholds for the valid-intrinsics-region are completely made up\n")
        im = (err < 1) * (mean < 0.5) * (stdev < 1.5) * (count > 3)

        # I compute the contour. OpenCV can't process binary images, so I need to
        # convert to a different image type first. AND findContours() reports the
        # coordinates in the opposite order as how they're given (image is x,y;
        # returned coords are y,x). Ugh
        contour = cv2.findContours(nps.transpose(im).astype(np.uint8).copy(),
                                   cv2.RETR_EXTERNAL,
                                   cv2.CHAIN_APPROX_SIMPLE)[1][0][:,0,:].astype(float)
        contour = mrcal.close_contour(contour)
        if contour.ndim != 2 or contour.shape[0] < 4:
            # I have a closed contour, so the only way for it to not be
            # degenerate is to include at least 4 points
            return None

        # I convert the contours back to the full-res image coordinate. The grid
        # mapping is based on the corner pixels
        contour[:,0] *= float(W-1)/(gridn_x-1)
        contour[:,1] *= float(H-1)/(gridn_y-1)

        return contour.round().astype(np.int32)

    except:
        return None


valid_intrinsics_region = [get_valid_intrinsics_region(i) for i in range(Ncameras)]




# Write the output models
models = make_cameramodels(intrinsics, extrinsics, imagersizes,
                           args.observed_pixel_uncertainty,
                           covariance_intrinsics,
                           valid_intrinsics_region)
# The note says how we ran this, and contains the commented-out report
note = \
    "generated on {} with   {}\n".format(time.strftime("%Y-%m-%d %H:%M:%S"),
                                           ' '.join(mrcal.shellquote(s) for s in sys.argv)) + \
    re.sub(r"^(.)", r"# \1", report, flags=re.M)
for i_camera in range(len(models)):

    filename_base = \
        '{}/camera{}-{}'.format(args.outdir, i_camera//2, i_camera%2) \
        if args.pairs \
        else '{}/camera-{}'.format(args.outdir, i_camera)

    cameramodelfile = filename_base + '.cameramodel'
    models[i_camera].write(cameramodelfile, note)
    print("Wrote {}".format(cameramodelfile))



if not args.explore:
    sys.exit(0)



# We're exploring!
import gnuplotlib as gp


print(r'''Calibration results REPL.
Potential things to look at:

    show_calibration_geometry()
    show_residuals_observation_worst(i_observation_in_order_from_worst)
    show_residuals_observation(i_observation, vectorscale=20)
    show_intrinsics_uncertainty(i_camera)
    show_valid_intrinsics_region(i_camera)
    show_residuals('vectorfield', i_camera, show_all_reproj_errors=True)
    show_residuals('heatmap',     i_camera)
    show_residuals('directions',  i_camera)
    show_residuals_histogram(     i_camera)
    show_residuals_radial(        i_camera)
    show_residuals_regional(      i_camera)
    show_distortion('heatmap',    i_camera)
    show_distortion('vectorfield',i_camera)
    show_distortion('radial',     i_camera)
    show_splined_model_surface(   i_camera, i_xy)
    show_roi(i_camera)
    stats
    i_observations_worst
    rms_reproj_err_including_outliers_perobservation
    rms_reproj_err_0_for_outliers_perobservation
    rms_measurements_0_for_outliers_perobservation
    paths[i_observations_worst[0]]
    calobject_warp
''')


non_outlier_mask = np.ones( (Nobservations,
                             args.object_width_n,
                             args.object_width_n), dtype=bool)
non_outlier_mask.ravel()[stats['outlier_indices']] = False
non_outliers_per_observation = np.sum( nps.clump(non_outlier_mask, n=-2).astype(int),
                                       axis=-1)

rms_reproj_err_including_outliers_perobservation = \
    np.sqrt( nps.norm2( nps.clump(reproj_err_including_outliers,n=-3) ) /
             (args.object_width_n*args.object_width_n) )
rms_reproj_err_0_for_outliers_perobservation     = \
    np.sqrt( nps.norm2( nps.clump(reproj_err_0_for_outliers,n=-3) ) /
             non_outliers_per_observation )
rms_measurements_0_for_outliers_perobservation   = \
    np.sqrt( nps.norm2( nps.clump(measurements_0_for_outliers,n=-3) ) /
             non_outliers_per_observation )


i_observations_worst    = list(reversed(np.argsort(rms_measurements_0_for_outliers_perobservation)))
i_observation_from_path = dict( [(paths[_i],_i) for _i in range(len(observations))] )

def show_residuals_observation(observation, vectorscale = 1.0, **kwargs):
    r'''Visualize calibration residuals for a single observation

    Given a single observation, plots the chessboard image overlaid with its
    residuals. Each residual is plotted as a circle, color-coded by the error
    size, and with a vector showing the error itself. If a point was thrown out
    as an outlier, the vector is shown, but the circle is omitted.

    The observation is given in the first argument as either an integer
    (observation index) or a string (path).

    Usually the errors are small, and hard to see. So for legibility the error
    vectors can be scaled up by passing in a 'vectorscale' argument.

    All kwargs are passed on to the gnuplotlib constructor to control the
    generated plot.

    '''

    if isinstance(observation, (int,np.integer)):
        i_observation = observation
    elif isinstance(observation, str):
        i_observation = i_observation_from_path[observation]
    else:
        raise Exception("observation should be a string (image path) or an integer; got type(observation) = {}".format(type(observation)))

    obs              = nps.clump( observations[i_observation, ..., :2], n=2)
    i_frame,i_camera = indices_frame_camera[i_observation]
    reproj           = nps.clump( projected[i_frame,i_camera], n=2)

    # Reprojection error per point. These may or may not have been thrown out as
    # outliers. And these may have been scaled in the measurement vector
    err = reproj - obs

    # non_outlier_mask[i_observation] is dtype=bool, shape=(Nwant,Nwant), so I
    # can use it as an index. measurements_0_for_outliers has shape
    # (Nobservations,Nwant,Nwant,2)
    # This thing has shape (Nvalidpoints,2)
    measurements_no_outliers = \
        measurements_0_for_outliers[i_observation,
                                    non_outlier_mask[i_observation],
                                    :]
    obs_ignoring_outliers = obs[non_outlier_mask[i_observation].ravel(), :]

    imagepath = paths[i_observation]
    plotkwargs = \
        dict(square=1,cbmin=0,
             title='{}: i_observation={}, i_frame={}, i_camera={}, path={}, error_RMS_all_points={:.2f}, measurement_RMS_ignoring_outliers={:.2f}'. \
               format( intrinsics[0],
                       i_observation, i_frame, i_camera,
                       paths[i_observation],
                       rms_reproj_err_including_outliers_perobservation[i_observation],
                       rms_measurements_0_for_outliers_perobservation[i_observation]),
             **kwargs)
    if os.path.isfile(imagepath):
        # only plot an image overlay if the image exists
        plotkwargs['rgbimage'] = imagepath
        plotkwargs['set']      = 'autoscale noextend'
    else:
        W,H=imagersizes[i_camera]
        plotkwargs['xrange'] = [0,W-1]
        plotkwargs['yrange'] = [H-1,0]

    gp.plot( (obs_ignoring_outliers[:,0], obs_ignoring_outliers[:,1], np.sqrt(nps.norm2(measurements_no_outliers)),
              dict(_with     = 'points pt 7 ps 2 palette',
                   legend    = 'reprojection error',
                   tuplesize = 3)),

             (obs[:,0], obs[:,1], vectorscale*err[:,0], vectorscale*err[:,1],
              dict(_with     = 'vectors size screen 0.01,20 fixed filled lw 2',
                   legend    = 'observed',
                   tuplesize = 4)),

             **plotkwargs)


def show_residuals_observation_worst(i, **kwargs):
    show_residuals_observation( i_observations_worst[i], **kwargs )

def check_confidence_computations(solver_context, observed_pixel_uncertainty):
    r'''Test computeUncertaintyMatrices() and compute_intrinsics_uncertainty()

    The uncertainty computation is documented in the docstring for
    compute_intrinsics_uncertainty(). The math and the implementation are
    tricky, so this function exists to empirically confirm that the thing being
    computed is correct, both in implementation and intent.

    Call this after we just solved a full optimization problem

    This function checks some linearization assumptions. It uses a densified
    jacobian to do the math, so this is very inefficient, and only viable for
    small problems.

    '''

    indices_frame_camintrinsics_camextrinsics = \
        nps.glue(indices_frame_camera,
                 indices_frame_camera[:,(1,)]-1,
                 axis=-1)

    lensmodel = intrinsics[0]


    def callback(intrinsics_data):
        x,Joptimizer = \
            mrcal.optimizerCallback(intrinsics_data,extrinsics,frames, None,
                                    observations, indices_frame_camintrinsics_camextrinsics,
                                    None, None,
                                    lensmodel,
                                    do_optimize_calobject_warp        = args.optimize_calobject_warp,
                                    calobject_warp                    = calobject_warp,
                                    imagersizes                       = imagersizes,
                                    do_optimize_intrinsic_core        = not args.skip_intrinsics_solve,
                                    do_optimize_intrinsic_distortions = not args.skip_intrinsics_solve,
                                    do_optimize_extrinsics            = not args.skip_extrinsics_solve,
                                    calibration_object_spacing        = args.object_spacing,
                                    calibration_object_width_n        = args.object_width_n,
                                    skip_regularization               = args.skip_regularization,
                                    outlier_indices                   = stats['outlier_indices'],
                                    roi                               = roi,
                                    verbose                           = False)
        Joptimizer = Joptimizer.toarray()
        J = Joptimizer.copy()
        solver_context.pack(J)
        return x,J,Joptimizer

    def callback_perturbed(delta, i_var):
        intrinsics_data = intrinsics[1].copy()
        intrinsics_data[0, i_var] += delta
        return callback(intrinsics_data)[0]

    def callback_perturbed_intrinsics(delta, i_var):
        ivar = solver_context.state_index_intrinsics(0) + i_var
        return callback_perturbed(delta, i_var), ivar



    # State and measurements at the operating point
    p0 = solver_context.p().copy()
    x0,J0,Joptimizer0 = callback(intrinsics[1])


    ###########################################################################
    # First a very basic gradient check. The test-gradients tool does this much
    # more thoroughly
    delta = 1e-3
    x2,ivar2 = callback_perturbed_intrinsics(delta,0)

    dx2          = x2 - x0
    dx2_estimate = J0[:,ivar2]*delta

    print("Gradient check. Should be close to 0: {:.2g}". \
          format(nps.norm2(dx2-dx2_estimate)))

    ###########################################################################
    # We're supposed to be at the optimum. E = norm2(x) ~ norm2(x0 + Jdp) =
    # norm2(x0) + 2 Jt x0 dp + norm2(Jdp). For very small dp, I should see Jt x0
    # = 0 at the optimum. But if the gradients are large, the 2nd-order dp
    # dependence isn't negligible, and I won't see 0
    delta = 1e-8
    x2,ivar2 = callback_perturbed_intrinsics(delta,0)
    dx2                = x2 - x0
    dx2_predicted      = J0[:,ivar2] * delta
    x2_predicted       = x0 + dx2_predicted
    dE2                = nps.norm2(x2)           - nps.norm2(x0)
    dE2_predicted      = nps.norm2(x2_predicted) - nps.norm2(x0)
    dE2_predicted_jtx  = 2 * nps.inner(x0, J0[:,ivar2]) * delta
    dE2_predicted_jtx2 = dE2_predicted_jtx + nps.norm2(dx2_predicted)
    print("Sanity check. Should be close to 0: {:.2g} {:.2g}". \
          format(dE2_predicted      - dE2,
                 dE2_predicted_jtx2 - dE2))
    print("Sanity check. It would be nice if it was close to 0, but maybe not: {:.2g}". \
          format(dE2_predicted_jtx - dE2))


    ###########################################################################
    # Fine. Let's make sure the noise propagation works as it should. First off,
    # is the implementation correct?
    Nintrinsics         = mrcal.getNlensParams(lensmodel)
    Nobservations_board = indices_frame_camera.shape[0]
    Nmeasurements_board = Nobservations_board * args.object_width_n * args.object_width_n * 2

    invJtJ = np.linalg.inv(nps.matmult(nps.transpose(J0), J0))
    J0obs = J0[:Nmeasurements_board,:]

    for icam in range(Ncameras):
        invJtJ_slice = invJtJ[Nintrinsics*icam:Nintrinsics*(icam+1),
                              Nintrinsics*icam:Nintrinsics*(icam+1)]
        err_inv_jtj_intrinsics = \
            np.linalg.norm(covariance_intrinsics[icam, ...]/(observed_pixel_uncertainty*observed_pixel_uncertainty) -
                           nps.matmult( invJtJ[Nintrinsics*icam:Nintrinsics*(icam+1),:],
                                        nps.transpose(J0obs),
                                        J0obs,
                                        invJtJ[:,Nintrinsics*icam:Nintrinsics*(icam+1)]))

        print("invjtj_intrinsics error (should be 0): {}".format(err_inv_jtj_intrinsics))

    err_inv_jtj_extrinsics = \
        np.linalg.norm(covariance_extrinsics/(observed_pixel_uncertainty*observed_pixel_uncertainty) -
                       nps.matmult( invJtJ[   Nintrinsics*Ncameras:Nintrinsics*Ncameras + 6*(Ncameras-1), :],
                                    nps.transpose(J0obs),
                                    J0obs,
                                    invJtJ[:, Nintrinsics*Ncameras:Nintrinsics*Ncameras + 6*(Ncameras-1)   ]))

    print("invJtJ_extrinsics error (should be 0): {}".format(err_inv_jtj_extrinsics))

    ###########################################################################
    # I confirmed that I'm computing what I thought I'm computing
    # So if I perturb my input observation vector qref by dqref, the resulting
    # effect on the parameters is dp = M dqref
    #
    #   where M = inv(JtJ) Jobservationst W
    def make_perturbation(stdev):
        return np.random.randn(Nmeasurements_board) * stdev

    def optimize_perturbed_observations(dqref):

        intrinsics_data_resolved = intrinsics[1].copy()
        extrinsics_resolved      = extrinsics.copy()
        frames_resolved          = frames.copy()
        calobject_warp_resolved  = calobject_warp.copy() if calobject_warp is not None else calobject_warp

        observations_perturbed_noweight = (observations[...,:2].ravel() + dqref).reshape(observations.shape[:-1] + (2,))
        observations_perturbed = nps.glue( observations_perturbed_noweight,
                                           observations[..., (2,)],
                                           axis = -1 )

        stats1 = mrcal.optimize(intrinsics_data_resolved,
                                extrinsics_resolved,
                                frames_resolved,
                                None,
                                observations_perturbed, indices_frame_camintrinsics_camextrinsics,
                                None, None,
                                lensmodel,
                                do_optimize_calobject_warp        = args.optimize_calobject_warp,
                                calobject_warp                    = calobject_warp_resolved,
                                imagersizes                       = imagersizes,
                                do_optimize_intrinsic_core        = not args.skip_intrinsics_solve,
                                do_optimize_intrinsic_distortions = not args.skip_intrinsics_solve,
                                do_optimize_extrinsics            = not args.skip_extrinsics_solve,
                                calibration_object_spacing        = args.object_spacing,
                                calibration_object_width_n        = args.object_width_n,
                                skip_outlier_rejection            = True, # use outliers in outlier_indices
                                skip_regularization               = args.skip_regularization,
                                outlier_indices                   = stats['outlier_indices'],
                                roi                               = roi,
                                get_covariances                   = False,
                                verbose                           = False,
                                solver_context                    = solver_context)
        return solver_context.p().copy()

    dqref = make_perturbation(1e-4)

    p1 = optimize_perturbed_observations(dqref)
    dp = p1-p0

    # Slow! Inefficient!
    w = observations[..., np.array((2,2))].ravel()
    M = np.linalg.solve( nps.matmult(nps.transpose(Joptimizer0),Joptimizer0),
                         nps.transpose(Joptimizer0[:Nmeasurements_board, :]) ) * w
    dp_predicted = nps.matmult( dqref, nps.transpose(M)).ravel()

    print("Popping up a plot of expected and observed dp. This should match well. Intrinsics may be a bit off")
    plot_dp = gp.gnuplotlib(title='Parameter shift due to input observations shift')
    plot_dp.plot(nps.cat(dp, dp_predicted), legend=np.array(('dp_reoptimized', 'dp_reoptimized_predicted')))


    ###########################################################################
    # Now I do a bigger, statistical thing. I compute many random perturbations
    # of the input, reoptimize for each, and look at how that affects a
    # particular projection point. I have a prediction on the variance that I
    # can check

    # where I'm evaluating the projection. I look at 1/3 (w,h). I'd like to be
    # in the center-ish, but not AT the center
    v0 = mrcal.unproject(imagersizes[0] / 3,
                         lensmodel, intrinsics[1][0])

    stdev = 1e-4
    q_sampled = np.zeros((100,Ncameras,2), dtype=float)
    Nintrinsics = intrinsics[1].shape[-1]
    for i in range(len(q_sampled)):
        p = optimize_perturbed_observations( make_perturbation(stdev) )
        solver_context.unpack(p)

        for icam in range(Ncameras):
            q_sampled[i,icam] = \
                mrcal.project(v0, lensmodel,
                              p[Nintrinsics*icam:Nintrinsics*(icam+1)])

    plot_distribution = [None] * Ncameras
    for icam in range(Ncameras):
        dq = q_sampled[:, icam, ...] - mrcal.project(v0, lensmodel, intrinsics[1][icam])

        dq_mean0 = dq - np.mean(dq,axis=-2)
        C = nps.matmult(nps.transpose(dq_mean0), dq_mean0)
        l,V = np.linalg.eig(C)
        l0 = l[0]
        l1 = l[1]
        V0 = V[:,0]
        V1 = V[:,1]
        if l0 < l1:
            l1,l0 = l0,l1
            V1,V0 = V0,V1

        Var = np.mean( nps.outer(dq_mean0,dq_mean0), axis=-3 )
        err_1sigma_observed_major       = np.sqrt(l0/q_sampled.shape[0])
        err_1sigma_observed_minor       = np.sqrt(l1/q_sampled.shape[0])
        err_1sigma_observed_anisotropic = np.diag(np.sqrt( Var ))
        err_1sigma_observed_isotropic   = np.sqrt( np.trace(Var) / 2. )

        err_1sigma_predicted_isotropic = \
            mrcal.compute_intrinsics_uncertainty(models[icam], v0,
                                                 focus_radius = 0) \
            / models[icam].observed_pixel_uncertainty() * stdev


        print("Noisy input, recalibration produced RMS reprojection error {:.2g} pixels. Predicted {:.2g} pixels". \
              format(err_1sigma_observed_isotropic,
                     err_1sigma_predicted_isotropic))
        plot_distribution[icam] = gp.gnuplotlib(square=1, title='Uncertainty reprojection distribution for camera {}'.format(icam))
        plot_distribution[icam]. \
            plot( (dq[:,0], dq[:,1], dict(_with='points pt 7 ps 2')),
                  (0,0, 2*err_1sigma_observed_major, 2*err_1sigma_observed_minor, 180./np.pi*np.arctan2(V0[1],V0[0]),
                   dict(_with='ellipses lw 2', tuplesize=5, legend='Observed 1-sigma, full covariance')),
                  (0,0, 2*err_1sigma_observed_anisotropic[0], 2*err_1sigma_observed_anisotropic[1],
                   dict(_with='ellipses lw 2', tuplesize=4, legend='Observed 1-sigma, independent x,y')),
                  (0,0, err_1sigma_observed_isotropic,
                   dict(_with='circles lw 2', tuplesize=3, legend='Observed 1-sigma; isotropic')),
                  (0,0, err_1sigma_predicted_isotropic,
                   dict(_with='circles lw 2', tuplesize=3, legend='Predicted 1-sigma; isotropic')))

    import IPython
    IPython.embed()
    sys.exit()




def _get_show_residuals_data(i_camera, focus_center, focus_radius, show_all_reproj_errors):
    r'''Return the data used by the various show_residuals() functions'''

    if i_camera < 0: i_camera = 0 # first camera by default

    # I have a bunch of errors in reproj_err_including_outliers. I need to pick out
    # - the ones for THIS camera (if requested)
    # - the non-outliers         (if requested)
    #
    # The "for this camera" part is specified in indices_frame_camera. This
    # indexes FRAMES
    #
    # The "outlier" part is given by stats['outlier_indices']. This indexes
    # FEATURES (each feature is 2 measurements: x,y).
    #
    # I construct a feature index map, fill it in with both filters, and use it
    # to pull out the correct data

    # all true by default, cutting out the last dimension: x,y
    idx = np.ones( reproj_err_including_outliers.shape[:-1], dtype=bool)

    if i_camera >= 0:
        idx[indices_frame_camera[:,1] != i_camera, ...] = False

    if not show_all_reproj_errors:
        nps.clump(idx, n=3)[stats['outlier_indices']] = False
        err = measurements_0_for_outliers[idx, ...]
    else:
        err = reproj_err_including_outliers[idx, ...]

    obs = observations[idx, ..., :2]

    W,H=imagersizes[i_camera]
    if focus_center is None:
        focus_center = (imagersizes[i_camera]-1.)/2.
    if focus_radius == 0:
        # I use all the data
        pass
    else:
        if focus_radius < 0:
            focus_radius = min(imagersizes[i_camera])/6
        idx = nps.norm2(obs - focus_center) < focus_radius*focus_radius
        obs = obs[idx, ...]
        err = err[idx, ...]
    # err,obs are now both of shape (N,2). Each slice is xy

    valid_intrinsics_region_plotarg = None
    if i_camera >= 0:
        valid_intrinsics_region_plotarg_3d = \
            (valid_intrinsics_region[i_camera][:,0],
             valid_intrinsics_region[i_camera][:,1],
             np.zeros(valid_intrinsics_region[i_camera].shape[-2]),
             dict(_with  = 'lines lw 3',
                  legend = "Valid-intrinsics region")) if valid_intrinsics_region[i_camera] is not None else None
        valid_intrinsics_region_plotarg_2d = \
            (valid_intrinsics_region[i_camera][:,0],
             valid_intrinsics_region[i_camera][:,1],
             dict(_with  = 'lines lw 3',
                  legend = "Valid-intrinsics region")) if valid_intrinsics_region[i_camera] is not None else None

    return i_camera,err,obs,W,H,focus_center,focus_radius,valid_intrinsics_region_plotarg_2d,valid_intrinsics_region_plotarg_3d


plots_residuals = dict()
def show_residuals(how, i_camera = 0, focus_center=None, focus_radius=0,
                   vectorscale = 1.0,
                   show_all_reproj_errors=False, **kwargs):

    r'''Visualize the optimized reprojection errors

    This function visualizes the solution in several ways, selected by the 'how'
    argument.

      if how == 'vectorfield': we plot a vectorfield, showing each observed
                               point, and its reprojection discrepancy

      if how == 'heatmap':     we plot each observed point, but instead of showing
                               an error vector, we render a point that's
                               color-coded with its error
      elif how == 'directions':we plot each observed point, but instead of showing
                               an error vector, we show the color-coded
                               direction of the error. The error magnitude is
                               ignored. This is useful to see systematic
                               patterns in the error surface

    i_camera is the camera in question. First camera by default

    if show_all_reproj_errors: we show the distribution of REPROJECTION ERRORS,
    INCLUDING OUTLIERS. This is not what was optimized: the optimization ignored
    outliers, and errors were scaled to trust poor corner detections less.

    if not show_all_reproj_errors: we show what was actually optimized. The
    outliers do not appear, and the errors are scaled. This is the default

    '''

    global plots_residuals
    if not how in plots_residuals:
        plots_residuals[how] = [None] * (Ncameras+1)
    plots_how = plots_residuals[how]

    i_camera,err,obs, \
        W, \
        H, \
        focus_center, \
        focus_radius, \
        valid_intrinsics_region_plotarg_2d, \
        valid_intrinsics_region_plotarg_3d = \
            _get_show_residuals_data(i_camera, focus_center, focus_radius, show_all_reproj_errors)

    if how == 'vectorfield':
        plots_how[i_camera+1] = \
            gp.gnuplotlib( square=1,
                           _xrange=[0,W], yrange=[H,0],
                           title = 'Fitted reprojection errors {}. Errors shown as vectors and colors'. \
                           format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                           xlabel = 'Imager x',
                           ylabel = 'Imager y',
                           **kwargs)
        plot_data_args = [(obs[:,0], obs[:,1],
                           vectorscale*err[:,0], vectorscale*err[:,1],
                           np.sqrt(nps.norm2(err)),
                           dict(_with='vectors size screen 0.01,20 fixed filled palette',
                                tuplesize=5))]
        if valid_intrinsics_region_plotarg_2d is not None:
            plot_data_args.append(valid_intrinsics_region_plotarg_2d)
        plots_how[i_camera+1].plot(*plot_data_args)
    if how == 'heatmap':
        plots_how[i_camera+1] = \
            gp.gnuplotlib( square=1,
                           _xrange=[0,W], yrange=[H,0],
                           title = 'Fitted reprojection errors {}. Errors shown as colors'. \
                           format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                           xlabel = 'Imager x',
                           ylabel = 'Imager y',
                           **kwargs)
        plot_data_args = [( obs[:,0], obs[:,1], np.sqrt(nps.norm2(err)),
                            dict(_with='points pt 7 palette',
                                 tuplesize=3))]
        if valid_intrinsics_region_plotarg_2d is not None:
            plot_data_args.append(valid_intrinsics_region_plotarg_2d)
        plots_how[i_camera+1].plot(*plot_data_args)
    elif how == 'directions':
        plots_how[i_camera+1] = \
            gp.gnuplotlib( square=1,
                           _xrange=[0,W], yrange=[H,0],
                           title = 'Fitted reprojection errors {}. Directions shown as colors. Magnitudes ignored'. \
                           format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                           xlabel = 'Imager x',
                           ylabel = 'Imager y',

                           # Use an maximum-saturation, maximum-value HSV
                           # palette where the hue encodes the error direction.
                           # The direction is periodic, as is the hue
                           _set='palette defined ( 0 "#00ffff", 0.5 "#80ffff", 1 "#ffffff") model HSV',
                           cbrange = [-180., 180.],
                           **kwargs)
        plot_data_args = [( obs[:,0], obs[:,1], 180./np.pi * np.arctan2(err[...,1], err[...,0]),
                            dict(_with='points pt 7 palette',
                                 tuplesize=3))]
        if valid_intrinsics_region_plotarg_2d is not None:
            plot_data_args.append(valid_intrinsics_region_plotarg_2d)
        plots_how[i_camera+1].plot(*plot_data_args)

    else:
        raise Exception("Unknown visualization method '{}'. I know of 'vectorfield','heatmap','histogram','radial','regional'". \
                        format(how))

plots_residuals_radial = None
def show_residuals_radial(i_camera = 0, focus_center=None, focus_radius=0,
                          show_all_reproj_errors=False, **kwargs):

    r'''Visualize the optimized reprojection errors, looking at distance-from-center

    Plot residuals against distance from the center. If focus_center is not
    None, we use that; otherwise we use the imager center

    i_camera is the camera in question. First camera by default

    if show_all_reproj_errors: we show the distribution of REPROJECTION ERRORS,
    INCLUDING OUTLIERS. This is not what was optimized: the optimization ignored
    outliers, and errors were scaled to trust poor corner detections less.

    if not show_all_reproj_errors: we show what was actually optimized. The
    outliers do not appear, and the errors are scaled. This is the default

    '''

    global plots_residuals_radial
    if plots_residuals_radial is None:
        plots_residuals_radial = [None] * (Ncameras+1)

    i_camera,err,obs, \
        W, \
        H, \
        focus_center, \
        focus_radius, \
        valid_intrinsics_region_plotarg_2d, \
        valid_intrinsics_region_plotarg_3d = \
            _get_show_residuals_data(i_camera, focus_center, focus_radius, show_all_reproj_errors)

    r = np.sqrt(nps.norm2(obs - focus_center))
    plots_residuals_radial[i_camera+1] = \
        gp.gnuplotlib(
            title = 'Fitted reprojection errors shown against distance from {}. Data from {}'. \
            format( focus_center, 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
            xlabel = 'Distance from {} (pixels)'.format(focus_center),
            ylabel = 'Reprojection error (pixels). x and y components of error are counted separately',
            **kwargs)
    plots_residuals_radial[i_camera+1]. \
        plot( nps.transpose(nps.cat(r,r)).ravel(),
              err.ravel(),
              _with='points')


plots_residuals_regional = None
def show_residuals_regional(i_camera = 0, focus_center=None, focus_radius=0,
                            show_all_reproj_errors=False, **kwargs):

    r'''Visualize the optimized reprojection errors, broken up by region

    Plots residuals grouped by discrete regions of the image. Useful to see
    specifically where the fit is poor

    i_camera is the camera in question. First camera by default

    if show_all_reproj_errors: we show the distribution of REPROJECTION ERRORS,
    INCLUDING OUTLIERS. This is not what was optimized: the optimization ignored
    outliers, and errors were scaled to trust poor corner detections less.

    if not show_all_reproj_errors: we show what was actually optimized. The
    outliers do not appear, and the errors are scaled. This is the default

    '''

    global plots_residuals_regional
    if plots_residuals_regional is None:
        plots_residuals_regional = [None] * (Ncameras+1)

    i_camera,err,obs, \
        W, \
        H, \
        focus_center, \
        focus_radius, \
        valid_intrinsics_region_plotarg_2d, \
        valid_intrinsics_region_plotarg_3d = \
            _get_show_residuals_data(i_camera, focus_center, focus_radius, show_all_reproj_errors)


    if i_camera < 0:
        raise Exception("Regional visualization for 'all' cameras at once isn't useful. Pass i_camera >= 0")

    mean,stdev,count,using = \
        mrcal.report_residual_statistics(obs,err,
                                         imagersizes[i_camera])
    def mkplot(x, title, **kwargs_here):
        kwargs_here.update(kwargs)
        if 'hardcopy' in kwargs_here:
            what = re.sub('[^a-zA-Z0-9_-]+', '_', title)
            kwargs_here['hardcopy'] = re.sub(r'(\.[^\.]+$)', '.' + what + r'\1', kwargs_here['hardcopy'])

        p = gp.gnuplotlib( _3d=1,
                           ascii=1,
                           unset='grid',
                           _xrange=[0,W], _yrange=[H,0],
                           _set = ['xrange [:] noextend',
                                   'yrange [:] noextend reverse',
                                   'view equal xy',
                                   'view map'],
                           title = title,
                           **kwargs_here)
        plot_data_args = [( nps.transpose(x),
                            dict(tuplesize=3,
                                 _with='image',
                                 using=using))]
        if valid_intrinsics_region_plotarg_3d is not None:
            plot_data_args.append(valid_intrinsics_region_plotarg_3d)
        p.plot(*plot_data_args)
        return p

    plots_residuals_regional[i_camera+1] = [ mkplot(np.abs(mean), 'abs(mean)'),
                                             mkplot(stdev,        'stdev'),
                                             mkplot(count,        'count', cbrange = (0, 20)) ]


plots_residuals_histogram = None
def show_residuals_histogram(i_camera = 0, focus_center=None, focus_radius=0, binwidth=0.02,
                             show_all_reproj_errors=False, **kwargs):

    r'''Visualize the histogram of the optimized reprojection errors

    We show a histogram of residuals and overlay it with an idealized
    distribution. If the optimization was successful, and if
    observed_pixel_uncertainty was correct, the two should line up.

    i_camera is the camera in question. First camera by default

    if show_all_reproj_errors: we show the distribution of REPROJECTION ERRORS,
    INCLUDING OUTLIERS. This is not what was optimized: the optimization ignored
    outliers, and errors were scaled to trust poor corner detections less.

    if not show_all_reproj_errors: we show what was actually optimized. The
    outliers do not appear, and the errors are scaled. This is the default

    '''

    global plots_residuals_histogram
    if plots_residuals_histogram is None:
        plots_residuals_histogram = [None] * (Ncameras+1)

    i_camera,err,obs, \
        W, \
        H, \
        focus_center, \
        focus_radius, \
        valid_intrinsics_region_plotarg_2d, \
        valid_intrinsics_region_plotarg_3d = \
            _get_show_residuals_data(i_camera, focus_center, focus_radius, show_all_reproj_errors)

    x = err.ravel()
    N = len(x)

    sigma_expected = args.observed_pixel_uncertainty
    sigma_observed = np.std(x)
    from scipy.special import erf

    def make_gaussian(sigma,title):
        # I want to plot a PDF of a normal distribution together with the
        # histogram to get a visual comparison. This requires a scaling on
        # either the PDF or the histogram. I plot a scaled pdf:
        #
        #   f = k*pdf = k * exp(-x^2 / (2 s^2)) / sqrt(2*pi*s^2)
        #
        # I match up the size of the central bin of the histogram (-binwidth/2,
        # binwidth/2):
        #
        #   bin(0) ~ k*pdf(0) ~ pdf(0) * N * binwidth
        #
        # So k = N*binwdith should work. I can do this more precisely:
        #
        #   bin(0) ~ k*pdf(0) ~
        #     = N * integral( pdf(x) dx,                                -binwidth/2, binwidth/2)
        #     = N * integral( exp(-x^2 / (2 s^2)) / sqrt( 2*pi*s^2) dx, -binwidth/2, binwidth/2)
        # ->k = N * integral( exp(-x^2 / (2 s^2)) / sqrt( 2*pi*s^2) dx, -binwidth/2, binwidth/2) / pdf(0)
        #     = N * integral( exp(-x^2 / (2 s^2)) dx,                   -binwidth/2, binwidth/2)
        #     = N * integral( exp(-(x/(sqrt(2) s))^2) dx )
        #
        # Let u  = x/(sqrt(2) s)
        #     du = dx/(sqrt(2) s)
        #     u(x = binwidth/2) = binwidth/(s 2sqrt(2)) ->
        #
        #   k = N * sqrt(2) s * integral( exp(-u^2) du )
        #     = N*sqrt(2pi) s * erf(binwidth / (s 2*sqrt(2)))
        #
        # for low x erf(x) ~ 2x/sqrt(pi). So if binwidth << sigma
        # k = N*sqrt(2pi) s * erf(binwidth / (s 2*sqrt(2)))
        #   ~ N*sqrt(2pi) s * (binwidth/(s 2*sqrt(2))) *2 / sqrt(pi)
        #   ~ N binwidth
        return \
            '{k}*exp(-(x-{mean})*(x-{mean})/(2.*{var})) / sqrt(2.*pi*{var}) title "{title}" with lines lw 2'. \
            format(mean= 0,
                   var = sigma*sigma,
                   title = title,
                   k   = N * np.sqrt(2.*np.pi) * sigma * erf(binwidth/(2.*np.sqrt(2)*sigma)))

    equations = [make_gaussian(sigma,title) for sigma,title in \
                 ( (sigma_expected, 'Normal distribution of residuals with expected stdev: {:.02f} pixels'.format(sigma_expected)),
                   (sigma_observed, 'Normal distribution of residuals with observed stdev: {:.02f} pixels'.format(sigma_observed)))]
    plots_residuals_histogram[i_camera+1] = \
        gp.gnuplotlib(equation_above = equations,
                      title = 'Observed and expected distribution of fitted reprojection errors {}'. \
                      format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                      xlabel = 'Reprojection error (pixels). x and y components of error are counted separately',
                      ylabel = 'Observed frequency',
                      **kwargs)
    plots_residuals_histogram[i_camera+1].plot(x, histogram=1, binwidth=binwidth,)


plots_intrinsics_uncertainty = [None] * Ncameras
def show_intrinsics_uncertainty(i_camera = None, outlierness = False, gridn_x = 60, gridn_y = 40, **kwargs):

    if covariance_intrinsics is None:
        print("No intrinsics uncertainty was computed. You need to call mrcal.optimize(..., get_covariances = True) for this to work")
        return False


    global plots_intrinsics_uncertainty
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))
    for i_camera in i_camera_all:
        plots_intrinsics_uncertainty[i_camera] = \
            mrcal.show_intrinsics_uncertainty(models[i_camera],
                                              outlierness,
                                              extratitle = "Camera {} with {}".format(i_camera, intrinsics[0]),
                                              gridn_x=gridn_x,
                                              gridn_y=gridn_y,
                                              **kwargs)
plots_valid_intrinsics_region = [None] * Ncameras
def show_valid_intrinsics_region(i_camera = None, **kwargs):
    global plots_valid_intrinsics_region
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))
    for i_camera in i_camera_all:
        plots_valid_intrinsics_region[i_camera] = \
            mrcal.show_valid_intrinsics_region(models[i_camera],
                                               title = "Valid-intrinsics region for camera {}".format(i_camera),
                                               **kwargs)

plots_distortion = [None] * Ncameras
def show_distortion(mode, i_camera = None, gridn_x = 60, gridn_y = 40, **kwargs):

    global plots_distortion
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))
    for i_camera in i_camera_all:
        plots_distortion[i_camera] = \
            mrcal.show_distortion(models[i_camera],
                                  mode,
                                  extratitle = "camera {}".format(i_camera),
                                  gridn_x=gridn_x,
                                  gridn_y=gridn_y,
                                  **kwargs)

plots_splined_model_surface = [None] * Ncameras
def show_splined_model_surface(i_camera = None, i_xy=0, **kwargs):

    global plots_splined_model_surface
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))
    for i_camera in i_camera_all:
        plots_splined_model_surface[i_camera] = \
            mrcal.show_splined_model_surface(models[i_camera], i_xy,
                                             extratitle = "camera {}".format(i_camera),
                                             **kwargs)

plots_roi = [None] * Ncameras
def show_roi(i_camera = None, **kwargs):
    global plots_roi
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))

    NboardPoints     = args.object_width_n*args.object_width_n
    Nfeatures        = NboardPoints*len(observations)
    feats            = observations[..., :2].reshape(Nfeatures,2)

    def append_icamera(iFeatures):
        '''input: (N,) array of feature indices; output: (2,N) array of feature,camera indices)'''
        iObservations = iFeatures / NboardPoints
        iObservations = iObservations.astype(int)
        iCamera = np.array([indices_frame_camera[iObs,1] for iObs in iObservations])
        return nps.cat(iFeatures, iCamera)

    iFeature_roi_out = append_icamera(stats['outside_ROI_indices'])
    iFeature_roi_in  = append_icamera(np.setdiff1d(np.arange(Nfeatures), iFeature_roi_out[0,:]))

    for i_camera in i_camera_all:

        iFeature_roi_in_thiscam  = iFeature_roi_in [ 0, iFeature_roi_in [1,:] == i_camera]
        iFeature_roi_out_thiscam = iFeature_roi_out[ 0, iFeature_roi_out[1,:] == i_camera]

        plots_roi[i_camera] = \
            gp.gnuplotlib(square=1, xrange=(0,imagersizes[i_camera,0]-1),yrange=(imagersizes[i_camera,1]-1,0), _with='points pt 7 ps 2',
                          **kwargs)
        plots_roi[i_camera]. \
            plot( (feats[iFeature_roi_in_thiscam, 0], feats[iFeature_roi_in_thiscam, 1], dict(legend='in' )),
                  (feats[iFeature_roi_out_thiscam,0], feats[iFeature_roi_out_thiscam,1], dict(legend='out')) )

plot_calibration_geometry = None
def show_calibration_geometry(**kwargs):
    global plot_calibration_geometry
    plot_calibration_geometry = \
        mrcal.show_calibration_geometry(models,
                                        [f"camera {i}" for i in range(len(models))],
                                        frames=frames,
                                        object_spacing=args.object_spacing)

import IPython
IPython.embed()
