#!/usr/bin/python3

r'''Calibrate some synchronized cameras

SYNOPSIS

  $ mrcal-calibrate-cameras
      --corners-cache corners.vnl
      --focal 1700 --object-spacing 0.01 --object-width-n 10
      --outdir /tmp
      --distortion-model DISTORTION_OPENCV8
      --observed-pixel-uncertainty 0.5
      'left*.png' 'right*.png'

    ... lots of output as the solve runs ...
    Done!
    RMS reprojection error: 1.9 pixels
    Worst reprojection error: 7.8 pixels
    Noutliers: 319 out of 17100 total points: 1.9% of the data

    Wrote /tmp/camera0-0.cahvor
    Wrote /tmp/camera0-1.cahvor
    Wrote /tmp/camera0-0.cameramodel
    Wrote /tmp/camera0-1.cameramodel

This tool uses the generic mrcal platform to solve a common specific problem of
N-camera calibration using observations of a chessboard.


TUTORIAL

If all you want to do is run a calibration, read this section first.

You need to get observations of a grid of points. This tool doesn't dictate
exactly how these observations are obtained, but the recommended way to do that
is to use mrgingham (http://github.com/dkogan/mrgingham). This documentation
assumes that's what is being done.

See the mrgingham documentation for a .pdf of a chessboard pattern. This pattern
should be printed (at some size; see below) and mounted onto a RIGID and FLAT
surface to produce the calibration object. The most useful observations are
close-ups: views that cover as much of the imager as possible. Thus you
generally a large printout of the chessboard pattern. If you're calibrating a
wide lens then this is especially true: the wider the lens, the larger an object
needs to be in order to cover the field of view.

Now that we have a calibration object, this object needs to be shown to the
camera(s) to produce the images that mrgingham will use to find the corner
coordinates, which mrcal will then use in its computations.

It is important that the images contain clear corners. If the image is badly
overexposed, the white chessboard squares will bleed into each other, the
adjoining black squares will no longer touch each other in the image, and there
would be no corner to detect. Conversely, if the image is badly underexposed,
the black squares will bleed into each other, which would also destroy the
corner. mrgingham tries to handle a variety of lighting conditions, including
varying illuination across the image, but the corners must exist in the image in
some form. A fundamental design decision in mrgingham is to only output
chessboards that we are very confident in, and a consequence of this is that
mrgingham requires the WHOLE chessboard to be visible in order to produce any
results. Thus it requires a bit of effort to produce any data at the edges and
in the corners of the imager: if even a small number of the chessboard corners
are out of bounds, mrgingham will not detect the chessboard at all. A live
preview of the calibration images being gathered is thus essential to aid the
user in obtaining good data. Another requirement due to the design of mrgingham
is that the board should be held with a flat edge parallel to the camera xz
plane (parallel to the ground, usually). mrgingham looks for vertical and
horizontal sequences of corners, but if the board is rotated in this way, then
none of these sequences are "horizontal" or "vertical", but they're all
"diagonal", which isn't what mrgingham is looking for.

The most useful observations to gather are

- close-ups: the chessboard should fill the whole frame as much as possible

- oblique views: tilt the board forward/back and left/right. I generally tilt by
  more than 45 degrees. At a certain point the corners become indistinct and
  mrgingham starts having trouble, but depending on the lens, that point could
  come with quite a bit of tilt.

- If you are calibrating multiple cameras, and they are synchronized, you can
  calibrate them all at the same time, and obtain intrinsics AND extrinsics. In
  that case you want frames where multiple cameras see the calibration object at
  the same time. Depending on the geometry, it may be impossible to place a
  calibration object in a location where it's seen by all the cameras, AND where
  it's a close-up for all the cameras at the same time. In that case, get
  close-ups for each camera individually, and get observations common to
  multiple cameras, that aren't necessarily close-ups. The former will serve to
  define your camera intrinsics, and the latter will serve to define your
  extrinsics (geometry).

A dataset composed primarily of tilted closeups will produce good results. It is
better to have more data rather than less. mrgingham will throw away frames
where no chessboard can be found, so it is perfectly reasonable to grab too many
images with the expectation that they won't all end up being used in the
computation.

I usually aim for about 100 usable frames, but you can often get away with far
fewer. The mrcal confidence feedback (see below) will tell you if you need more
data.

Once we have gathered input images, we can run the calibration procedure:

  mrcal-calibrate-cameras
    --corners-cache corners.vnl
    -j 10
    --focal 2000
    --object-spacing 0.1
    --object-width-n 10
    --outdir /tmp
    --distortion-model DISTORTION_OPENCV8
    --observed-pixel-uncertainty 1.0
    --explore
    'frame*-camera0.png' 'frame*-camera1.png' 'frame*-camera2.png'

You would adjust all the arguments for your specific case.

The first argument says that the chessboard corner coordinates live in a file
called "corners.vnl". If this file exists, we'll use that data. If that file
does not exist (which is what will happen the first time), mrgingham will be
invoked to compute the corners from the images, and the results will be written
to that file. So the same command is used to both compute the corners initially,
and to reuse the pre-computed corners with subsequent runs.

'-j 10' says to spread the mrgingham computation across 10 CPU cores. This
command controls mrgingham only; if 'corners.vnl' exists, this option does
nothing.

'--focal 2000' says that the initial estimate for the camera focal lengths is
2000 pixels. This doesn't need to be precise at all, but do try to get this
roughly correct if possible. Simple geometry says that

  focal_length = imager_width / ( 2 tan (field_of_view_horizontal / 2) )

--object-spacing is the width of each square in your chessboard. This depends on
the specific chessboard object you are using. --object-width-n is the corner
count of the calibration object. Currently mrgingham more or less assumes that
this is 10.

--outdir specifies the directory where the output models will be written

--distortion-model specifies which distortion model we're using for the cameras.
At this time all OpenCV distortion models are supported, in addition to
DISTORTION_CAHVOR. The CAHVOR model is there for legacy compatibility only. If
you're not going to be using these models in a system that only supports CAHVOR,
there's little reason to use it. If you use a model that is too lean
(DISTORTION_NONE or DISTORTION_OPENCV4 maybe), the model will not fit the data,
especially at the edges; the tool will tell you this. If you use a model that is
too rich (something crazy like DISTORTION_OPENCV14), then you will need much
more data than you normally would. Most lenses I've seen work well with
DISTORTION_OPENCV4 or DISTORTION_OPENCV5 or DISTORTION_OPENCV8; wider lenses
need richer models.

'--observed-pixel-uncertainty 1.0' says that the x,y corner coordinates reported
by mrgingham are distributed normally, independently, and with the standard
deviation as given in this argument. There's a tool to compute this value
empirically, but it needs more validation. For now pick a value that seems
reasonable. 1.0 pixels or less usually makes sense.

--explore says that after the models are computed, a REPL should be open so that
the user can look at various metrics describing the output; more on this
later.

After all the options, globs describing the images are passed in. Note that
these are GLOBS, not FILENAMES. So you need to quote or escape each glob to
prevent the shell from expanding it. You want one glob per camera; in the above
example we have 3 cameras. The program will look for all files matching the
globs, and filenames with identical matched strings are assumed to have been
gathered at the same instant in time. I.e. if in the above example we found
frame003-camera0.png and frame003-camera1.png, we will assume that these two
images were time-synchronized. If your capture system doesn't have
fully-functional frame syncronization, you should run a series of monocular
calibrations. Otherwise the models won't fit well (high reprojection errors
and/or high outlier counts) and you might see a frame with systematic
reprojection errors where one supposedly-synchronized camera's observation pulls
the solution in one direction, and another camera's observation pulls it in
another.

When you run the program as given above, the tool will spend a bit of time
computing (usually 10-20 seconds is enough, but this is highly dependent on the
specific problem, the amount of data, and the computational hardware). When
finished, it will write the resulting models to disk, and open a REPL (if
--explore was given). Models are written in both .cahvor and .cameramodel file
formats. Both contain the same information, but .cameramodel is far more
sensible. The .cahvor file format exists for legacy compatibility only. Use this
one one only if you'll be using these models in some cahvor-only tool; in this
case you'll probably want to choose the DISTORTION_CAHVOR model as well. The
resulting filenames are "camera-N.cameramodel" where N is the index of the
camera, starting at 0. The models contain the intrinsics and extrinsics, with
camera-0 sitting at the reference coordinate system.

When the solve is completed, you'll see a summary such as this one:

    RMS reprojection error: 0.3 pixels
    Worst reprojection error: 4.0 pixels
    Noutliers: 7 out of 9100 total points: 0.1% of the data

The reprojection errors should look reasonable given your
--observed-pixel-uncertainty. Since any outliers will be thrown out, the
reported reprojection errors will be reasonable.

Higher outlier counts are indicative of some/all of these:

- Errors in the input data, such as incorrectly-detected chessboard corners, or
  unsynchronized cameras

- Badly-fitting distortion model

A distortion model that doesn't fit isn't a problem in itself. The results will
simply not be reliable everywhere in the imager, as indicated by the uncertainty
and residual metrics (see below)

With --explore you get a REPL, and a message that points out some useful
functions. Generally you want to start with

    show_residuals_observation_worst(0)

This will show you the worst-fitting chessboard observation with its observed
and predicted corners, as an error vector. The reprojection errors are given by
a colored dot. Corners thrown out as outliers will be missing their colored dot.
You want to make sure that this is reasonable. Incorrectly-detected corners will
be visible: they will be outliers or they will have a high error. The errors
should be higher towards the edge of the imager, especially with a wider lens. A
richer better-fitting model would reduce those errors. Past that, there should
be no pattern to the errors. If the camera synchronization was broken, you'll
see a bias in the error vectors, to compensate for the motion of the chessboard.

Next do this for each camera in your calibration set (i_camera is an index
counting up from 0):

    show_residuals('regional', i_camera)

Each of these will pop up 3 plots describing your distribution of errors. You
get

- a plot showing the mean reprojection error across the imager
- a plot showing the standard deviation of reprojection errors across the imager
- a plot showing the number of data points across the imager AFTER the outlier
  rejection

The intrinsics are reliable in areas that have

- a low mean error relative to --observed-pixel-uncertainty
- a standard deviation roughly similar to --observed-pixel-uncertainty
- have some data available

If you have too little data, you will be overfitting, so you'd be expalining the
signal AND the noise, and your reprojection errors will be too low. With enough
input data you'll be explaining the signal only: the noise is random and with
enough samples our model can't explain it. Another factor that controls this is
the model we're fitting. If we fit a richer model (DISTORTION_OPENCV8 vs
DISTORTION_OPENCV4 for instance), the extra parameters will allow us to fit the
data better, and to produce lower errors in more areas of the imager.

These are very rough guidelines; I haven't written the logic to automatically
interpret these yet. A common feature that these plots bring to light is a
poorly-fitting model at the edges of the imager. In that case you'll see higher
errors with a wider distribution towards the edge.

Finally run this:

    show_intrinsics_uncertainty()

This will pop up a plot of projection uncertainties for each camera. The
uncertainties are shown as a color-map along with contours. These are the
expected value of projection based on noise in input corner observations. The
noise is assumed to be independent, 0-mean gaussian with a standard deviation of
--observed-pixel-uncertainty. You will see low uncertainties in the center of
the imager (this is the default focus point; a different one can be picked). As
you move away from the center, you'll see higher errors. You should decide how
much error is acceptable, and determine the usable area of the imager based on
this. These uncertainty metrics are complementary to the residual metrics
described above. If you have too little data, the residuals will be low, but the
uncertainties will be very high. The more data you gather, the lower the
uncertainties. A richer distortion model lowers the residuals, but raises the
uncertainties. So with a richer model you need to get more data to get to the
same acceptable uncertainty level. The uncertainties are all determined relative
to some focus point. If you care about the calibration accuracy in a particular
area of the imager, do something like this instead:

    show_intrinsics_uncertainty( focus_center = np.array((1000,2000))) )

'''

from __future__ import print_function

import sys
import argparse
import re
import os

def parse_args():

    def positive_float(string):
        try:
            value = float(string)
        except:
            raise argparse.ArgumentTypeError("argument MUST be a positive floating-point number. Got '{}'".format(string))
        if value <= 0:
            raise argparse.ArgumentTypeError("argument MUST be a positive floating-point number. Got '{}'".format(string))
        return value
    def positive_int(string):
        try:
            value = int(string)
        except:
            raise argparse.ArgumentTypeError("argument MUST be a positive integer. Got '{}'".format(string))
        if value <= 0 or abs(value-float(string)) > 1e-6:
            raise argparse.ArgumentTypeError("argument MUST be a positive integer. Got '{}'".format(string))
        return value


    parser = \
        argparse.ArgumentParser(description = __doc__,
                                formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--focal',
                        type=float,
                        default=1970,
                        required=True,
                        help='Initial estimate of the focal length, in pixels')
    parser.add_argument('--imagersize',
                        nargs=2,
                        type=int,
                        required=False,
                        help='''Size of the imager. This is only required if we pass --corners-cache AND if none
                        of the image files on disk actually exist''')
    parser.add_argument('--outdir',
                        type=lambda d: d if os.path.isdir(d) else \
                                parser.error("--outdir requires an existing directory as the arg, but got '{}'".format(d)),
                        default='.',
                        help='Directory for the output camera models')
    parser.add_argument('--object-spacing',
                        required=False,
                        type=float,
                        help='Width of each square in the calibration board, in meters')
    parser.add_argument('--object-width-n',
                        type=int,
                        default=10,
                        help='How many points the calibration board has per side')
    parser.add_argument('--distortion-model',
                        required=False,
                        default='DISTORTION_OPENCV4',
                        help='''Which distortion model we're using. By default I use DISTORTION_OPENCV4''')
    parser.add_argument('--roi',
                        nargs=4,
                        type=float,
                        action='append',
                        required=False,
                        help='''Region of interest of the calibration. This is the area in the imager we're
                        interested in. Errors in observations outside this area
                        will be attenuated significantly. If we want to use all
                        the data evenly, omit this argument. Otherwise pass 4
                        values for each --roi:
                        (x_center,y_center,x_radius,y_radius). The region is an
                        axis-aligned ellipsoid. If passing in ANY roi, you MUST
                        pass in the ROI for EACH camera; a separate '--roi' for
                        each one.''')
    parser.add_argument('--incremental',
                        required=False,
                        default=False,
                        action='store_true',
                        help='''If passed, we incrementally increase ROI and distortion model complexity
                        across multiple solves. In this mode the requested ROI
                        is a target, and the requested distortion model is the
                        upper bound. If we can get away with a simpler one, we
                        use that.''')
    parser.add_argument('--num-cross-validation-splits',
                        required=False,
                        default=1,
                        type=positive_int,
                        help='''If passed, we cross-validate the results with this many splits. This only
                        makes sense as an integer >1. THIS IS EXPERIMENTAL.''')
    parser.add_argument('--jobs', '-j',
                        type=int,
                        default=1,
                        help='''How much parallelization we want. Like GNU make. Affects only the chessboard
                        corner finder. If we are reading a cache file, this does nothing''')
    parser.add_argument('--corners-cache',
                        type=lambda f: f if os.path.isfile(f) or not os.path.isdir(f) else \
                                parser.error("--corners-cache requires an existing, readable file as the arg or a non-existing path, but got '{}'".format(f)),
                        required=False,
                        help='Path to read corner-finder data from or (if path does not exist) to write data to')

    parser.add_argument('--skip-regularization',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we apply regularization to the solver. This option turns that
                        off''')

    parser.add_argument('--skip-outlier-rejection',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we throw out outliers. This option turns that off''')

    parser.add_argument('--verbose-solver',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default the final stage of the solver doesn't say much. This option turns
                        on verbosity to get lots of diagnostics.''')

    parser.add_argument('--optimize-calobject-warp',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''By default we assume the calibration target is flat. If it isn't and we want
                        to compute it, pass this option.''')

    parser.add_argument('--explore',
                        action='store_true',
                        required=False,
                        default=False,
                        help='''After the solve open an interactive shell to examine the solution''')
    parser.add_argument('--observed-pixel-uncertainty',
                        type=positive_float,
                        required=True,
                        help='''The standard deviation of x and y pixel coordinates of the input
                        observations. The distribution of the inputs is assumed
                        to be gaussian, with the standard deviation specified by
                        this argument. Note: this is the x and y standard
                        deviation, treated independently. If each of these is s,
                        then the LENGTH of the deviation of each pixel is a
                        Rayleigh distribution with expected value s*sqrt(pi/2) ~
                        s*1.25''')

    parser.add_argument('images',
                        type=str,
                        nargs='+',
                        help='''A glob-per-camera for the images. Include a glob for each camera. It is
                        assumed that the image filenames in each glob are of of
                        the form xxxNNNyyy where xxx and yyy are common to all
                        images in the set, and NNN varies. This NNN is a frame
                        number, and identical frame numbers across different
                        globs signify a time-synchronized observation. I.e. you
                        can pass 'left*.jpg' and 'right*.jpg' to find images
                        'left0.jpg', 'left1.jpg', ..., 'right0.jpg',
                        'right1.jpg', ...''')

    parser.add_argument('--cull-points-left-of',
                        required=False,
                        default=-1,
                        type=float,
                        help='''For testing. Throw out all observations with x < the given value''')
    parser.add_argument('--cull-points-rad-off-center',
                        required=False,
                        default=-1,
                        type=float,
                        help='''For testing. Throw out all observations with dist_from_center > the given
                        value''')
    parser.add_argument('--cull-random-observations-ratio',
                        required=False,
                        default=-1,
                        type=float,
                        help='''For testing. Throw out a random number of board observations. The ratio of
                        observations is given as the argument. 1.0 = throw out
                        ALL the observations; 0.0 = throw out NONE of the
                        observations''')



    return parser.parse_args()

args = parse_args()

# arg-parsing is done before the imports so that --help works without building
# stuff, so that I can generate the manpages and README


if args.object_spacing is None:
    sys.stderr.write("Warning: assuming default calibration-object spacing of 0.1m. If this is wrong, all distances will be off by a scale factor\n")
    args.object_spacing = 0.1




import numpy as np
import numpysane as nps
import cv2
import copy
import time

import mrcal




def get_imagersize_one(icamera, indices_frame_camera, paths, args_imagersize):
    r'''Returns the imager size for a given camera

    This reports the size for ONE camera. I only look at the first match. It is
    assumed that all the images matching this glob have the same imager size.

    If I have a corners cache, then this is the ONLY place where I'd need the
    images on disk at all. If the user passes --imagersize, then I really don't
    need the images.

    '''
    if args_imagersize is not None:
        return args_imagersize
    try:
        iobservation0_thiscamera = next( i for i in range(len(paths)) if indices_frame_camera[i,1] == icamera )
    except:
        raise Exception("Couldn't find any images for camera '{}'".format(icamera))

    try:
        img = cv2.imread(paths[iobservation0_thiscamera]);
        h,w = img.shape[:2]
    except:
        raise Exception("I needed to read '{}' to get an imagersize, but couldn't open it, and get image dimensions from it. Make the images findable, or pass --imagersize". \
                        format(paths[iobservation0_thiscamera]))

    if args_imagersize is not None:
        if w != args_imagersize[0] or h != args_imagersize[1]:
            raise Exception("Inconsistent imager size. Cmdline says {}, but image says {}. Since the image exists on disk, you don't need to pass --imagesize at all".format(args_imagersize, [w,h]))
    return [w,h]


def make_cameramodel(i_camera, intrinsics, extrinsics, imagersizes,
                     observed_pixel_uncertainty,
                     invJtJ_intrinsics_full,
                     invJtJ_intrinsics_observations_only,
                     valid_intrinsics_region = None):
    r'''Assemble one cameramodel from a completed calibration

    The calibration routines treat the intrinsics and extrinsics for all cameras
    as a vector. This routine converts a single camera to a mrcal.cameramodel
    structure that can be fed to all the other routines.

    '''

    if i_camera >= 1:
        rt_x0 = extrinsics[i_camera-1,:].ravel()
    else:
        rt_x0 = np.zeros(6)
    Rt_rx = mrcal.invert_Rt( mrcal.Rt_from_rt(rt_x0))

    if invJtJ_intrinsics_full is not None:
        invJtJ_intrinsics_full = invJtJ_intrinsics_full[i_camera, ...]
    if invJtJ_intrinsics_observations_only is not None:
        invJtJ_intrinsics_observations_only = invJtJ_intrinsics_observations_only[i_camera, ...]
    if valid_intrinsics_region is not None:
        valid_intrinsics_region = valid_intrinsics_region[i_camera]

    return mrcal.cameramodel( intrinsics                          = (intrinsics[0], intrinsics[1][i_camera,:]),
                              extrinsics_Rt_toref                 = Rt_rx,
                              imagersize                          = imagersizes[i_camera],
                              observed_pixel_uncertainty          = observed_pixel_uncertainty,
                              invJtJ_intrinsics_full              = invJtJ_intrinsics_full,
                              invJtJ_intrinsics_observations_only = invJtJ_intrinsics_observations_only,
                              valid_intrinsics_region             = valid_intrinsics_region)

def make_cameramodels(intrinsics, extrinsics, imagersizes,
                      observed_pixel_uncertainty,
                      invJtJ_intrinsics_full,
                      invJtJ_intrinsics_observations_only,
                      valid_intrinsics_region = None):
    r'''Assemble cameramodels from a completed calibration

    The calibration routines treat the intrinsics and extrinsics for all cameras
    as a vector. This routine converts those to a list of mrcal.cameramodel
    structures that can be fed to all the other routines.

    '''
    return [ make_cameramodel(i_camera,
                              intrinsics, extrinsics, imagersizes,
                              observed_pixel_uncertainty,
                              invJtJ_intrinsics_full,
                              invJtJ_intrinsics_observations_only,
                              valid_intrinsics_region) for i_camera in range(len(intrinsics[1])) ]


# # Test for this function
# Nobservations = 5
# indices = np.array((1,3,4), dtype=int)
# observations = np.arange(15).reshape(5,3)
# frames = np.array((10,11,12,13), dtype=int)
# indices_frame_camera = np.array(((0,100),
#                                  (1,200),
#                                  (2,300),
#                                  (3,900),
#                                  (3,800)),
#                                 dtype=int)
# paths = np.arange(Nobservations)
# outlier_indices=np.array((2,5, 205,208, 311,390), dtype=int)
# # observations 0xx and 2xx are skipped
# # observation 3xx is now observation 1xx
# # 111,190
# split_observations, split_indices_frame_camera, split_paths, split_frames, split_outlier_indices = \
#     get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths,
#                                          frames,
#                                          outlier_indices)
# print split_outlier_indices
def get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths,
                                         frames = None,
                                         outlier_indices = None):
    r'''Returns a subset of observations from observation indices

    Observations are stored across variables:

    - observations
    - indices_frame_camera
    - paths
    - frames
    - outlier_indices

    These must all be self-consistent. This function takes in the desired
    observation indices to keep, and returns copies of all the variables that
    contain the requested subset of data and are consistent with each other

    '''

    if len(indices) == 0:
        raise Exception("Selected subset of data is empty: I threw out everything!")

    observations_new         = observations        [indices, ...].copy()
    paths_new                = [paths[i] for i in indices]
    indices_frame_camera_new = indices_frame_camera[indices, ...].copy()

    # I now collapse newly-missing frames and build the frame indices
    indices_frames  = []
    iframe_old_last = -1
    iframe_new_last = -1

    if outlier_indices is not None:
        # I make a copy of the outlier indices array, and iterate through it. As I
        # go I copy indices from the back of the array to the front. Initially the
        # to/from pointers are identical, but as I skip observations I'm going to be
        # skipping outlier indices, and a gap will developt between the pointers
        outlier_indices = outlier_indices.copy()

        # Index into the outlier_indices array that I copy FROM
        i_outlier_indices_old = 0
        # Index into the outlier_indices array that I copy TO
        i_outlier_indices_new = 0


    Nfeatures_in_observation = args.object_width_n*args.object_width_n

    def outlier_index_next_bounds(i0, iobs):


        ifeature_threshold = iobs*Nfeatures_in_observation
        for i in range(i0,len(outlier_indices)):
            if outlier_indices[i] >= ifeature_threshold:
                break
        else:
            return len(outlier_indices),len(outlier_indices)

        # found beginning of the set of outliers for this observation (or
        # further ones). If these outliers are for THIS observation, find the
        # end of the outliers for this observation. Otherwise tell the caller
        i0 = i
        if int(outlier_indices[i]/Nfeatures_in_observation) != iobs:
            # I don't have any outliers for this observation
            return i0,i0

        ifeature_threshold += Nfeatures_in_observation
        for i in range(i0+1,len(outlier_indices)):
            if outlier_indices[i] >= ifeature_threshold:
                return i0,i

        return i0,len(outlier_indices)

    def outlier_indices_accept(iobs_old, iobs_new, i_outlier_indices_old,i_outlier_indices_new):

        # I need to grab outliers for this observation. These begin somewhere
        # at/after i_outlier_indices_old because I may have skipped some
        # observations. First I find where the observations I want begin
        iold0,iold1 = outlier_index_next_bounds(i_outlier_indices_old, iobs_old)
        if iold0 == iold1:
            # I don't have any outliers for this observation
            return iold1, i_outlier_indices_new

        Noutliers_here = iold1-iold0
        inew0 = i_outlier_indices_new
        inew1 = inew0 + Noutliers_here
        i_observations_offset = iobs_old-iobs_new

        outlier_indices[inew0:inew1] = outlier_indices[iold0:iold1] - i_observations_offset*Nfeatures_in_observation

        return iold1, i_outlier_indices_new + Noutliers_here


    for iobs_new in range(len(indices)):
        iobs_old   = indices[iobs_new]
        iframe_old = indices_frame_camera_new[iobs_new,0]
        if iframe_old != iframe_old_last:
            # Saw new frame. The iframe in the data is going to be
            # non-consecutive, so I adjust it to become consecutive. And I then
            # update the mapping
            iframe_new_last += 1
            iframe_old_last = iframe_old
            indices_frames.append(iframe_old)
        indices_frame_camera_new[iobs_new,0] = iframe_new_last

        if outlier_indices is not None:
            i_outlier_indices_old,i_outlier_indices_new = \
                outlier_indices_accept(iobs_old, iobs_new,
                                   i_outlier_indices_old,i_outlier_indices_new)


    if frames is not None:
        frames_new = frames[indices_frames, ...].copy()
    else:
        frames_new = None

    if outlier_indices is not None:
        outlier_indices = outlier_indices[:i_outlier_indices_new]
    return observations_new, indices_frame_camera_new, paths_new, frames_new, outlier_indices

def get_observation_subset__random(ratio_cull, observations, indices_frame_camera, paths):
    r'''Returns a random subset of observations'''

    # keep this many
    N = int(round((1.0 - ratio_cull) * len(observations)))

    indices = np.sort(np.random.choice(len(observations), N, replace=False))

    return get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths)

def get_observation_subset__right_of_threshold_and_within_center(point_x_threshold,
                                                                 rad_threshold,
                                                                 observations,
                                                                 imagersizes,
                                                                 indices_frame_camera, paths, object_width_n):
    r'''Returns a subset of observations

    This throws out all observations that lie COMPLETELY to the left of the
    given threshold or outside the given circle. The mrcal internals handle
    partial board observations

    '''

    # observations that have fewer than this many points are thrown out
    must_have_at_least_points = object_width_n*2

    def have_enough_points(i):
        x = None
        if point_x_threshold > 0:
            x = observations[i,:,:,0] >= point_x_threshold
        if rad_threshold > 0:
            y = nps.norm2(observations[i,...] - (imagersizes[indices_frame_camera[i,1]] - 1.)/2.) < rad_threshold*rad_threshold
            if x is None:
                x = y
            else:
                x = x*y

        return np.count_nonzero(x) >= must_have_at_least_points

    indices = np.array([i for i in range(len(observations)) if \
                        have_enough_points(i)],
                       dtype=int)
    return get_observation_subset__from_indices(indices, observations, indices_frame_camera, paths)

def incremental_optimization_loop(args, imagersizes, observations, indices_frame_camera, outlier_indices, incremental):
    '''Solve an incrementally-expanding optimization problem in several passes

    The logic is this:

        m   = simplest_model
        roi = smallest region

        while roi<ROI:
            solve(m,roi)
            if(couldn't fit the data very well):
                if m < M:
                    m++
                else:
                    # I'm already at the most complex model
                    print("Given distortion model doesn't fit in the required ROI!")
                    break
            else:
                roi++

    I.e. I start with a smaller region-of-interest than what I actually care
    about, and with a simpler distortion model than what I was asked to use. I
    solve again and again, increasing the region-of-interest and distortion
    model complexity as I go, using the outlier counts to guide the process.

    have minimal m that works with ROI

    '''

    Ncameras = len(args.images)

    distortion_model = 'DISTORTION_NONE'
    intrinsics_data,extrinsics,frames = \
        mrcal.make_seed_no_distortion(imagersizes          = imagersizes,
                                      focal_estimate       = args.focal,
                                      Ncameras             = Ncameras,
                                      indices_frame_camera = indices_frame_camera,
                                      corners              = observations,
                                      dot_spacing          = args.object_spacing,
                                      object_width_n       = args.object_width_n)

    # done with the preliminaries. Run the calibration, in several passes
    sys.stderr.write("vvvvvvvvvvvvvvvvvvvv initial solve: geometry only\n")
    stats = mrcal.optimize(intrinsics_data, extrinsics, frames, None,
                           observations, indices_frame_camera,
                           None, None,
                           distortion_model,
                           imagersizes                       = imagersizes,
                           observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                           do_optimize_intrinsic_core        = False,
                           do_optimize_intrinsic_distortions = False,
                           calibration_object_spacing        = args.object_spacing,
                           calibration_object_width_n        = args.object_width_n,
                           skip_outlier_rejection            = True,
                           skip_regularization               = True,
                           outlier_indices                   = outlier_indices,
                           roi                               = args.roi,
                           get_invJtJ_intrinsics             = False,
                           VERBOSE                           = False)
    sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n\n".format(stats['rms_reproj_error__pixels']))

    sys.stderr.write("vvvvvvvvvvvvvvvvvvvv initial solve: geometry and intrinsic core only\n")
    stats = mrcal.optimize(intrinsics_data, extrinsics, frames, None,
                           observations, indices_frame_camera,
                           None, None,
                           distortion_model,
                           imagersizes                       = imagersizes,
                           observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                           do_optimize_intrinsic_core        = True,
                           do_optimize_intrinsic_distortions = False,
                           calibration_object_spacing        = args.object_spacing,
                           calibration_object_width_n        = args.object_width_n,
                           skip_outlier_rejection            = True,
                           skip_regularization               = True,
                           outlier_indices                   = outlier_indices,
                           roi                               = args.roi,
                           get_invJtJ_intrinsics             = False,
                           VERBOSE                           = False)
    sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n".format(stats['rms_reproj_error__pixels']))
    # I favor the center pixel at the center of the imager

    intrinsics_data[:,2:4] = (imagersizes - 1) / 2

    Nfeatures = args.object_width_n*args.object_width_n*len(observations)

    def get_scaled_roi(roi_final, iroi, Nroi):

        if Nroi == 1:
            if iroi != 0:
                raise Exception("get_scaled_roi(Nroi=1, iroi != 0) doesn't make any sense")
            return roi_final

        scale = float(iroi+1)/float(Nroi)
        return nps.glue(roi_final[:,:2],
                        roi_final[:,2:] * scale,
                        axis = -1)

    def expand_intrinsics(distortion_model, intrinsics_data):
        NnewDistortions = \
            mrcal.getNdistortionParams(distortion_model) - \
            (intrinsics_data.shape[1] - 4)
        newDistortions = \
            (np.random.random((Ncameras, NnewDistortions)) - 0.5)*2. *1e-6
        m = re.search("OPENCV([0-9]+)", distortion_model)
        if m:
            Nd = int(m.group(1))
            if Nd >= 8:
                # Push down the rational components of the seed. I'd like these all to
                # sit at 0 ideally. The radial distortion in opencv is x_distorted =
                # x*scale where r2 = norm2(xy - xyc) and
                #
                # scale = (1 + k0 r2 + k1 r4 + k4 r6)/(1 + k5 r2 + k6 r4 + k7 r6)
                #
                # Note that k2,k3 are tangential (NOT radial) distortion components.
                # Note that the r6 factor in the numerator is only present for
                # >=DISTORTION_OPENCV5. Note that the denominator is only present for >=
                # DISTORTION_OPENCV8. The danger with a rational model is that it's
                # possible to get into a situation where scale ~ 0/0 ~ 1. This would
                # have very poorly behaved derivatives. If all the rational coefficients
                # are ~0, then the denominator is always ~1, and this problematic case
                # can't happen. I favor that.
                newDistortions[5:8] *= 1e-3
        return nps.glue( intrinsics_data, newDistortions, axis=-1 )

    def eval_solution(stats, outside_ROI_indices__prevROI):

        Nfeatures = args.object_width_n*args.object_width_n*len(observations)
        x    = stats['x'][:Nfeatures*2]

        def makemask_inside(outside_indices):
            maskout = np.zeros(x.shape, dtype=bool)
            maskout[outside_indices*2 + 0] = True
            maskout[outside_indices*2 + 1] = True
            return ~maskout


        if outside_ROI_indices__prevROI is None:
            maskin = makemask_inside(stats['outside_ROI_indices'])
            s = np.std(x[maskin])

        else:
            maskold_only = makemask_inside(outside_ROI_indices__prevROI)
            masknew_only = \
                makemask_inside (stats['outside_ROI_indices']) * \
                ~maskold_only


            # It's possible that increasing the roi adds a SMALL NUMBER of
            # points total. If the model doesn't fit the new ROI well, these
            # points would have high errors, but since there aren't a lot of
            # them, this wouldn't reflect at all in the new distribution. I
            # re-weight the distribution of the NEW points to be equal to k
            # times the distribution of all the previous points in the set. If
            # k==1 then the set of the new points is equivalent in weight to the
            # set of the old points
            k = 1
            xold = x[maskold_only]
            xnew = x[masknew_only]
            if len(xnew) == 0:
                print("RMS error: {}".format(stats['rms_reproj_error__pixels']))
                return True,"Extended ROI contains no new data"

            wnew = k * len(xold)/len(xnew)

            mean = (np.sum( xold                  ) + wnew*np.sum( xnew                  )) / ((1. + k) * len(xold))
            var  = (np.sum((xold-mean)*(xold-mean)) + wnew*np.sum((xnew-mean)*(xnew-mean))) / ((1. + k) * len(xold))
            s    = np.sqrt(var)



        print("RMS error: {}".format(stats['rms_reproj_error__pixels']))
        print("In-ROI independent x,y stdev: {} (user says {})".format(s, args.observed_pixel_uncertainty))

        # If a model fits in a specific ROI, then (assuming no outliers) all the
        # error is attributable to input noise. I'm given an estimate of this
        # noise on the input, so I can check to see if this is true
        stdev_error_ratio = s / args.observed_pixel_uncertainty

        q_threshold = 1.5

        return stdev_error_ratio < q_threshold, "stdev_error_ratio={} (wanted < {})".format(stdev_error_ratio, q_threshold)


    # Alrighty. All the preliminary business is finished. I should have a usable
    # seed now. And thus I now run the main optimization loop
    if not incremental:
        # We're not doing the incremental loop. Just solve it once and call it good
        distortion_model = args.distortion_model
        intrinsics_data  = expand_intrinsics(distortion_model, intrinsics_data)

        print("=================== optimizing everything{}from seeded intrinsics". \
              format(" except board warp " if args.optimize_calobject_warp else " "))

        stats = mrcal.optimize(intrinsics_data, extrinsics, frames, None,
                               observations, indices_frame_camera,
                               None, None,
                               distortion_model,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = True,
                               do_optimize_intrinsic_distortions = True,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = args.skip_outlier_rejection,
                               skip_regularization               = args.skip_regularization,
                               outlier_indices                   = outlier_indices,
                               roi                               = args.roi,
                               get_invJtJ_intrinsics             = False,
                               VERBOSE                           = args.verbose_solver)
        return "fixed solve", (distortion_model, intrinsics_data), extrinsics, frames, args.roi, stats




    Nroi = 8
    if args.roi is None:
        # no explicit region-of-interest given. I thus use the whole imager.
        # I use an ellipse with the imager's aspect ratio, passing through
        # the corner
        widths       = imagersizes.astype(float)-1
        centerpixels = widths / 2.
        roi_final = nps.glue(centerpixels, widths/2.*np.sqrt(2), axis=-1)
    else:
        roi_final = args.roi

    stats_best = None
    roi_best   = None

    iroi = 0
    outside_ROI_indices__prevROI = None
    while iroi<Nroi:
        roi = get_scaled_roi(roi_final, iroi, Nroi)

        print("")
        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv next distortion/ROI:\n")
        print("Distortion model: {}"         .format(distortion_model))
        print("ROI:              {}/{}  ({})".format(iroi+1, Nroi, roi))

        state = copy.deepcopy( (intrinsics_data, extrinsics, frames), )
        stats = mrcal.optimize(state[0], state[1], state[2], None,
                               observations, indices_frame_camera,
                               None, None,
                               distortion_model,
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = True,
                               do_optimize_intrinsic_distortions = True,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = True,
                               skip_regularization               = args.skip_regularization,
                               outlier_indices                   = outlier_indices,
                               roi                               = roi,
                               get_invJtJ_intrinsics             = False,
                               VERBOSE                           = args.verbose_solver)

        solution_acceptable,solution_description = eval_solution(stats, outside_ROI_indices__prevROI)

        if solution_acceptable:
            # We found a good solution for this distortion model and ROI. Let's
            # expand the region of interest and go again

            # save the initial state. The last one of these chunks of data is
            # the best solution I got
            outlier_indices       = stats['outlier_indices']
            intrinsics_data       = state[0].copy()
            extrinsics            = state[1].copy()
            frames                = state[2].copy()
            stats_best            = copy.deepcopy(stats)
            roi_best              = copy.deepcopy(roi)
            distortion_model_best = copy.deepcopy(distortion_model)
            result                = 'Usable solve found at the full ROI'

            outside_ROI_indices__prevROI = stats['outside_ROI_indices']
            iroi += 1
            sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ {}: good solve! roi++\n".format(solution_description))
        else:
            # This solution wasn't very good. Let's try a richer distortion
            # model

            distortion_model1 = mrcal.getNextDistortionModel(distortion_model, args.distortion_model)

            if distortion_model1 == distortion_model:

                # we're already at the last model in the family, or at the
                # maximum model the user asked for. There's nowhere more to go,
                # so I guess I'm done
                sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ {}: ill-fitting solve, but no more distortion-models remaining. I'm done\n".format(solution_description))

                # # For testing. The distribution can be plotted thusly:
                # import gnuplotlib as gp
                # x    = stats['x']
                # maskout = np.zeros(x.shape, dtype=bool)
                # maskout[stats['outside_ROI_indices']*2 + 0] = True
                # maskout[stats['outside_ROI_indices']*2 + 1] = True
                # x = x[~maskout]
                # s    = np.std(x)
                # s2   = s*s
                # gp.plot(x, histogram='freq', binwidth=0.2,
                #         equation='1./sqrt(2.*pi*{s2})*exp(-x*x/(2.*{s2})) axis x1y2'.format(s2=s2),
                #         _xrange=[-5.*s,5.*s],
                #         ymin=0, y2min=0,
                #         hardcopy='/tmp/tst.gp')
                # import IPython
                # IPython.embed()
                # sys.exit()


                if stats_best is None:
                    # This is the best I got I guess
                    intrinsics_data       = state[0]
                    extrinsics            = state[1]
                    frames                = state[2]
                    stats_best            = stats
                    roi_best              = roi
                    distortion_model_best = distortion_model
                    result                = 'No usable solves found'
                else:
                    result                = 'Usable solves found, but not for the full ROI'
                break

            else:
                # I try the next model in the family, keeping the roi and
                # outlier list the same
                distortion_model = distortion_model1
                intrinsics_data  = expand_intrinsics(distortion_model, intrinsics_data)
                sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ {}: ill-fitting solve, distortion++\n".format(solution_description))

    return                                                                            \
        result,                                                                       \
        ( distortion_model_best,                                                      \
          intrinsics_data[:,:(4+mrcal.getNdistortionParams(distortion_model_best))]), \
         extrinsics,                                                                  \
         frames,                                                                      \
         roi_best,                                                                    \
         stats_best







# expand ~/ into $HOME/
args.images = [os.path.expanduser(g) for g in args.images]

Ncameras = len(args.images)
if Ncameras > 10:
    raise Exception("Got {} image globs. It should be one glob per camera, and this sounds like WAY too make cameras. Did you forget to escape your glob?". \
                    format(Ncameras))

if args.roi is not None:
    if len(args.roi) != Ncameras:
        raise Exception("Globs say we have {} cameras, but --roi suggests I have {}. These MUST match". \
                        format(Ncameras, len(args.roi)))
    try:
        args.roi = np.array(args.roi, dtype=float)
    except:
        sys.stderr.write("Couldn't interpret --roi as a numpy array")
        raise

observations, indices_frame_camera, paths = \
    mrcal.get_chessboard_observations(args.object_width_n,
                                      args.object_width_n,
                                      args.images,
                                      args.corners_cache,
                                      jobs = args.jobs)

# list of imager sizes; one per camera
imagersizes = np.array([get_imagersize_one(icamera, indices_frame_camera, paths, args.imagersize) for icamera in range(Ncameras)],
                       dtype=np.int32)

if args.cull_random_observations_ratio >= 0:
    observations, indices_frame_camera, paths, _, _ = \
        get_observation_subset__random(args.cull_random_observations_ratio,
                                       observations, indices_frame_camera, paths)
outlier_indices = None
if args.cull_points_left_of > 0 or args.cull_points_rad_off_center > 0:

    # first cut off full observations
    observations, indices_frame_camera, paths, _, _ = \
        get_observation_subset__right_of_threshold_and_within_center( \
            args.cull_points_left_of,
            args.cull_points_rad_off_center,
            observations,
            imagersizes, indices_frame_camera, paths,
            args.object_width_n)

    # any observations that lie partially outside the threshold remain. I cut
    # out individual points as outliers
    if args.cull_points_left_of > 0:
        outlier_indices0 = set(np.flatnonzero(observations[...,0] < args.cull_points_left_of))
    else:
        outlier_indices0 = set()

    if args.cull_points_rad_off_center > 0:
        centerpixels = (imagersizes[ indices_frame_camera[:,1] ] - 1.)[:,np.newaxis,np.newaxis,:] / 2.
        radsq = args.cull_points_rad_off_center*args.cull_points_rad_off_center
        outlier_indices1 = set(np.flatnonzero(nps.norm2(observations - centerpixels) > radsq))
    else:
        outlier_indices1 = set()

    outlier_indices = np.array(sorted(list(outlier_indices0.union( outlier_indices1 ))), dtype=np.int32)


result,intrinsics,extrinsics,frames,roi,stats = \
    incremental_optimization_loop(args, imagersizes, observations, indices_frame_camera, outlier_indices, args.incremental)
if args.incremental:
    print(">>>>>>>>>>>>>>>>> " + result)
    print("Final Distortion model: {}".format(intrinsics[0]))
    print("Final ROI:              {}".format(roi))


if args.skip_outlier_rejection: print("We are NOT rejecting outliers")
else:                           print("We ARE rejecting outliers")
if args.skip_regularization:    print("We are NOT applying regularization in the solver")
else:                           print("We ARE applying regularization in the solver")


# I now optimize again, primarily to get invJtJ_intrinsics_observations_only and solver_context. This should be
# quick since I'm already at the optimum. This solve shouldn't move the
# operating point at all
solver_context = mrcal.SolverContext()




















if args.num_cross_validation_splits > 1:

    # THIS IS ALL VERY EXPERIMENTAL


    def cross_validation_makesplit(Nobservations, Nsplit):
        r'''Returns a random splitting of the data set

        This function returns a python list (of length Nsplit). Each contains a
        numpy array of sorted integer indices

        I have Nobservations observations, and I want to split them into Nsplit
        equal (and random) sets. If an even splitting isn't possible, the N
        stragglers are distributed amount the N trailing sets

        '''

        # I create a random list of indices, and take sequential subsets of it
        i_observations = np.arange(Nobservations, dtype=np.int32)
        np.random.shuffle(i_observations)

        # I could do this:
        #   s = [i_observations[isplit*N_insplit:(isplit+1)*N_insplit] for isplit in range(Nsplit)]
        # But then I need to deal with the remaining observations. For instance,
        # trying to split 14 into 4 groups would create 4 groups of 3, and 2
        # observations remaining. I want to distribute these 2 extra observations
        # one-at-a-time among my groups, hence this logic:

        s = [None] * Nsplit
        iobservation = 0
        for isplit in range(Nsplit):
            N_inthissplit = int( (Nobservations - iobservation) / (Nsplit - isplit))
            s[isplit] = i_observations[iobservation:iobservation+N_inthissplit]
            iobservation += N_inthissplit

        for i in s:
            i.sort()

        return s




    Nobservations = indices_frame_camera.shape[0]
    splits = cross_validation_makesplit(Nobservations, args.num_cross_validation_splits)

    cross_validation_models = []

    for isplit in range(len(splits)):

        s = splits[isplit]

        split_observations, split_indices_frame_camera, split_paths, split_frames, split_outlier_indices = \
            get_observation_subset__from_indices(s, observations, indices_frame_camera, paths,
                                                 frames, stats['outlier_indices'])

        split_intrinsics = copy.deepcopy(intrinsics)
        split_extrinsics = copy.deepcopy(extrinsics)

        sys.stderr.write("vvvvvvvvvvvvvvvvvvvv Evaluating split {}/{}\n".format(isplit+1, args.num_cross_validation_splits))
        stats = mrcal.optimize(split_intrinsics[1],
                               split_extrinsics,
                               split_frames,
                               None,
                               split_observations, split_indices_frame_camera,
                               None, None,
                               split_intrinsics[0],
                               imagersizes                       = imagersizes,
                               observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                               do_optimize_intrinsic_core        = True,
                               do_optimize_intrinsic_distortions = True,
                               calibration_object_spacing        = args.object_spacing,
                               calibration_object_width_n        = args.object_width_n,
                               skip_outlier_rejection            = args.skip_outlier_rejection,
                               skip_regularization               = args.skip_regularization,
                               outlier_indices                   = split_outlier_indices,
                               roi                               = roi,
                               get_invJtJ_intrinsics             = True,
                               VERBOSE                           = False,
                               solver_context                    = solver_context)

        invJtJ_intrinsics_observations_only = stats.get('invJtJ_intrinsics_observations_only')

        report = "RMS reprojection error: {} pixels\n".format(stats['rms_reproj_error__pixels'])
        sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ \n" + report)

        cross_validation_models.append( make_cameramodels(split_intrinsics, split_extrinsics, MMt=None) )
    # for i_camera in range(len(intrinsics[1]):
    i_camera = 0
    if roi is None:
        focus_center = None
        focus_radius = min(imagersizes[i_camera])/6
    else:
        focus_center = roi[i_camera,:2]
        focus_radius = min(roi[i_camera,2:])
    plot = \
        mrcal.show_intrinsics_diff([models[i_camera] for models in cross_validation_models],
                                   focus_center = focus_center,
                                   focus_radius = focus_radius)

    plot.wait()

    print("done!!!!!!")
    sys.exit()












if args.optimize_calobject_warp:
    calobject_warp = np.array((0,0), dtype=float)
else:
    calobject_warp = None

sys.stderr.write("vvvvvvvvvvvvvvvvvvvv final, full re-optimization call to get board warp, invJtJ_intrinsics_observations_only and solver_context\n")
stats = mrcal.optimize(intrinsics[1],extrinsics,frames, None,
                       observations, indices_frame_camera,
                       None, None,
                       intrinsics[0],
                       do_optimize_calobject_warp        = args.optimize_calobject_warp,
                       calobject_warp                    = calobject_warp,
                       imagersizes                       = imagersizes,
                       observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                       do_optimize_intrinsic_core        = True,
                       do_optimize_intrinsic_distortions = True,
                       calibration_object_spacing        = args.object_spacing,
                       calibration_object_width_n        = args.object_width_n,
                       skip_outlier_rejection            = True, # use outliers in outlier_indices
                       skip_regularization               = args.skip_regularization,
                       outlier_indices                   = stats['outlier_indices'],
                       roi                               = roi,
                       get_invJtJ_intrinsics             = True,
                       VERBOSE                           = False,
                       solver_context                    = solver_context)
sys.stderr.write("^^^^^^^^^^^^^^^^^^^^ RMS error: {}\n".format(stats['rms_reproj_error__pixels']))


invJtJ_intrinsics_full              = stats.get('invJtJ_intrinsics_full')
invJtJ_intrinsics_observations_only = stats.get('invJtJ_intrinsics_observations_only')

report = "RMS reprojection error: {:.01f} pixels\n".format(stats['rms_reproj_error__pixels'])

Npoints = args.object_width_n*args.object_width_n*len(observations)
xyerr = stats['x'][:Npoints*2].reshape(Npoints,2)
worst_point_err = np.sqrt(np.max(nps.inner(xyerr,xyerr)))
report += "Worst reprojection error: {:.01f} pixels\n".format(worst_point_err)
if not args.skip_outlier_rejection:
    report += "Noutliers: {} out of {} total points: {:.01f}% of the data\n". \
        format(stats['Noutliers'],
               args.object_width_n*args.object_width_n*len(observations),
               100.0 * stats['Noutliers'] / (args.object_width_n*args.object_width_n*len(observations)))
if calobject_warp is not None:
    report += "calobject_warp = {}".format(calobject_warp)
print(report)








projected = mrcal.calobservations_project(intrinsics[0], intrinsics[1], extrinsics, frames, args.object_spacing, args.object_width_n, calobject_warp)
err_including_outliers,err_0_for_outliers = \
    mrcal.calobservations_compute_reproj_error(projected, observations,
                                               indices_frame_camera, args.object_width_n,
                                               stats['outlier_indices'])

def get_valid_intrinsics_region(i_camera,
                                ignore_outliers = True,
                                focus_center = None, focus_radius = -1):

    '''THIS FUNCTION IS MADE UP. PLEASE FIX'''
    idx = np.ones( err_including_outliers.shape[:-1], dtype=bool)

    if i_camera >= 0:
        idx[indices_frame_camera[:,1] != i_camera, ...] = False
    if ignore_outliers:
        nps.clump(idx, n=3)[stats['outlier_indices']] = False

    err = err_including_outliers[idx, ...]
    obs = observations          [idx, ...]

    W,H=imagersizes[i_camera]
    if focus_center is None:
        focus_center = (imagersizes[i_camera]-1.)/2.

    gridn_x,gridn_y = 20,10
    mean,stdev,count,using = \
        mrcal.report_residual_statistics(obs,err, imagersizes[i_camera],
                                         gridn_x = gridn_x,
                                         gridn_y = gridn_y)

    if invJtJ_intrinsics_observations_only is None:
        raise Exception("No intrinsics uncertainty was computed. You need to call mrcal.optimize(..., get_invJtJ_intrinsics = True) for this to work")

    err = mrcal.compute_intrinsics_uncertainty(intrinsics[0],
                                               intrinsics[1][i_camera],
                                               imagersizes  [i_camera],
                                               args.observed_pixel_uncertainty,
                                               invJtJ_intrinsics_observations_only[i_camera],

                                               gridn_x      = gridn_x,
                                               gridn_y      = gridn_y,
                                               focus_center = focus_center,
                                               focus_radius = focus_radius)

    try:

        sys.stderr.write("These thresholds for the valid-intrinsics-region are completely made up\n")
        im = (err < 1) * (mean < 0.5) * (stdev < 1.5) * (count > 3)

        # I compute the contour. OpenCV can't process binary images, so I need to
        # convert to a different image type first. AND findContours() reports the
        # coordinates in the opposite order as how they're given (image is x,y;
        # returned coords are y,x). Ugh
        contour = cv2.findContours(nps.transpose(im).astype(np.uint8).copy(),
                                   cv2.RETR_EXTERNAL,
                                   cv2.CHAIN_APPROX_SIMPLE)[1][0][:,0,:].astype(float)
        contour = mrcal.close_contour(contour)
        if contour.ndim != 2 or contour.shape[0] < 4:
            # I have a closed contour, so the only way for it to not be
            # degenerate is to include at least 4 points
            return None

        # I convert the contours back to the full-res image coordinate. The grid
        # mapping is based on the corner pixels
        contour[:,0] *= float(W-1)/(gridn_x-1)
        contour[:,1] *= float(H-1)/(gridn_y-1)

        return contour.round().astype(np.int32)

    except:
        return None


valid_intrinsics_region = [get_valid_intrinsics_region(i) for i in range(Ncameras)]




# Write the output models
models = make_cameramodels(intrinsics, extrinsics, imagersizes,
                           args.observed_pixel_uncertainty,
                           invJtJ_intrinsics_full,
                           invJtJ_intrinsics_observations_only,
                           valid_intrinsics_region)
# The note says how we ran this, and contains the commented-out report
note = \
    "generated on {} with   {}\n".format(time.strftime("%Y-%m-%d %H:%M:%S"),
                                           ' '.join(mrcal.shellquote(s) for s in sys.argv)) + \
    re.sub(r"^(.)", r"# \1", report, flags=re.M)
for i_camera in range(len(models)):
    cahvorfile = '{}/camera-{}.cahvor'.format(args.outdir, i_camera)
    models[i_camera].write(cahvorfile, note)
    print("Wrote {}".format(cahvorfile))

    cameramodelfile = '{}/camera-{}.cameramodel'.format(args.outdir, i_camera)
    models[i_camera].write(cameramodelfile, note)
    print("Wrote {}".format(cameramodelfile))



if not args.explore:
    sys.exit(0)



# We're exploring!
import gnuplotlib as gp


print(r'''Calibration results REPL.
Potential things to look at:

    show_residuals_observation_worst(i_observation_in_order_from_worst)
    show_residuals_observation(i_observation, vectorscale=20)
    show_intrinsics_uncertainty(i_camera)
    show_valid_intrinsics_region(i_camera)
    show_residuals('histogram',   i_camera)
    show_residuals('vectorfield', i_camera, ignore_outliers=False)
    show_residuals('heatmap',     i_camera)
    show_residuals('radial',      i_camera)
    show_residuals('regional',    i_camera)
    show_distortion('heatmap',    i_camera)
    show_distortion('vectorfield',i_camera)
    show_distortion('radial',     i_camera)
    show_roi(i_camera)
    stats
    i_observations_worst
    rms_err_including_outliers_perimage
    rms_err_0_for_outliers_perimage
    paths[i_observations_worst[0]]
    calobject_warp
''')


rms_err_including_outliers_perimage = np.sqrt( nps.norm2( nps.clump(err_including_outliers,n=-3) ) /
                                               (args.object_width_n*args.object_width_n) )
rms_err_0_for_outliers_perimage     = np.sqrt( nps.norm2( nps.clump(err_0_for_outliers,    n=-3) ) /
                                               (args.object_width_n*args.object_width_n) )

i_observations_worst    = list(reversed(np.argsort(rms_err_0_for_outliers_perimage)))
i_observation_from_path = dict( [(paths[_i],_i) for _i in range(len(observations))] )

def show_residuals_observation(observation, vectorscale = 1.0, **kwargs):
    r'''Visualize calibration residuals

    Takes either an integer (observation index) or a string (path)

    '''

    if isinstance(observation, (int,np.integer)):
        i_observation = observation
    elif isinstance(observation, str):
        i_observation = i_observation_from_path[observation]
    else:
        raise Exception("observation should be a string (image path) or an integer; got type(observation) = {}".format(type(observation)))

    ioutlier0 = np.searchsorted(stats['outlier_indices'], args.object_width_n*args.object_width_n*i_observation,     'left')
    ioutlier1 = np.searchsorted(stats['outlier_indices'], args.object_width_n*args.object_width_n*(i_observation+1), 'left')
    outlier_indices_thisobservation = stats['outlier_indices'][ioutlier0:ioutlier1] - args.object_width_n*args.object_width_n*i_observation

    obs              = nps.clump( observations[i_observation], n=2)
    i_frame,i_camera = indices_frame_camera[i_observation]
    reproj           = nps.clump( projected[i_frame,i_camera], n=2)

    # error per dot
    err     = reproj - obs
    err_len = np.sqrt(nps.norm2(err))

    nonoutlier_indices_thisobservation = np.ones((args.object_width_n*args.object_width_n,),dtype=bool)
    nonoutlier_indices_thisobservation[outlier_indices_thisobservation] = False
    obs_ignoring_outliers = obs[nonoutlier_indices_thisobservation, :]

    imagepath = paths[i_observation]
    plotkwargs = \
        dict(square=1,cbmin=0,
             title='{}: i_observation={}, i_frame={}, i_camera={}, path={}, error_RMS_all_points={}, error_RMS_ignoring_outliers={}'. \
               format( intrinsics[0],
                       i_observation, i_frame, i_camera,
                       paths[i_observation],
                       rms_err_including_outliers_perimage[i_observation],
                       rms_err_0_for_outliers_perimage[i_observation]),
             **kwargs)
    if os.path.isfile(imagepath):
        # only plot an image overlay if the image exists
        plotkwargs['rgbimage'] = imagepath
        plotkwargs['set']      = 'autoscale noextend'
    else:
        W,H=imagersizes[i_camera]
        plotkwargs['xrange'] = [0,W-1]
        plotkwargs['yrange'] = [H-1,0]

    gp.plot( (obs_ignoring_outliers[:,0], obs_ignoring_outliers[:,1], err_len[nonoutlier_indices_thisobservation],
              dict(_with     = 'points pt 7 ps 2 palette',
                   legend    = 'reprojection error',
                   tuplesize = 3)),

             (obs[:,0], obs[:,1], vectorscale*err[:,0], vectorscale*err[:,1],
              dict(_with     = 'vectors size screen 0.01,20 fixed filled lw 2',
                   legend    = 'observed',
                   tuplesize = 4)),

             **plotkwargs)


def show_residuals_observation_worst(i, **kwargs):
    show_residuals_observation( i_observations_worst[i], **kwargs )

def check_confidence_computations():
    r'''These all test the confidence computations using the debugging exports from
    computeConfidence_MMt() in mrcal.c. It's all for debugging.

    '''

    # E0 = nps.inner(x,x)
    # E0_rms = np.sqrt(E0/(x.shape[0]/2))
    # mu_sumofsquares = E0
    # s_sumofsquares  = 2*np.sqrt(E0)
    # mu_meanofsquares = mu_sumofsquares/(x.shape[0]/2)
    # s_meanofsquares  = s_sumofsquares /(x.shape[0]/2)

    # gp.plot( equation='1./sqrt(2.*pi*{var})*exp(-({x_meanofsquares}-{mu})**2. / (2.*{var}))*2*x'. \
    #          format(x_meanofsquares = '(x*x)',
    #                 mu  = mu_meanofsquares,
    #                 var = s_meanofsquares*s_meanofsquares),
    #          _xrange=[0,E0_rms*2],
    #          _set='samples 1000')

    i_camera = 0


    import IPython
    import numpy as np
    import numpysane as nps
    import gnuplotlib as gp

    global stats,observations,MMt

    raise Exception("I think this doesn't take into account the weights on x[] (that come from, for example, ROI)")

    x0            = stats['x']
    dm            = np.loadtxt("/tmp/dm")
    Jtdm          = np.loadtxt("/tmp/Jtdm")
    dp            = np.loadtxt("/tmp/dp")
    dx_hypothesis = np.loadtxt("/tmp/dx_hypothesis")
    dx            = np.loadtxt("/tmp/dx")

    observations += dm.reshape(116,10,10,2)
    intrinsics0 = np.copy(intrinsics[1])
    frames0     = np.copy(frames)
    p0          = nps.glue( intrinsics[1].ravel(),
                            frames.ravel(),
                            axis=-1)

    J      = np.fromfile("/tmp/J1_23200_704.dat").reshape(23200,704)
    M      = np.linalg.pinv(J)
    MMt_ref = nps.matmult(M,nps.transpose(M))
    Nintrinsics = intrinsics[1].shape[-1]
    print( "MMt difference should be 0: {}". \
           format(np.linalg.norm(MMt[i_camera]/args.observed_pixel_uncertainty/args.observed_pixel_uncertainty -
                                 MMt_ref[Nintrinsics*i_camera:Nintrinsics*(i_camera+1),
                                         Nintrinsics*i_camera:Nintrinsics*(i_camera+1)])) )

    stats = mrcal.optimize(intrinsics[1], extrinsics, frames, None,
                           observations, indices_frame_camera,
                           None, None,
                           intrinsics[0],
                           imagersizes                       = imagersizes,
                           observed_pixel_uncertainty        = args.observed_pixel_uncertainty,
                           do_optimize_intrinsic_core        = True,
                           do_optimize_intrinsic_distortions = True,
                           calibration_object_spacing        = args.object_spacing,
                           calibration_object_width_n        = args.object_width_n,
                           VERBOSE                           = False,
                           skip_outlier_rejection            = True,
                           skip_regularization               = True)

    p1 = nps.glue( intrinsics[1].ravel(),
                   frames.ravel(),
                   axis=-1)
    x1 = stats['x']
    intrinsics1 = intrinsics[1]
    E0 = np.sqrt(nps.inner(x0,x0)/(x0.shape[0]/2))
    E1 = np.sqrt(nps.inner(x1,x1)/(x0.shape[0]/2))


    dp_observed = p1-p0
    dx_observed = x1-x0

    dp_ref = nps.matmult(M, nps.transpose(dm)).ravel()

    print("dp difference should be 0: {}".format(np.linalg.norm(dp - dp_observed)))
    print("dp difference should be 0: {}".format(np.linalg.norm(dp - dp_ref)))
    print("dx difference should be 0: {}".format(np.linalg.norm(dx - dx_observed)))
    # gp.plot(nps.cat(dp,            dp_observed), legend=np.array(("computed",   "observed")), title="dp")
    # gp.plot(nps.cat(dp,            dp_ref),      legend=np.array(("computed",   "reference")),title="dp")
    # gp.plot(nps.cat(dx,            dx_observed), legend=np.array(("computed",   "observed")), title="dx")

    # unperturbed projection: q0
    # perturbed   projection: q1
    # If my math is right, and things are locally linear, I can predict q1-q0:
    # dq = F df + C dc + D dd =
    #    = (F Mf + C Mc + D Md) dm
    v    = np.array((-0.81691696, -0.02852554,  0.57604945))
    q0,dq_dv,dq_di = mrcal.project(v, intrinsics[0], intrinsics0[i_camera], get_gradients=True)
    F    = dq_di[..., 0:2]
    C    = dq_di[..., 2:4]
    D    = dq_di[..., 4: ]
    q1   = mrcal.project(v, intrinsics[0], intrinsics1[i_camera], get_gradients=False)
    Mf = M[Nintrinsics*i_camera+0 : Nintrinsics*i_camera+2,   :]
    Mc = M[Nintrinsics*i_camera+2 : Nintrinsics*i_camera+4,   :]
    Md = M[Nintrinsics*i_camera+4 : Nintrinsics*(i_camera+1) ,:]
    dq = nps.matmult((nps.matmult(F, Mf) +
                      nps.matmult(C, Mc) +
                      nps.matmult(D, Md) ),
                     nps.transpose(dm)).ravel()
    dq_observed = q1-q0
    print("dq got, difference: {}, {}".format(dq, dq-dq_observed))


plots_residuals = dict()
def show_residuals(how, i_camera, focus_center=None, focus_radius=0, binwidth=0.02, ignore_outliers=True, **kwargs):

    r'''Visualize the optimized reprojection errors

    This function visualizes the solution in several ways, selected by the 'how'
    argument.

      if how == 'vectorfield': we plot a vectorfield, showing each observed
                               point, and its reprojection discrepancy

      elif how == 'heatmap':   we plot each observed point, but instead of showing
                               an error vector, we render a point that's
                               color-coded with its error

      elif how == 'histogram': we show a histogram of residuals and overlay it
                               with an idealized distribution. If the
                               optimization was successful, and if
                               observed_pixel_uncertainty was correct, the two
                               should line up.

      elif how == 'radial':    Plot residuals against distance from the center. If
                               focus_center is not None, we use that; otherwise
                               we use the imager center

      elif how == 'regional':  Plots residuals grouped by discrete regions of the
                               image. Useful to see specifically where the fit is
                               poor

    i_camera is the camera in question. <0 means "all cameras"

    if ignore_outliers: we show the distribution without outliers: this is the
    default, and this is what the optimizer actually ended up optimizing.

    '''

    global plots_residuals
    if not how in plots_residuals:
        plots_residuals[how] = [None] * (Ncameras+1)
    plots_how = plots_residuals[how]

    if i_camera < 0: i_camera = -1

    # I have a bunch of errors in err_including_outliers. I need to pick out
    # - the ones for THIS camera (if requested)
    # - the non-outliers         (if requested)
    #
    # The "for this camera" part is specified in indices_frame_camera. This
    # indexes FRAMES
    #
    # The "outlier" part is given by stats['outlier_indices']. This indexes
    # FEATURES (each feature is 2 measurements: x,y).
    #
    # I construct a feature index map, fill it in with both filters, and use it
    # to pull out the correct data

    # all true by default, cutting out the last dimension: x,y
    idx = np.ones( err_including_outliers.shape[:-1], dtype=bool)

    if i_camera >= 0:
        idx[indices_frame_camera[:,1] != i_camera, ...] = False
    if ignore_outliers:
        nps.clump(idx, n=3)[stats['outlier_indices']] = False

    err = err_including_outliers[idx, ...]
    obs = observations          [idx, ...]

    W,H=imagersizes[i_camera]
    if focus_center is None:
        focus_center = (imagersizes[i_camera]-1.)/2.
    if focus_radius == 0:
        # I use all the data
        pass
    else:
        if focus_radius < 0:
            focus_radius = min(imagersizes[i_camera])/6
        idx = nps.norm2(obs - focus_center) < focus_radius*focus_radius
        obs = obs[idx, ...]
        err = err[idx, ...]
    # err,obs are now both of shape (N,2). Each slice is xy

    valid_intrinsics_region_plotarg = None
    if i_camera >= 0:
        valid_intrinsics_region_plotarg_3d = \
            (valid_intrinsics_region[i_camera][:,0],
             valid_intrinsics_region[i_camera][:,1],
             np.zeros(valid_intrinsics_region[i_camera].shape[-2]),
             dict(_with  = 'lines lw 3',
                  legend = "Valid-intrinsics region")) if valid_intrinsics_region[i_camera] is not None else None
        valid_intrinsics_region_plotarg_2d = \
            (valid_intrinsics_region[i_camera][:,0],
             valid_intrinsics_region[i_camera][:,1],
             dict(_with  = 'lines lw 3',
                  legend = "Valid-intrinsics region")) if valid_intrinsics_region[i_camera] is not None else None
    if how == 'vectorfield':
        plots_how[i_camera+1] = \
            gp.gnuplotlib( square=1,
                           _xrange=[0,W], yrange=[H,0],
                           title = 'Fitted reprojection errors {}. Errors shown as vectors and colors'. \
                           format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                           xlabel = 'Imager x',
                           ylabel = 'Imager y',
                           **kwargs)
        plot_data_args = [(obs[:,0], obs[:,1],
                           err[:,0], err[:,1],
                           np.sqrt(nps.norm2(err)),
                           dict(_with='vectors size screen 0.01,20 fixed filled palette',
                                tuplesize=5))]
        if valid_intrinsics_region_plotarg_2d is not None:
            plot_data_args.append(valid_intrinsics_region_plotarg_2d)
        plots_how[i_camera+1].plot(*plot_data_args)
    elif how == 'heatmap':
        plots_how[i_camera+1] = \
            gp.gnuplotlib( square=1,
                           _xrange=[0,W], yrange=[H,0],
                           title = 'Fitted reprojection errors {}. Errors shown as colors'. \
                           format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                           xlabel = 'Imager x',
                           ylabel = 'Imager y',
                           **kwargs)
        plot_data_args = [( obs[:,0], obs[:,1], np.sqrt(nps.norm2(err)),
                            dict(_with='points pt 7 palette',
                                 tuplesize=3))]
        if valid_intrinsics_region_plotarg_2d is not None:
            plot_data_args.append(valid_intrinsics_region_plotarg_2d)
        plots_how[i_camera+1].plot(*plot_data_args)

    elif how == 'histogram':

        x = err.ravel()
        N = len(x)

        sigma_expected = args.observed_pixel_uncertainty
        sigma_observed = np.std(x)
        from scipy.special import erf

        def make_gaussian(sigma,title):
            # I want to plot a PDF of a normal distribution together with the
            # histogram to get a visual comparison. This requires a scaling on
            # either the PDF or the histogram. I plot a scaled pdf:
            #
            #   f = k*pdf = k * exp(-x^2 / (2 s^2)) / sqrt(2*pi*s^2)
            #
            # I match up the size of the central bin of the histogram (-binwidth/2,
            # binwidth/2):
            #
            #   bin(0) ~ k*pdf(0) ~ pdf(0) * N * binwidth
            #
            # So k = N*binwdith should work. I can do this more precisely:
            #
            #   bin(0) ~ k*pdf(0) ~
            #     = N * integral( pdf(x) dx,                                -binwidth/2, binwidth/2)
            #     = N * integral( exp(-x^2 / (2 s^2)) / sqrt( 2*pi*s^2) dx, -binwidth/2, binwidth/2)
            # ->k = N * integral( exp(-x^2 / (2 s^2)) / sqrt( 2*pi*s^2) dx, -binwidth/2, binwidth/2) / pdf(0)
            #     = N * integral( exp(-x^2 / (2 s^2)) dx,                   -binwidth/2, binwidth/2)
            #     = N * integral( exp(-(x/(sqrt(2) s))^2) dx )
            #
            # Let u  = x/(sqrt(2) s)
            #     du = dx/(sqrt(2) s)
            #     u(x = binwidth/2) = binwidth/(s 2sqrt(2)) ->
            #
            #   k = N * sqrt(2) s * integral( exp(-u^2) du )
            #     = N*sqrt(2pi) s * erf(binwidth / (s 2*sqrt(2)))
            #
            # for low x erf(x) ~ 2x/sqrt(pi). So if binwidth << sigma
            # k = N*sqrt(2pi) s * erf(binwidth / (s 2*sqrt(2)))
            #   ~ N*sqrt(2pi) s * (binwidth/(s 2*sqrt(2))) *2 / sqrt(pi)
            #   ~ N binwidth
            return \
                '{k}*exp(-(x-{mean})*(x-{mean})/(2.*{var})) / sqrt(2.*pi*{var}) title "{title}" with lines lw 2'. \
                format(mean= 0,
                       var = sigma*sigma,
                       title = title,
                       k   = N * np.sqrt(2.*np.pi) * sigma * erf(binwidth/(2.*np.sqrt(2)*sigma)))

        equations = [make_gaussian(sigma,title) for sigma,title in \
                     ( (sigma_expected, 'Normal distribution of residuals with expected stdev: {:.02f} pixels'.format(sigma_expected)),
                       (sigma_observed, 'Normal distribution of residuals with observed stdev: {:.02f} pixels'.format(sigma_observed)))]
        plots_how[i_camera+1] = \
            gp.gnuplotlib(equation_above = equations,
                          title = 'Observed and expected distribution of fitted reprojection errors {}'. \
                          format( 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                          xlabel = 'Reprojection error (pixels). x and y components of error are counted separately',
                          ylabel = 'Observed frequency',
                          **kwargs)
        plots_how[i_camera+1].plot(x, histogram=1, binwidth=binwidth,)

    elif how == 'radial':
        r = np.sqrt(nps.norm2(obs - focus_center))
        plots_how[i_camera+1] = \
            gp.gnuplotlib(
                title = 'Fitted reprojection errors shown against distance from {}. Data from {}'. \
                format( focus_center, 'everywhere' if focus_radius==0 else '{} pixels from {}'.format(focus_radius, focus_center)),
                xlabel = 'Distance from {} (pixels)'.format(focus_center),
                ylabel = 'Reprojection error (pixels). x and y components of error are counted separately',
                **kwargs)
        plots_how[i_camera+1]. \
            plot( nps.transpose(nps.cat(r,r)).ravel(),
                  err.ravel(),
                  _with='points')

    elif how == 'regional':

        if i_camera < 0:
            raise Exception("Regional visualization for 'all' cameras at once isn't useful. Pass i_camera >= 0")

        mean,stdev,count,using = \
            mrcal.report_residual_statistics(obs,err,
                                             imagersizes[i_camera])
        def mkplot(x, title, **kwargs_here):
            kwargs_here.update(kwargs)
            if 'hardcopy' in kwargs_here:
                what = re.sub('[^a-zA-Z0-9_-]+', '_', title)
                kwargs_here['hardcopy'] = re.sub(r'(\.[^\.]+$)', '.' + what + r'\1', kwargs_here['hardcopy'])

            p = gp.gnuplotlib( _3d=1,
                               ascii=1,
                               unset='grid',
                               _xrange=[0,W], _yrange=[H,0],
                               _set = ['xrange [:] noextend',
                                       'yrange [:] noextend reverse',
                                       'view equal xy',
                                       'view map'],
                               title = title,
                               **kwargs_here)
            plot_data_args = [( nps.transpose(x),
                                dict(tuplesize=3,
                                     _with='image',
                                     using=using))]
            if valid_intrinsics_region_plotarg_3d is not None:
                plot_data_args.append(valid_intrinsics_region_plotarg_3d)
            p.plot(*plot_data_args)
            return p

        plots_how[i_camera+1] = [ mkplot(np.abs(mean), 'abs(mean)'),
                                  mkplot(stdev,        'stdev'),
                                  mkplot(count,        'count', cbrange = (0, 20)) ]

    else:
        raise Exception("Unknown visualization method '{}'. I know of 'vectorfield','heatmap','histogram','radial','regional'". \
                        format(how))


plots_intrinsics_uncertainty = [None] * Ncameras
def show_intrinsics_uncertainty(i_camera = None, outlierness = False, gridn_x = 60, gridn_y = 40, **kwargs):

    if invJtJ_intrinsics_observations_only is None:
        print("No intrinsics uncertainty was computed. You need to call mrcal.optimize(..., get_invJtJ_intrinsics = True) for this to work")
        return False


    global plots_intrinsics_uncertainty
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))
    for i_camera in i_camera_all:
        plots_intrinsics_uncertainty[i_camera] = \
            mrcal.show_intrinsics_uncertainty(intrinsics[0],
                                              intrinsics[1][i_camera],
                                              imagersizes  [i_camera],
                                              args.observed_pixel_uncertainty,
                                              invJtJ_intrinsics_full[i_camera] if outlierness else invJtJ_intrinsics_observations_only[i_camera],
                                              outlierness,
                                              valid_intrinsics_region[i_camera],
                                              extratitle = "Camera {} with {}".format(i_camera, intrinsics[0]),
                                              gridn_x=gridn_x,
                                              gridn_y=gridn_y,
                                              cbmax=5,
                                              **kwargs)
plots_valid_intrinsics_region = [None] * Ncameras
def show_valid_intrinsics_region(i_camera = None, **kwargs):
    global plots_valid_intrinsics_region
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))
    for i_camera in i_camera_all:
        plots_valid_intrinsics_region[i_camera] = \
            mrcal.show_valid_intrinsics_region(models[i_camera],
                                               title = "Valid-intrinsics region for camera {}".format(i_camera),
                                               **kwargs)

plots_distortion = [None] * Ncameras
def show_distortion(mode, i_camera, gridn_x = 60, gridn_y = 40, **kwargs):

    global plots_distortion
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))
    for i_camera in i_camera_all:
        plots_distortion[i_camera] = \
            mrcal.show_distortion(intrinsics[0],intrinsics[1][i_camera],
                                  imagersizes[i_camera],
                                  mode,
                                  extratitle = "camera {}".format(i_camera),
                                  gridn_x=gridn_x,
                                  gridn_y=gridn_y,
                                  **kwargs)

plots_roi = [None] * Ncameras
def show_roi(i_camera = None, **kwargs):
    global plots_roi
    i_camera_all = (i_camera,) if i_camera is not None else range(len(intrinsics[1]))

    NboardPoints     = args.object_width_n*args.object_width_n
    Nfeatures        = NboardPoints*len(observations)
    feats            = observations.reshape(Nfeatures,2)

    def append_icamera(iFeatures):
        '''input: (N,) array of feature indices; output: (2,N) array of feature,camera indices)'''
        iObservations = iFeatures / NboardPoints
        iObservations = iObservations.astype(int)
        iCamera = np.array([indices_frame_camera[iObs,1] for iObs in iObservations])
        return nps.cat(iFeatures, iCamera)

    iFeature_roi_out = append_icamera(stats['outside_ROI_indices'])
    iFeature_roi_in  = append_icamera(np.setdiff1d(np.arange(Nfeatures), iFeature_roi_out[0,:]))

    for i_camera in i_camera_all:

        iFeature_roi_in_thiscam  = iFeature_roi_in [ 0, iFeature_roi_in [1,:] == i_camera]
        iFeature_roi_out_thiscam = iFeature_roi_out[ 0, iFeature_roi_out[1,:] == i_camera]

        plots_roi[i_camera] = \
            gp.gnuplotlib(square=1, xrange=(0,imagersizes[i_camera,0]-1),yrange=(imagersizes[i_camera,1]-1,0), _with='points pt 7 ps 2',
                          **kwargs)
        plots_roi[i_camera]. \
            plot( (feats[iFeature_roi_in_thiscam, 0], feats[iFeature_roi_in_thiscam, 1], dict(legend='in' )),
                  (feats[iFeature_roi_out_thiscam,0], feats[iFeature_roi_out_thiscam,1], dict(legend='out')) )

import IPython
IPython.embed()
