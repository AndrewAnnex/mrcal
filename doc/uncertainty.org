#+TITLE: Projection uncertainty
#+OPTIONS: toc:t

After a calibration has been computed, it is important to get a sense of how
good the calibration is. Without doing that, we have no idea of the precision of
the data products that use the calibration. We have a vague sense that "more
chessboard observations are better", but that's about it.

mrcal addresses this by providing an estimate of projection uncertainty
explicitly via the [[file:mrcal-python-api-reference.html#-projection_uncertainty][=mrcal.projection_uncertainty()=]] function. This tells you how
good your calibration is (lower projection uncertainties are good), and it tells
you how good your downstream results are (by allowing the user to propagate the
projection uncertainties through their data pipeline).

A grand summary of the process:

1. Estimate the noise distribution on the chessboard observations input to the
   calibration routine
2. Propagate that uncertainty to the optimal parameters $\vec p$ reported by the
   calibration routine
3. Propagate the uncertainty in calibration parameters $\vec p$ through the
   projection function to get uncertainty in the resulting pixel coordinate $\vec
   q$

This overall approach is sound, but it implies some limitations:

- Only the response to chessboard observation noise is taken into account. Any
  other issues are /not/ included in the reported uncertainty. Issues such as:
  motion blur, out-of-focus images, out-of-synchronization images, unexpected
  chessboard shape. It is thus imperative that we try to minimize these issues,
  and mrcal provides [[file:how-to-calibrate.org][tools]] to detect some of these problems.

- A consequence of the above is that the choice of lens model affects the
  reported uncertainties. Lean models (those with few parameters) are less
  flexible than rich models, and don't fit general lenses as well as rich models
  do. However, this stiffness also serves to limit the model's response to noise
  in their parameters. So the above method will report less uncertainty for
  leaner models than rich models. So, unless we're /sure/ that a given lens
  follows some particular lens model perfectly, a [[file:lensmodels.org::#splined-stereographic-lens-model][splined lens model]] (i.e. a
  very rich model) is recommended for truthful uncertainty reporting. Otherwise
  the reported confidence comes from the model itself, rather than the
  calibration data.

- Currently the uncertainty estimates can be computed only from a vanilla
  calibration problem: a set of stationary cameras observing a moving
  calibration object. Other formulations can be used to compute the lens
  parameters as well (structure-from-motion while also computing the lens models
  for instance), but at this time the uncertainty computations cannot handle
  those cases.

* Propagating input noise to the state vector
We solved the least squares problem, so we have the optimal state vector $\vec p^*$. Let's find
the uncertainty at this point.

We apply a perturbation to the observations $\vec q_\mathrm{ref}$, reoptimize
this slightly-perturbed least-squares problem (assuming everything is linear)
and look what happens to the optimal state vector $\vec p$.

We have

\[ E \equiv \left \Vert \vec x \right \Vert ^2 \]
\[ J \equiv \frac{\partial \vec x}{\partial \vec p} \]
\[ \frac{\partial E}{\partial \vec p} \left(\vec p = \vec p^* \right) = 2 J^T \vec x^* = 0 \]

We perturb the problem:

\[ E( \vec p + \Delta \vec p, \vec q_\mathrm{ref} + \Delta \vec q_\mathrm{ref})) \approx \left \Vert \vec x + J \Delta \vec p + \frac{\partial \vec x}{\partial \vec q_\mathrm{ref}} {\Delta \vec q_\mathrm{ref}} \right \Vert ^2 \]

And we reoptimize:

\[ \frac{\mathrm{d}E}{\mathrm{d}\Delta \vec p} \approx 
2 \left( \vec x + J \Delta \vec p + \frac{\partial \vec x}{\partial \vec q_\mathrm{ref}} {\Delta \vec q_\mathrm{ref}} \right)^T J = 0\]

we started at an optimum, so $J^T \vec x^* = 0$, and thus

\[ J^T J \Delta \vec p = -J^T \frac{\partial \vec x}{\partial \vec q_\mathrm{ref}} {\Delta \vec q_\mathrm{ref}} \]

As stated above, for reprojection errors we have

\[ \vec x_\mathrm{observations} = W (\vec q - \vec q_\mathrm{ref}) \]

where $W$ is a diagonal matrix of weights. Let's assume the non-observations
elements of $\vec x$ are at the end, so

\[ \frac{\partial \vec x}{\partial \vec q_\mathrm{ref}} =
\left[ \begin{array}{cc} - W \\ 0 \end{array} \right] \]

and thus

\[ J^T J \Delta \vec p = -J_\mathrm{observations}^T W \Delta \vec q_\mathrm{ref} \]

So if we perturb the input observation vector $q_\mathrm{ref}$ by $\Delta
q_\mathrm{ref}$, the resulting effect on the optimal parameters is $\Delta \vec
p = M \Delta \vec q_\mathrm{ref}$. Where

\[ M = - \left( J^T J \right)^{-1} J_\mathrm{observations}^T W \]

As usual,

\[ \mathrm{Var}(\vec p) = M \mathrm{Var}\left(\vec q_\mathrm{ref}\right) M^T \]

As stated before, we're assuming independent noise on all observed pixels, with
a standard deviation inversely proportional to the weight:

\[ \mathrm{Var}\left( \vec q_\mathrm{ref} \right) = \sigma^2 W^{-2} \]

so

\begin{aligned}
\mathrm{Var}\left(\vec p\right) &= \sigma^2 M W^{-2} M^T \\
&= \sigma^2 \left( J^T J \right)^{-1} J_\mathrm{observations}^T W W^{-2} W J_\mathrm{observations} \left( J^T J \right)^{-1} \\
&= \sigma^2 \left( J^T J \right)^{-1} J_\mathrm{observations}^T J_\mathrm{observations}  \left( J^T J \right)^{-1}
\end{aligned}

If we have no regularization, and all measurements are pixel errors, then
$J_\mathrm{observations} = J$ and

\[\mathrm{Var}\left(\vec p\right) = \sigma^2 \left( J^T J \right)^{-1} \]

Note that this does not explicitly depend on $W$. However, the weights are a
part of $J$. So if observation $i$ were to become less precise,
$\mathrm{Var}\left(\vec q_{\mathrm{ref}_i} \right)$ would increase, which means
that $w_i$ and $x_i$ and $J_i$ would all decrease. And as a result,
$\mathrm{Var}\left(\vec p\right)$ would increase, as expected.

* Propagating the state vector noise through projection
I now have the variance of the full optimization state $\vec p$. This contains
the intrinsics and extrinsics of /all/ the cameras. And it contains /all/ the
poses of observed chessboards, and everything else, like the chessboard warp
terms.

How are those parameters used during the optimization? The fundamental operation
is projecting points in a "frame" coordinate system (the coordinate system of a
chessboard). Projecting a point $p_\mathrm{chessboard}$ involves several
transformations and then a projection:

\[ \vec q                     \xleftarrow{\mathrm{intrinsics}}
   \vec p_\mathrm{camera}     \xleftarrow{T_\mathrm{cr}}
   \vec p_\mathrm{reference}  \xleftarrow{T_\mathrm{rf}}
   \vec p_\mathrm{frame}
\]

Here the $\mathrm{intrinsics}$ are the lens parameters, $T_\mathrm{cr}$ is the
extrinsics transformation, and $T_\mathrm{rf}$ is the "frame" transformation.
Each is an element of the state vector $\vec p$ whose uncertainty we have.

So how can we estimate $\mathrm{Var}\left( \vec q \right)$? The simplest thing
to do is to focus just on the projection operation:

\[\vec q = \mathrm{project}\left(\vec p_\mathrm{camera}, \mathrm{intrinsics}\right)\]

We can use this expression to propagate the intrinsics uncertainties, but this
is insufficient. We want to know the projection uncertainty of points in a
/fixed/ coordinate system, a coordinate system that doesn't move due to random
shifts in the state $\vec p$. As we can see above, $\vec p_\mathrm{camera}$
depends on the extrinsics, which are a part of the state.

[[file:figures/uncertainty.svg]]

But what if we only have one camera, and thus we have no extrinsics (the camera
coordinate system /is/ the reference coordinate system)? This doesn't work
either. The lens intrinsics encode an implied transformation that moves the
camera coordinate system, so once again $\vec p_\mathrm{camera}$ would move in
response to our perturbation.

So how do we operate on points in a fixed coordinate system when all the
coordinate systems we have are floating random variables? We can use the poses
of the observed chessboards in aggregate: these are the most fixed thing we
have.

Let's focus on /one/ observed chessboard frame: frame 0. I want to know the
uncertainty at a pixel coordinate $\vec q$. I follow the sequence above in
reverse:

\[ \vec p_{\mathrm{frame}_0} = T_{\mathrm{f}_0\mathrm{r}} T_\mathrm{rc} \mathrm{unproject}\left( \vec q \right) \]

This is a "fixed" point. I then transform and project $\vec p_{\mathrm{frame}_0}$
back to the imager to get $\vec q^+$. But here I take into account the
uncertainties of each transformation to get the desired projection uncertainty
$\mathrm{Var}\left(\vec q^+ - \vec q\right)$. The full data flow looks like
this, with all the perturbed quantities superscripted with a $+$.

\[
   \vec q^+                         \xleftarrow{\mathrm{intrinsics}^+}
   \vec p^+_\mathrm{camera}         \xleftarrow{T^+_\mathrm{cr}}
   \vec p^+_{\mathrm{reference}_0}  \xleftarrow{T^+_{\mathrm{rf}_0}} \vec p_{\mathrm{frame}_0} \xleftarrow{T_\mathrm{fr}}
   \vec p_\mathrm{reference}
   \xleftarrow{T_\mathrm{rc}}   \vec p_\mathrm{camera}
   \xleftarrow{\mathrm{intrinsics}}
   \vec q
\]

This works, but it depends on $\vec p_{\mathrm{frame}_0}$ being "fixed", which it
isn't, since $T_\mathrm{f0r}$ is in the optimization state /and/ since the
reference coordinate system that $T_\mathrm{f0r}$ relates to isn't fixed either.
However, we're observing more than one chessboard, and /together/ all the
chessboard frames can represent a mostly-fixed reference.

How do I combine all the different estimates from the different chessboard
observations? I take a very simple approach: I compute the mean of all the $\vec
p^+_\mathrm{reference}$ estimates from each frame. The full data flow looks like
this:

\begin{aligned}
   & \swarrow                   & \vec p^+_{\mathrm{reference}_0}  & \xleftarrow{T^+_{\mathrm{rf}_0}} & \vec p_{\mathrm{frame}_0} & \nwarrow & \\
   \vec q^+                      \xleftarrow{\mathrm{intrinsics}^+}
   \vec p^+_\mathrm{camera}      \xleftarrow{T^+_\mathrm{cr}}
   \vec p^+_\mathrm{reference}
   & \xleftarrow{\mathrm{mean}} & \vec p^+_{\mathrm{reference}_1}  & \xleftarrow{T^+_{\mathrm{rf}_1}} & \vec p_{\mathrm{frame}_1} & \xleftarrow{T_\mathrm{fr}} &
   \vec p_\mathrm{reference}
   \xleftarrow{T_\mathrm{rc}}   \vec p_\mathrm{camera}
   \xleftarrow{\mathrm{intrinsics}}
   \vec q \\
   & \nwarrow                   & \vec p^+_{\mathrm{reference}_2}  & \xleftarrow{T^+_{\mathrm{rf}_2}} & \vec p_{\mathrm{frame}_2} & \swarrow
\end{aligned}

This is better, but has another issue. What is the transformation relating the
original and perturbed reference coordinate systems?

\[ T_{\mathrm{r}^+\mathrm{r}} = \mathrm{mean}_i \left( T_{\mathrm{r}^+\mathrm{f}_i} T_{\mathrm{f}_i\mathrm{r}} \right) \]

Each transformation $T$ includes a rotation matrix $R$, so the above constructs
a new rotation as a mean of multiple rotation matrices, which is aphysical: the
resulting matrix is not a valid rotation. In practice, the perturbations are
tiny, and this is sufficiently close. Extreme geometries do break this, and I
will tweak this approach in the future.

So to summarize, to compute the projection uncertainty at a pixel $\vec q$ we

1. Unproject $\vec q$ and transform to /each/ frame coordinate system $\vec
   p_{\mathrm{frame}_i}$

2. Transform and project back to $\vec q^+$, taking the mean of $\vec
   p_{\mathrm{reference}_i}$ and taking into account uncertainties

We have $\vec q^+\left(\vec p\right) = \mathrm{project}\left( T_\mathrm{cr} \,
\mathrm{mean}_i \left( T_{\mathrm{rf}_i} \vec p_{\mathrm{frame}_i} \right)
\right)$ so

\[ \mathrm{Var}\left( \vec q \right) = \frac{\partial \vec q}{\partial \vec p} \mathrm{Var}\left( \vec p \right ) \frac{\partial \vec q}{\partial \vec p}^T \]

$\mathrm{Var}\left( \vec p \right )$ is the variance of the optimization state
vector we computed earlier, and $\frac{\partial \vec q}{\partial \vec p}$ comes
from the projection expression above.

The [[file:mrcal-python-api-reference.html#-projection_uncertainty][=mrcal.projection_uncertainty()=]] function implements this logic, which can
also be accessed using the [[file:mrcal-show-projection-uncertainty.html][=mrcal-show-projection-uncertainty=]] tool.

* The effect of range
The above works, but it glosses over an important detail. Unlike a projection
operation, an /unprojection/ is ambiguous: given some camera-coordinate-system
point $\vec p$ that projects to a pixel $\vec q$, we have $\vec q =
\mathrm{project}\left(k \vec v\right)$ /for all/ $k$. So an unprojection gives
you a direction, but no range. The direct implication of this is that we can't
ask for an "uncertainty at pixel coordinate $\vec q$". Rather we must ask about
"uncertainty at pixel coordinate $\vec q$ looking out $x$ meters".

A surprising consequence of this is that while /projection/ is invariant to
scaling ($k \vec v$ projects to the same $\vec q$ for any $k$), the uncertainty
of this projection is /not/ invariant to this scaling:

[[file:figures/projection-scale-invariance.svg]]

Let's look at the projection uncertainty at the center of the imager at
different ranges for an arbitrary model:

#+begin_src sh
mrcal-show-projection-uncertainty --vs-distance-at center data/board/opencv8.cameramodel --set 'yrange [0:0.4]'
#+end_src

[[file:figures/uncertainty-vs-distance-at-center.svg]]

So the uncertainty grows without bound as we approach the camera. As we move
away, there's a sweet spot where we have maximum confidence. And as we move
further out still, we approach some uncertainty asymptote at infinity.
Qualitatively this is the figure I see 100% of the time, with the position of
the minimum and of the asymptote varying.

Why is the uncertainty unbounded as we approach the camera? Because we're
looking at the projection of a stationary global point into a camera whose
position is uncertain. As we get closer to the origin of the camera, the noise
in the camera position dominates the projection, and the uncertainty shoots to
infinity.

What controls the range where we see the uncertainty optimum? The range where we
observed the chessboards. The uncertainty we asymptotically approach at infinity
is set by the specifics of the chessboard dance. See the [[file:tour.org::#choreography][tour of mrcal]] for a
study.

More uncertainty results are reported in the [[file:tour.org::#uncertainty][tour of mrcal]].
