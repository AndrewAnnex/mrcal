#+TITLE: Recipes
#+OPTIONS: toc:t

* Using a non-mrgingham corner detector or a non-chessboard
:PROPERTIES:
:CUSTOM_ID: non-mrgingham-detector
:END:

While in my day-to-day work I use /chessboards/ and process images of them using
the [[https://github.com/dkogan/mrgingham][mrgingham]] chessboard corner detector, this isn't a requirement. In fact,
mrcal doesn't care at all where its detections come from. The only requirements
on the calibration object are that

- The calibration object is nominally planar; small amounts of [[file:formulation.org::#board-deformation][deformation]] are
  allowed
- The object contains a /regular/ grid of points. Gaps are allowed, but the
  points that do exist must lie on this grid
- The grid spacing is identical in the horizontal and vertical directions
- Each point in the object is uniquely identifiable in each observation of the
  object

It's /not/ required that all points are observed in every image of the object:
partial observations of the board are supported by mrcal (mrgingham won't detect
those, but mrcal has no problem ingesting incomplete views). And boards that
don't contain a full grid are supported as well. For instance here's [[https://github.com/dkogan/mrcal/issues/4][a bug
report]] where somebody used a calibration board with an unrelated fiducial in
the middle.

To use a grid detector other than mrgingham, we need to produce a compatible
=corners.vnl= file. This is a [[https://www.github.com/dkogan/vnlog][=vnlog=]] (text table) where each row describes a
single corner detection.  A sample =corners.vnl= describing observations of a toy
2x2 chessboard:

#+begin_example
#   filename      x    y  weight
frame0-cam0.jpg 10.2 12.5 1.0   
frame0-cam0.jpg 21.2 15.1 1.0   
frame0-cam0.jpg  9.4 19.5 0.5   
frame0-cam0.jpg 21.3 23.6 1.0   
frame0-cam1.jpg -    -    -     
frame1-cam0.jpg -    -    -     
frame1-cam1.jpg 30.1 39.6 0.25  
frame1-cam1.jpg 45.8 38.5 1.0   
frame1-cam1.jpg -    -    -     
frame1-cam1.jpg 42.5 47.4 1.0   
#+end_example

Whitespace added for clarity. Here we have 2 cameras and 2 frames. Only
=frame0-cam0.jpg= and =frame1-cam1.jpg= have a chessboard detection, with one of
the corners missing in =frame1-cam1.jpg=.

The =corners.vnl= file contains 3 or 4 columns. The first 3 columns are:

- =filename=: a path to the image on disk
- =x=, =y=: pixel coordinates of a detected corner in the 

If a 4th column is present, it describes the detector's confidence in the
detection of that particular corner. It may be either

- =level=: the decimation level of the detected corner. If the detector needed
  to cut down the image resolution to find this corner, we report that
  resolution here. Level-0 means "full-resolution", level-1 means
  "half-resolution", level-2 means "quarter-resolution" and so on. A level of
  =-= or <0 means "skip this point"; this is how incomplete board observations
  are specified. This "decimation level" interpretation is the
  [[file:mrcal-calibrate-cameras.html][=mrcal-calibrate-cameras=]] default. This column is reported by mrgingham

- =weight=: how strongly to weight that corner. More confident detections take
  stronger weights. This should be inversely proportional to the standard
  deviation of the detected pixel coordinates. With decimation levels we have
  $\mathrm{weight} = 2^{-\mathrm{level}}$. As before, a weight of =-= or <0
  means "skip this point"; this is how incomplete board observations are
  specified. Select this "weight" interpretation with =mrcal-calibrate-cameras
  --corners-cache-has-weights=

If no 4th column is present, we assume an even weight of 1.0 for all the points.

The whole chessboard is described by a sequence of these corner detections,
listed in a /consistent/ grid order: the first row is traversed point-by-point
in order, then the second row, and so on. Each chessboard image is represented
by either /exactly/ $N_\mathrm{width} N_\mathrm{height}$ corner records or a
single record

#+begin_example
FILENAME - - -
#+end_example

to represent images with no detected corners. An image with incomplete
detections should /still/ contain $N_\mathrm{width} N_\mathrm{height}$ records
in the same consistent order. The missing corners should be given with any =x=,
=y=, but with $\mathrm{weight} \leq 0$ or =-=. The record could be completely
null:

#+begin_example
FILENAME - - -
#+end_example

The missing points are treated as outliers by the solver. Currently the
diagnostics included these points as outliers as well, although that will likely
change in the future.

* Using mrgingham with rotated cameras
:PROPERTIES:
:CUSTOM_ID: calibrating-upside-down
:END:

The [[https://github.com/dkogan/mrgingham][mrgingham corner detector]] is the usual tool I use to detect corners in
images of chessboards (although [[#non-mrgingham-detector][other methods are available]]). mrgingham looks
for plain chessboards in the images, without any extra fiducials. It reports the
corners in the top-most horizontal row in order from left to right. Then the
next row down, and the next row, and so on. Here "top", "left" and "right" are
the pixel coordinates in the image. The position of each corner in this list
uniquely identifies the corner. So the corner in row $i$, col $j$ always appears
at index $i N_\mathrm{width} + j$ in the list. This works well, as long as the
"horizontal" and "vertical" directions in the image are consistent, which they
usually are. However, if the camera orientation isn't identical across cameras
or across time, issues can arise.

Consider a 2-camera calibration where one camera is mounted rightside-up, but
the other is mounted upside-down. Here the first corner reported in the left
camera is the top-left corner in the chessboard, but the first corner reported
in the right camera is the bottom-right corner in the chessboard. The first
reported corner has index 0, so it must represent the same corner for all
cameras, but here it does not.

In the very common situation where the cameras are all mounted right-side-up or
sideways or upside-down we can handle this situation by reordering the corners
in a mrgingham corners list. This is done by the [[https://github.com/dkogan/mrgingham/mrgingham-rotate-corners][=mrgingham-rotate-corners=
tool]]. The usage is simple:

#+begin_src sh
< corners.vnl                        \
mrgingham-rotate-corners [--gridn N] \
  --90  REGEX_CAM_90deg              \
  --180 REGEX_CAM_180deg             \
  --270 REGEX_CAM_270deg             \
  [... more rotation selections ...] \
> corners-rotated.vnl
#+end_src

We pass in the =corners.vnl= set of detections. Filenames that were captured by
a camera rotated by 90deg are selected by =REGEX_CAM_90deg= and so on. The
result is a =corners-rotated.vnl= with reordered corners that meet the
assumptions of the solver, and can be passed to [[file:mrcal-calibrate-cameras.html][=mrcal-calibrate-cameras=]].
Another example:

#+begin_src sh
# camera A is rightside-up
# camera B is mounted sideways
# cameras C,D are upside-down
mrgingham --gridn N                \
  'frame*-cameraA.jpg'             \
  'frame*-cameraB.jpg'             \
  'frame*-cameraC.jpg'             \
  'frame*-cameraD.jpg' |           \
mrgingham-rotate-corners           \
  --gridn N                        \
  --90 cameraB                     \
  --180 'camera[CD]'               \
> corners-rotated.vnl
#+end_src

* Physical lens stability
:PROPERTIES:
:CUSTOM_ID: lens-stability
:END:

When we calibrate a camera system, we're assuming that the physical properties
of the system are fixed. If they weren't, then even a very accurate calibration
isn't very useful: the system may have changed by the time we actually use the
computed calibration.

As usual, we try to stabilize all parts of the system, and then we check to see
how well we did. In the [[file:tour.org][tour of mrcal]] we used a Samyang 12mm F2.8 fisheye lens.
This is not a machine-vision lens; it's intended to be used by human
photographers operating an SLR camera. As a result, it has moving parts. In
particular, the human-operated focus ring engages an internal mechanism that
physically moves the front lens assembly. Immobilizing the external focus ring
does /not/ immobilize the internal mechanism, so any mechanical backlash will
show up as an instability in intrinsics.

From experience, I know that this lens is sensitive to mechanical motion, and we
can clearly see this in the data. For the [[file:tour.org][tour of mrcal]] I gathered two
independent sets of chessboard images one after another, without moving
anything. This was used for [[file:tour-cross-validation.org][cross-validation]], and resulted in this diff:

[[file:external/figures/cross-validation/diff-cross-validation-splined-noncentral.png]]

Then I moved the camera and tripod over by 2m or so, and gathered more
chessboard images. Comparing these with the previous set showed a clear shift in
the intrinsics:

#+begin_src sh :exports none :eval no-export
mkdir -p ~/projects/mrcal-doc-external/figures/lens-stability/
D=~/projects/mrcal/doc/external/2022-11-05--dtla-overpass--samyang--alpha7/

function c {
  < $1 ~/projects/mrcal-noncentral/analyses/noncentral/centralize.py 3
}

mrcal-show-projection-diff                                                                                       \
  --no-uncertainties                                                                                             \
  --radius 500                                                                                                   \
  --cbmax 2                                                                                                      \
  --unset key                                                                                                    \
  <(c $D/3-*/splined-noncentral.cameramodel)                                                                     \
  <(c $D/4-*/splined-noncentral.cameramodel)                                                                     \
  --hardcopy ~/projects/mrcal-doc-external/figures/lens-stability/diff-dance34-splined-noncentral.png \
  --terminal 'pngcairo size 1024,768 transparent noenhanced crop font ",12"'
#+end_src

[[file:external/figures/lens-stability/diff-dance34-splined-noncentral.png]]

To be clear: this isn't a /bad/ lens, it's just not built with high-accuracy
machine vision in mind. A lens intended for machine vision applications would do
better. If we had to use /this/ lens, I would gather multiple sets of data
before and after stressing the system (shaking, flipping, heating, etc). Then
the resulting diffs would tell us how much to trust the calibration.

* Stability of extrinsics
Similarly to [[#lens-stability][the above discussion about the stability of lens intrinsics]], we
sometimes want to consider the stability of the camera-camera geometric
transformation in a multi-camera system. For instance, it's possible to have a
multi-camera system composed of very stable lenses mounted on a not-rigid-enough
mount. Any mechanical stresses wouldn't affect the intrinsics, but the
extrinsics /would/ shift. Evaluation of this motion is described on the [[file:differencing.org::*Extrinsics
differences][differencing page]].

* Interoperating with other tools
Any application that uses camera models is composed of multiple steps, some of
which would benefit from mrcal-specific logic. Specifically:

1. For successful long-range triangulation or stereo we need maximum precision
   in our lens models. mrcal supports [[file:splined-models.org][=LENSMODEL_SPLINED_STEREOGRAPHIC=]]: a rich
   model that fits real-world lenses better than the lean models used by other
   tools. This is great, but as of today, mrcal is the only library that knows
   how to use these models.

2. Furthermore, mrcal can use [[file:stereo.org::#stereo-rectification-models][=LENSMODEL_LATLON=]] to describe the rectified
   system instead of the more traditional [[file:stereo.org::#stereo-rectification-models][=LENSMODEL_PINHOLE= rectification
   function]]. This allows nice stereo matching even with wide lenses, but once
   again: these rectified models and images can only be processed with mrcal.

A common need is to use mrcal's improved methods in projects built around legacy
stereo processing. This usually means selecting specific chunks of mrcal to
utilize, and making sure they can function as part of the existing framework.
Some relevant notes follow.

You can create /very/ accurate models with [[file:splined-models.org][=LENSMODEL_SPLINED_STEREOGRAPHIC=]]:
these have very low [[file:uncertainty.org][projection uncertainty]] and [[file:tour-cross-validation.org][cross-validation diffs]]. Even if
these models are not supported in the production system, it is worth solving
with them to serve as a ground truth.

** Utilizing a too-lean production model
If we calibrated with [[file:splined-models.org][=LENSMODEL_SPLINED_STEREOGRAPHIC=]] to get a ground truth,
we can recalibrate using the same data for whatever model is supported. A
[[file:differencing.org][difference]] can be computed to estimate the projection errors we expect from this
production lens model. There's a trade-off between how well the production model
fits and how much data is included in the calibration: the fit is usually good
near the center, with the errors [[file:differencing.org::#fitting-data-selection][increasing as we include more and more of the
imager towards the corners]]. If we only care about a region in the center, we
should cull the unneeded points with, for instance, the [[file:mrcal-cull-corners.html][=mrcal-cull-corners=]]
tool. This would make the production model fit better in the area we care about.

Keep in mind that these lens-model errors are correlated with each other when we
look at observations across the imager. And these errors are present in each
observation, so they're correlated across time as well. So these errors will
/not/ average out, and they will produce a bias in whatever these observations
are ultimately used for.

To be certain about how much error results from the production lens model alone,
you can [[file:how-to-calibrate.org::#simulating-perfect-data][generate perfect data using the splined solve, and reoptimize it with
the production model]]. This reports unambiguously the error due to the
lens-model-fitting issues in isolation.

** Reprojecting to a lean production model
It is possible to use a lean camera model /and/ get the full accuracy of
[[file:splined-models.org][=LENSMODEL_SPLINED_STEREOGRAPHIC=]] if we spend a bit of computation time:

1. Calibrate with [[file:splined-models.org][=LENSMODEL_SPLINED_STEREOGRAPHIC=]] to get the ground truth
2. Compute an acceptable production model that is close-ish to the ground truth.
   This doesn't need to be perfect
3. During operation of the system, reproject each captured image from the
   splined model to the production model using, for instance, the
   [[file:mrcal-reproject-image.html][=mrcal-reproject-image=]] tool.
4. Everything downstream of the image capture should be given the production
   model and the reprojected image

The (production model, reprojected image) pair describes the same scene as the
(splined model, captured image) pair. The downsides of doing this are the
quantization errors that result from resampling the input image and the
computation time. If we don't care about computation time at all, the production
model can use a higher resolution than the original image, which would reduce
the quantization errors.

** Using the [[file:stereo.org::#stereo-rectification-models][=LENSMODEL_LATLON= rectification model]]
To utilize the wide-lens-friendly [[file:stereo.org::#stereo-rectification-models][=LENSMODEL_LATLON= rectification model]], mrcal
must be involved in computing the rectified system and in converting disparity
values to ranges. There's usually little reason for the application to use the
rectified models and disparities for anything other than computing ranges, so
swapping in the mrcal logic here usually isn't effortful.

* Visualizing post-solve chessboard observations
:PROPERTIES:
:CUSTOM_ID: reproject-to-chessboard
:END:

mrcal is primarily a geometric toolkit: after we [[file:how-to-calibrate.org::#corner-detector][detect the chessboard corners]],
we never look at the chessboard images again, and do /everything/ with the
detected corner coordinates. This assumes the chessboard detector works
perfectly. At least for [[https://github.com/dkogan/mrgingham/][=mrgingham=]], this is a close-enough assumption; but it's
nice to be able to double-check. To do that the mrcal sources include the
[[https://www.github.com/dkogan/mrcal/blob/master/analyses/mrcal-reproject-to-chessboard][=mrcal-reproject-to-chessboard= tool]]; this is still experimental, so it's not
included in a mrcal installation, and currently has to be invoked from source.
This tool takes in completed calibration, and reprojects each chessboard image
to a chessboard-referenced space: each resulting image shows just the
chessboard, with each chessboard corner appearing at exactly the same pixel in
each image. Example from the [[file:tour.org][tour of mrcal]]:

#+begin_src sh
analyses/mrcal-reproject-to-chessboard \
  --image-path-prefix images           \
  splined.cameramodel
#+end_src
#+begin_src sh :exports none :eval no-export
Dout=~/projects/mrcal-doc-external/figures/reprojected-to-chessboard
mkdir -p $Dout

D=/home/dima/projects/mrcal-doc-external/2022-11-05--dtla-overpass--samyang--alpha7/3-f22-infinity/;
analyses/mrcal-reproject-to-chessboard \
  --image-path-prefix $D/images        \
  --outdir $Dout \
  $D/splined.cameramodel

ffmpeg \
  -r 5 -f image2 -export_path_metadata 1 \
  -pattern_type glob -i "$Dout/DSC*.JPG" \
  -filter:v "drawtext=text='%{metadata\\:lavf.image2dec.source_basename}':fontcolor=yellow:fontsize=48" \
  -y \
  $Dout/reprojected-to-chessboard.mp4
#+end_src

[[file:external/figures/reprojected-to-chessboard/DSC06155.JPG]]

The red circles indicate the corner observations classified as outliers by the
solver. This tool useful to look at the reprojected images in a quick
succession. Ideally every reprojected image should be very similar, with each
chessboard corner randomly, and independently jumping around a tiny bit (this is
reported in the [[file:tour-initial-calibration.org::#opencv8-solve-diagnostics][fit residuals]]). If the detector had issues or an image was
faulty in some way, this would be clearly seen by eyeballing the sequence of
images. The whole image would shift; or a single non-outlier corner would jump.
It's good to eyeball these animations as a final sanity check before accepting a
calibration. In this dataset, we have [[file:external/figures/reprojected-to-chessboard/reprojected-to-chessboard.mp4][this all-corner animation]] from ([[file:external/figures/reprojected-to-chessboard/][these
images]]). No issues here. For questionable calibration objects (such as grids
of circles), checking this is /essential/.

* Surveyed calibration
:PROPERTIES:
:CUSTOM_ID: surveyed-calibration
:END:

Usually cameras are calibrated by observing a moving calibration object with
stationary cameras. This is not the only possible scheme, and mrcal supports
others. A /surveyed/ calibration is one where the poses of the objects being
observed are pre-determined (by surveying them, for instance). Then we get a
simplified calibration problem:

- Camera is stationary, with a non-fixed pose: we solve for it
- Each point in space being observed has a fixed position. This is assumed to be
  known perfectly

Note that since the objects being observed are fixed, there is no interaction
between the multiple cameras being calibrated. So a multi-camera surveyed
calibration can be solved by computing several independent monocular
calibrations.

Furthermore, it doesn't matter if we're observing chessboards or discrete points
or both: everything being observed has a known, fixed position. So when solving
these problems we call =mrcal.optimize(...)= with

- =frames_rt_toref= and =points= placing the observed objects
- =do_optimize_frames = True= to tell the optimization to fix them in space
  instead of optimizing

uncertainty poor. not enough data.

This

m-c-c

Should show that you want multiple ranges of chessboards.
Unsurveyed is similar: you want tilted observations, which give you multiple
ranges at the same time.

#+begin_src sh
for z (2 8) { for seed (0 1) {
  test/test-surveyed-calibration.py \
    --seed-rng $seed \
    --z-ref-board0 $z \
    --write-model /tmp/surveyed-solve-z$z-seed$seed.cameramodel
} }
#+end_src

* [[file:mrcal-convert-lensmodel.html][=mrcal-convert-lensmodel=]]
xxx

* more                                                             :noexport:

chessboard video

show scene range error due to calibration

resolution tool

** CUSTOM_IDs linked to this document
Obtained like this:
#+begin_src sh
perl -nE  'if(/recipes.org::#(.+?)\]/) {say $1;}' *.org | sort -u
#+end_src

- [X] effect-of-chessboard-shape
- [X] effect-of-unfocused-corners
- [X] lens-stability
- [X] non-mrgingham-detector
- [X] rolling-shutter-and-sync-errors

I should look for generic "recipes" links also. grep for "recipes"
