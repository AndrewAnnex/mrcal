#+TITLE: Optimization problem formulation
#+OPTIONS: toc:t

mrcal contains a solver used to compute the lens models and/or geometry in any
given problem. This is accessible via either

- =mrcal_optimize()= routine in the [[file:c-api.org][C API]]
- [[file:mrcal-python-api-reference.html#-optimize][=mrcal.optimize()=]] routine in the Python API

These are the main call in the [[file:mrcal-calibrate-cameras.html][=mrcal-calibrate-cameras=]] tool (to calibrate
cameras) and [[file:mrcal-convert-lensmodel.html][=mrcal-convert-lensmodel=]] tool (to fit a different lens model into
an existing model). The optimization routines themselves are more general than
this, and can solve more problems, such as structure-from-motion. The APIs for
the handling of discrete points are still unstable, so the structure-from-motion
functionality remains undocumented for now.

The solver moves around in the space of /state/ vectors $\vec p$, trying to
minimize the cost function $E \equiv \left \Vert \vec x \right \Vert ^2$ where
$\vec x$ is the vector of /measurements/. The solver evaluates each hypothesis
$\vec p$ by repeatedly invoking a callback function to report $\vec x$ and the
local gradients $J \equiv \frac{\partial \vec x}{\partial \vec p}$. The callback
function is available by itself via

- =mrcal_optimizer_callback()= routine in the [[file:c-api.org][C API]]
- [[file:mrcal-python-api-reference.html#-optimizer_callback][=mrcal.optimizer_callback()=]] routine in the Python API

More or less, it's trying to find the set of geometry and lens parameters to
best explain the observed pixel coordinates.

* Optimization details
The mrcal solver is an optimization routine based on sparse nonlinear least
squares. The optimization loop is implemented in [[https://www.github.com/dkogan/libdogleg][=libdogleg=]], which uses the
[[https://people.engr.tamu.edu/davis/suitesparse.html][CHOLMOD solver]] to compute the [[https://en.wikipedia.org/wiki/Cholesky_decomposition][Cholesky factorization]]. With a Cholesky
factorization we can efficiently solve the linear system $J^T J \vec a = \vec b$
where the jacobian matrix $J$ is large and sparse.

The optimization problem is posed without constraints. This is achieved by using
[[https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation#Rotation_vector][Rodrigues vectors]] to represent rotations. A different rotation representation,
such as one using unit quaternions or rotation matrices would require
constraints: not all sets of 4 numbers are a unit quaternion, and not all sets
of 9 numbers are a valid rotation matrix.

The optimization algorithm is iterative, so it isn't guaranteed to converge to
the global optimum. Thus it is imperative to pass a good *seed* (an initial
estimate of the solution) to the optimization routines. The
[[file:mrcal-calibrate-cameras.html][=mrcal-calibrate-cameras=]] tool achieves this by

1. Computing an initial estimate directly using geometry and some simplifying
   assumptions. The geometric seeding routines are available by themselves:

   - [[file:mrcal-python-api-reference.html#-estimate_monocular_calobject_poses_Rt_tocam][=mrcal.estimate_monocular_calobject_poses_Rt_tocam()=]]: Estimate camera-referenced poses of the calibration object from monocular views
   - [[file:mrcal-python-api-reference.html#-estimate_joint_frame_poses][=mrcal.estimate_joint_frame_poses()=]]: Estimate world-referenced poses of the calibration object
   - [[file:mrcal-python-api-reference.html#-make_seed_pinhole][=mrcal.make_seed_pinhole()=]]: Compute an optimization seed for a camera calibration

2. And then refining that estimate with a sequences of optimization problems
   that allow more and more of the parameters to vary. The final problem is the
   /full/ problem where all the variables are free to move. The set of variables
   we're optimizing can be selected with the [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_problem_selections_t=]] structure
   passed to [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_optimize()=]] in C (or the =do_optimize_...= arguments to
   [[file:mrcal-python-api-reference.html#-optimize][=mrcal.optimize()=]] in Python).

* World geometry
There are 3 different coordinate systems in the optimization:

- *camera* coordinate system: the local coordinate system of each camera. The
  $x$ and $y$ axes are aligned with pixel coordinates in an image: $x$ is to the
  right and $y$ is down. $z$ is then forward to complete the right-handed
  system of coordinates.
- *frame* coordinate system: the local coordinate system of the chessboard. The
  chessboard is assumed mostly flat, with the grid of points lying in the $xy$
  plane. The origin is at the first point.
- *reference* coordinate system: the "world" coordinate system in the
  optimization problem. This coordinate system is the common system that ties
  everything together. Each chessboard pose is represented as a transformation
  between the local chessboard frame and the reference frame. And each camera
  pose is represented as the transformation between the local camera frame and
  the reference frame.

So the data flow to project a particular chessboard corner which sits at $\vec
p_\mathrm{frame}$ in the local chessboard coordinate system is:

\[ \vec q                     \xleftarrow{\mathrm{intrinsics}}
   \vec p_\mathrm{camera}     \xleftarrow{T_\mathrm{cr}}
   \vec p_\mathrm{reference}  \xleftarrow{T_\mathrm{rf}}
   \vec p_\mathrm{frame}
\]

where the intrinsics and the transformations $T_\mathrm{cr}$ and $T_\mathrm{rf}$ are elements of the state vector.

** Geometric free variables
If too many transformations are left as free variables for the optimizer to
find, the system will be under-determined, and the optimization routine will
fail: complaining about a "not positive definite" (singular in this case)
Hessian.

Example: we have 1 stationary camera observing 10 chessboards. We want to be
able to uniquely represent the transformation between each chessboard and the
camera, for a total of 10 transformations. If we optimize a separate
$T_\mathrm{cr}$ for the camera and 10 separate $T_\mathrm{rf}$ for each
chessboard, we will have 11 transformations in the optimization vector. Here 11
> 10, so the system is under-determined, and the optimization will fail.

In a vanilla calibration problem, we would address this by fixing the reference
coordinate system to one of the camera or chessboard frames. The mrcal
convention is to fix the reference coordinate system to camera 0. In the above
example, this would reduce the number of transformations being optimized from 11
to 10, which would resolve the issue.

Any other method of making the optimization variables unique is valid also. For
instance, the chessboard poses might be known. In that case we don't need to
optimize any $T_\mathrm{rf}$, and solving for /all/ the $T_\mathrm{cr}$ is
valid.

** The meaning of the /reference/ coordinate system
The reference coordinate system is a single coordinate system common to the
whole optimization problem that all the objects in the world can use to localize
themselves. This reference coordinate system does /not/ have any physical
meaning beyond that. In particular, the reference coordinate system is /not/
attached to any fixed object in the world. So if we're looking at how the
optimal geometry would respond to perturbations in the camera observations, the
reference coordinate system would move, as would the camera and chessboard
coordinate systems. Please see the [[file:uncertainty.org][projection uncertainty]] documentation for more
information.

* Calibration object
:PROPERTIES:
:CUSTOM_ID: Calibration object
:END:
This is called a "chessboard" or just "board" in some parts of the code. The
optimization code refers to the chessboard pose array as "frames".

When running a camera calibration, we use observations of a known-geometry
object. At this time mrcal expects this object to be a planar grid of observable
points, with possibly a small amount of [[#board deformation][deformation]].

Usually this object is a chessboard-like grid of black and white squares, where
the observed points are the corners between squares. These are detected and
serve as the input features to mrcal. mrcal is a purely geometrical toolkit, so
this vision problem must be handled by another library. I recommend [[https://github.com/dkogan/mrgingham/][=mrgingham=]],
but any other source of grid observations may be used.

When given an image of a chessboard, the detector is directly observing the
feature we actually care about. Another common calibration board style is a grid
of circles. When given an image of a grid of circles, the detector sees the edge
of each circle, and then infers the circle center. This is difficult to do
accurately when given tilted images subjected to arbitrary lens behaviors. The
resulting inaccuracies in detections of the circle centers will introduce biases
into the solve that aren't modeled by the [[file:uncertainty.org::#noise model][projection uncertainty routine]], so
chessboards are /strongly/ recommended.

mrcal [[file:uncertainty.org::#noise model][assumes independent noise]] on each point observation, so correlated sources
of points (such as corners of an apriltag) are also not appropriate sources of
data currently. Apriltag centers would work, however.

** Board deformation
:PROPERTIES:
:CUSTOM_ID: board deformation
:END:

The calibration object is assumed to be planar. However, large calibration
boards used for calibration of wide lenses are never flat: temperature and
humidity effects deform the board strongly-enough to affect the calibration.
mrcal models this deformation with two axis-aligned parabolic factors. If the
chessboard grid spans $[-1,1]$ along the $x$ and $y$ axes, then I define the
non-planar deformation as $z \equiv k_x (1 - x^2) + k_y (1 - y^2)$ with $k_x$
and $k_y$ being the two deformation factors being optimized by the solver.

Empirically, this appears to work well: I get better-fitting solves, and less
systematic error. And the optimal deformation factors $k_x$, $k_y$ are
consistent between different calibrations. A richer deformation model could work
even better, and will eventually be the studied.

* State vector $\vec p$
The state vector $\vec p$ is controlled by the optimization algorithm as it
searches for the optimal solution. This vector may contain

- *intrinsics*: the lens parameters of all the cameras in the optimization problem
- *extrinsics*: the poses of all the cameras in the optimization problem. These
  are specified as unconstrained =rt= transformations from some arbitrary
  "reference". coordinate system, to the camera coordinate system. These are
  represented by $T_\mathrm{cr}$ in the flow diagram above.
- *frames*: the poses of all the chessboards in the optimization problem. These
  are specified as unconstrained =rt= transformations from the local chessboard
  coordinate system to some arbitrary "reference" coordinate system. These are
  represented by $T_\mathrm{rf}$ in the flow diagram above.
- *points*: the location in the reference coordinate system of any discrete
  points being observed. A vanilla "calibration" problem wouldn't have any of
  these, but an SFM problem would have many.
- *calibration-object warp*: the deformation of the calibration object. Large
  calibration boards used for calibration of wide lenses are never flat:
  temperature and humidity effects deform the board strongly-enough to affect
  the calibration. mrcal models this deformation with two axis-aligned parabolic
  factors. If the chessboard grid spans $[-1,1]$ along the $x$ and $y$ axes,
  then I define the non-planar deformation as $z \equiv k_x (1 - x^2) + k_y (1 -
  y^2)$ with $k_x$ and $k_y$ being the two deformation factors being optimized.

The optimization problem /could/ contain all those things, but it usually
doesn't. A vanilla calibration problem (stationary cameras, moving chessboard)
has no discrete points. A structure-from-motion problem (moving cameras,
stationary world being observed) usually has no chessboards or
calibration-object warping, but many discrete points. An intrinsics-fitting
problem (such as what [[file:mrcal-convert-lensmodel.html][=mrcal-convert-lensmodel=]] solves) has no extrinsics or
frames or calibration-object warping, but multiple discrete points.

** State vector layout
When analyzing the behavior of the optimizer it is often useful to pick out
particular elements of the full optimization vector $\vec p$. mrcal provides a
number of functions to report the index and size of the block of $\vec p$ that
contains specific data. In C:

- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_state_index_intrinsics()=]]: Return the index in the optimization vector of the intrinsics of camera i
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_state_index_extrinsics()=]]: Return the index in the optimization vector of the extrinsics of camera i
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_state_index_frames()=]]: Return the index in the optimization vector of the pose of frame i
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_state_index_points()=]]: Return the index in the optimization vector of the position of point i
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_state_index_calobject_warp()=]]: Return the index in the optimization vector of the calibration object warp

- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_num_states_intrinsics()=]]: Get the number of intrinsics parameters in the optimization vector
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_num_states_extrinsics()=]]: Get the number of extrinsics parameters in the optimization vector
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_num_states_frames()=]]: Get the number of calibration object pose parameters in the optimization vector
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_num_states_points()=]]: Get the number of point-position parameters in the optimization vector
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_num_states_calobject_warp()=]]: Get the number of parameters in the optimization vector for the board warp

- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_num_states()=]]: Get the full length of the optimization vector

And in Python:

- [[file:mrcal-python-api-reference.html#-state_index_intrinsics][=mrcal.state_index_intrinsics()=]]: Return the index in the optimization vector of the intrinsics of camera i
- [[file:mrcal-python-api-reference.html#-state_index_extrinsics][=mrcal.state_index_extrinsics()=]]: Return the index in the optimization vector of the extrinsics of camera i
- [[file:mrcal-python-api-reference.html#-state_index_frames][=mrcal.state_index_frames()=]]: Return the index in the optimization vector of the pose of frame i
- [[file:mrcal-python-api-reference.html#-state_index_points][=mrcal.state_index_points()=]]: Return the index in the optimization vector of the position of point i
- [[file:mrcal-python-api-reference.html#-state_index_calobject_warp][=mrcal.state_index_calobject_warp()=]]: Return the index in the optimization vector of the calibration object warp

- [[file:mrcal-python-api-reference.html#-num_states_intrinsics][=mrcal.num_states_intrinsics()=]]: Get the number of intrinsics parameters in the optimization vector
- [[file:mrcal-python-api-reference.html#-num_states_extrinsics][=mrcal.num_states_extrinsics()=]]: Get the number of extrinsics parameters in the optimization vector
- [[file:mrcal-python-api-reference.html#-num_states_frames][=mrcal.num_states_frames()=]]: Get the number of calibration object pose parameters in the optimization vector
- [[file:mrcal-python-api-reference.html#-num_states_points][=mrcal.num_states_points()=]]: Get the number of point-position parameters in the optimization vector
- [[file:mrcal-python-api-reference.html#-num_states_calobject_warp][=mrcal.num_states_calobject_warp()=]]: Get the number of parameters in the optimization vector for the board warp

If plotting a whole vector of state (or a vector of measurements), it is really
helpful to annotate the plot to make it clear which variables correspond to each
block of state (or measurements). mrcal provides helper functions to help with
this:

- [[file:mrcal-python-api-reference.html#-plotoptions_state_boundaries][=mrcal.plotoptions_state_boundaries()=]]: Return the 'set' plot options for gnuplotlib to show the state boundaries
- [[file:mrcal-python-api-reference.html#-plotoptions_measurement_boundaries][=mrcal.plotoptions_measurement_boundaries()=]]: Return the 'set' plot options for gnuplotlib to show the measurement boundaries

** State vector scaling
The nonlinear least squares-solving library used by mrcal is [[https://www.github.com/dkogan/libdogleg][=libdogleg=]], which
implements [[https://en.wikipedia.org/wiki/Powell's_dog_leg_method][Powell's dogleg method]]. This is a trust-region algorithm that
represents the trust region as a ball in state space. I.e. the radius of this
trust region is the same in every direction. And /that/ means that the
optimization will work best when each state variable in $\vec p$ affects the
cost function $E$ evenly. Example of what we don't want: camera positions
measured in km, while the chessboard positions are measured in mm.

Clearly getting identical behavior from each variable is impossible, but we can
scale the elements of $\vec p$ to keep things more or less even. Thus the
=libdogleg= optimization library never sees the full state vector $\vec p$, but
the scaled vector $\vec p_\mathrm{packed}$. Similarly, it never sees the full
jacobian $J \equiv \frac{\partial \vec x}{\partial \vec p}$, but rather
$J_\mathrm{packed} \equiv \frac{\partial \vec x}{\partial \vec
p_\mathrm{packed}}$. This means that the optimization callback functions /also/
report the packed state. These are

- =mrcal_optimizer_callback()= routine in the [[file:c-api.org][C API]]
- [[file:mrcal-python-api-reference.html#-optimizer_callback][=mrcal.optimizer_callback()=]] routine in the Python API

To pack or unpack an array of state, mrcal provides some routines. In C:

- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_pack_solver_state_vector()=]]: Scales a state vector to the packed, unitless form used by the optimizer
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_unpack_solver_state_vector()=]]: Scales a state vector from the packed, unitless form used by the optimizer

And in Python:

- [[file:mrcal-python-api-reference.html#-pack_state][=mrcal.pack_state()=]]: Scales a state vector to the packed, unitless form used by the optimizer
- [[file:mrcal-python-api-reference.html#-unpack_state][=mrcal.unpack_state()=]]: Scales a state vector from the packed, unitless form used by the optimizer

* Measurement vector $\vec x$
Given a hypothesis state vector $\vec p$ mrcal computes a vector of errors, or
/measurements/ $\vec x$. The optimization algorithm searches the space of
hypotheses $\vec p$, trying to minimize $E \equiv \left \Vert \vec x \right \Vert^2$.

We know where each point was observed in reality, and we know where the state
vector $\vec p$ predicts each one would have been observed. So we can construct
a vector of errors $\vec q_\mathrm{err} \equiv \vec q_\mathrm{predicted}\left(
\vec p \right) - \vec q_\mathrm{ref}$.

For each observation in $\vec q_\mathrm{ref}$ the chessboard corner detection
routine tells us how confident it was in that observation, from which we can get
a vector of weights $\vec w$: less confident observations are weighed less in
the optimization. See the [[file:uncertainty.org][projection uncertainty]] documentation for the noise
analysis. Let $W \equiv \mathrm{diag}\left( \vec w \right)$. Then I can define

\[ \vec x_\mathrm{observations} \equiv W q_\mathrm{err} = W \left( \vec
q_\mathrm{predicted}\left( \vec p \right) - \vec q_\mathrm{ref} \right) \]

This is the bulk of the measurement vector.

** Regularization
:PROPERTIES:
:CUSTOM_ID: Regularization
:END:

In addition to $\vec x_\mathrm{observations}$ the measurement vector contains
[[https://en.wikipedia.org/wiki/Regularization_(mathematics)][/regularization/]] terms. These are mostly-insignificant terms that are meant to
improve the convergence of the solver. These are aphysical, and cause a bias in
the solution. mrcal is careful to keep these small-enough to not break anything
noticeably. The behavior of these terms is likely to change in the future, so I
don't want to do document these in detail; please consult the sources for
detail. Currently the logic is at the end of the [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=optimizer_callback()=]] function
in =mrcal.c=.

It is possible to control whether a solve does/does not include regularization
terms with the =do_apply_regularization= bit in [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_problem_selections_t=]] or the
=do_apply_regularization= key in the call to [[file:mrcal-python-api-reference.html#-optimize][=mrcal.optimize()=]].

** Measurement vector layout
When analyzing the behavior of the optimizer it is often useful to pick out
particular elements of the full measurement vector $\vec x$. mrcal provides a
number of functions to report the index and size of the block of $\vec x$ that
contains specific data. In C:

- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_measurement_index_boards()=]]: Return the measurement index of the start of a given board observation
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_measurement_index_points()=]]: Return the measurement index of the start of a given point observation
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_measurement_index_regularization()=]]: Return the index of the start of the regularization measurements
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_num_measurements_boards()=]]: Return how many measurements we have from calibration object observations
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_num_measurements_points()=]]: Return how many measurements we have from point observations
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_num_measurements_regularization()=]]: Return how many measurements we have from regularization
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_measurements()=]]: Return how many measurements we have in the full optimization problem

And in Python:

- [[file:mrcal-python-api-reference.html#-measurement_index_boards][=mrcal.measurement_index_boards()=]]: Return the measurement index of the start of a given board observation
- [[file:mrcal-python-api-reference.html#-measurement_index_points][=mrcal.measurement_index_points()=]]: Return the measurement index of the start of a given point observation
- [[file:mrcal-python-api-reference.html#-measurement_index_regularization][=mrcal.measurement_index_regularization()=]]: Return the index of the start of the regularization measurements
- [[file:mrcal-python-api-reference.html#-num_measurements_boards][=mrcal.num_measurements_boards()=]]: Return how many measurements we have from calibration object observations
- [[file:mrcal-python-api-reference.html#-num_measurements_points][=mrcal.num_measurements_points()=]]: Return how many measurements we have from point observations
- [[file:mrcal-python-api-reference.html#-num_measurements_regularization][=mrcal.num_measurements_regularization()=]]: Return how many measurements we have from regularization
- [[file:mrcal-python-api-reference.html#-num_measurements][=mrcal.num_measurements()=]]: Return how many measurements we have in the full optimization problem

