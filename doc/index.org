#+title: mrcal - a toolkit for manipulating cameras, projections and geometry
#+author: Dima Kogan
#+email: dima@secretsauce.net
#+language: en

* Intro
mrcal is a toolkit for working with lens models, camera geometry, images,
projections, and the various related operations such as camera calibration. This
toolkit was originally built to produce high-accuracy calibrations demanded by
long-range stereo, so it provides facilities to analyze the results and to track
down sources of error.

mrcal provides a routine to compute the "[[Model differencing][difference]]" between two models, which
can be a fundamental piece of a wide number of analyses, for instance to measure
a lens's response to temperature cycles.

mrcal provides estimates of [[file:uncertainty.org][projection uncertainty]], which can be used to gauge
calibration quality, and to compute the uncertainty of any data products that
use the lens model.

A rich, [[Splined stereographic lens model][splined lens model]] is available to fit any projection function and to
provide realistic uncertainty estimates.

The core functionality is exposed from the [[C API][C API]], while higher-level routines
are available through [[Python API][Python]]. The most common workflows are available as
[[Commandline tools][commandline tools]], with no coding required.

Please see [[file:tour.org][a tour of mrcal]] for a high-level overview of the capabilities of the
toolkit.

* Conventions
** Terminology
Some terms in the documentation and sources can have ambiguous meanings, so I
explicitly define them here

- *calibration*: the procedure used to compute the lens parameters and geometry
  of a set of cameras. Usually this involves a stationary set of cameras
  observing a moving object.

- *calibration object* or *chessboard* or *board*: these are used more or less
  interchangeably. They refer to the known-geometry object observed by the
  cameras, with those observations used as input during calibration

- *pose*: a position and orientation

- *intrinsics*: the parameters describing the behavior of a lens. The pose of
  the lens does not affect the intrinsics

- *extrinsics*: the pose of a lens in respect to some fixed coordinate system

- *frames*: in the context of mrcal's optimization these refer to an array of
  poses of the observed chessboards

- *SFM*: structure from motion. This is the converse of "calibration": we
  observe a stationary scene from a moving camera to compute the geometry of the
  scene

- *state*: the vector of parameters that an optimization algorithm is free to
  move around as it searches for the optimum. mrcal generally refers to this
  vector as $\vec p$

- *measurements* or *residuals*: I use these more or less interchangeably. This
  is the vector whose norm the optimization algorithm is trying to minimize.
  mrcal generally refers to this as $\vec x$, and it contains differences
  between pixel coordinates observed by a camera, and where the state vector
  $\vec p$ predicts those observations should be. The optimization tries to
  minimize these differences by finding the $\vec p$ that minimizes $\left \Vert
  \vec x \right \Vert ^2$

- *project*: to map a point in space to a pixel coordinate where that point
  would be observed by a given camera

- *unproject*: to map a pixel coordinate back to a point in space that would
  produce an observation at that pixel. Unprojection is only unique up-to scale

- *camera model*: this is used to refer to the intrinsics and extrinsics
  together.

** Symbols
*** Geometry
- $\vec q$ is a 2-dimensional vector representing a pixel coordinate: $\left( x,y \right)$

- $\vec v$ is a 3-dimensional vector representing a /direction/ $\left( x,y,z
  \right)$ in space. $\vec v$ is only defined up-to-length. In a camera's
  coordinate system we have $\vec q = \mathrm{project}\left(\vec v \right)$

- $\vec p$ is a 3-dimensional vector representing a /point/ $\left( x,y,z
  \right)$ in space. Unlike $\vec v$, $\vec p$ has a defined range. Like $\vec
  v$ we have $\vec q = \mathrm{project}\left(\vec p \right)$

*** Optimization
The core of the mrcal calibration routine is a nonlinear least-squares
optimization

\[
\min_{\vec p} E = \min_{\vec p} \left \Vert \vec x \left( \vec p \right) \right \Vert ^2
\]

Here we have

- $\vec p$ is the vector of parameters being optimized. It's clear from context
  whether $\vec p$ refers to some point in space, or the optimization vector.

- $\vec x$ is the vector of /measurements/ describing the error of the solution
  at some hypothesis $\vec p$

- $\vec E$ is the cost function being optimized. $E \equiv \left \Vert \vec x \right \Vert ^2$

- $\vec J$ is the /jacobian/ matrix. This is the matrix $\frac{ \partial \vec x
  }{ \partial \vec p }$ 

** Camera coordinate system
mrcal uses right-handed coordinate systems. No convention is assumed for the
world coordinate system. The canonical /camera/ coordinate system has =x,y= as
with pixel coordinates in an image: =x= is to the "right" and =y= is "down". =z=
is then "forward" to complete the right-handed system of coordinates.

** Transformations
We describe transformations as mappings between a representation of a point in
one coordinate system to a representation of the /same/ point in another
coordinate system. =T_AB= is a transformation from coordinate system =B= to
coordinate system =A=. These chain together nicely, so if we know the
transformation between =A= and =B= and between =B= and =C=, we can transform a
point represented in =C= to =A=: =x_A = T_AB T_BC x_C = T_AC x_C=. And =T_AC =
T_AB T_BC=.

** Poses

Various parts of the toolkit have preferred representations of pose, and mrcal
has functions to convert between them. Available representations are:

- =Rt=: a (4,3) numpy array with a (3,3) rotation matrix concatenated with a
  (1,3) translation vector. This form is easy to work with, but there are
  implied constraints: most (4,3) numpy arrays are /not/ valid =Rt=
  transformations.

- =rt=: a (6,) numpy array with a (3,) vector representing a [[https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation#Rotation_vector][Rodrigues rotation]]
  concatenated with another (3,) vector, representing a rotation. This form
  requires more computations to deal with, but has no implied constraints: /any/
  (6,) numpy array is a valid =rt= transformation. Thus this is the form used
  inside the mrcal optimization routine.

Each of these represents a transformation =rotate(x) + t=.

Since a pose represents a transformation between two coordinate systems, the
toolkit generally refers to a pose as something like =Rt_AB=, which is an
=Rt=-represented transformation to convert a point from a representation in the
coordinate system =B= to a representation in coordinate system =A=.

A Rodrigues rotation vector =r= represents a rotation of =length(r)= radians
around an axis in the direction =r=. Converting between =R= and =r= is done via
the [[https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula][Rodrigues rotation formula]]: using the [[file:mrcal-python-api-reference.html#-r_from_R][=mrcal.r_from_R()=]] and
[[file:mrcal-python-api-reference.html#-R_from_r][=mrcal.R_from_r()=]] functions. For translating /poses/, not just rotations, use
[[file:mrcal-python-api-reference.html#-rt_from_Rt][=mrcal.rt_from_Rt()=]] and [[file:mrcal-python-api-reference.html#-Rt_from_rt][=mrcal.Rt_from_rt()=]].

There're [[file:mrcal-python-api-reference.html#-R_from_quat][several]] [[file:mrcal-python-api-reference.html#-quat_from_R][functions]] to work with unit quaternions as a rotation
representation, but they're lightly used, and exist only for compatibility with
other tools. mrcal does not use quaternions.

** Linear algebra
mrcal follows the usual linear algebra convention of column vectors. So applying
a rotation looks like $\vec b = R \vec a$ where both $\vec a$ and $\vec b$ are
column vectors.

However, numpy print vectors (1-dimensional objects), as /row/ vectors, so the
code treats 1-dimensional objects as transposed vectors. In the code, the above
rotation would be implemented equivalently: $\vec b^T = \vec a^T R^T$. The
[[file:mrcal-python-api-reference.html#-rotate_point_R][=mrcal.rotate_point_R()=]] and [[file:mrcal-python-api-reference.html#-transform_point_Rt][=mrcal.transform_point_Rt()=]] functions serve to
handle this transparently.

A similar issue is that numpy follows the linear algebra convention of indexing
with =(index_column, index_row)= and not the other way around. This runs against
the /other/ convention of referring to image dimensions as =(width, height)= and
referring to pixels as =(x,y)=. mrcal places the =x= coordinate first (as in the
latter) whenever possible, but when interacting directly with numpy, it must
place the =y= coordinate first. The choice being made is very clearly
documented, so when in doubt, do read the docs.

When computing gradients mrcal places the dependent variables in the leading
dimensions, and the independent variables in the trailing dimensions. So in the
above expressions we have $\frac{ \partial \vec b }{ \partial \vec a } = R$ and
row $i$ of $R$ represents the $\frac{ \partial b_i }{ \partial \vec a }$

** Implementation
The core of mrcal is written in C, but most of the API is currently available in
Python only. The python-wrapping is done via the [[https://github.com/dkogan/numpysane/blob/master/README-pywrap.org][=numpysane_pywrap=]] library,
which makes it fairly simple to make the Python interface /and/ provides
[[https://numpy.org/doc/stable/user/basics.broadcasting.html][broadcasting]] support.

The Python layer uses [[https://numpy.org/][numpy]] and [[https://github.com/dkogan/numpysane/][=numpysane=]] heavily. All the plotting is done
with [[https://github.com/dkogan/gnuplotlib][=gnuplotlib=]]. [[https://opencv.org/][OpenCV]] is used a bit, but /only/ in the Python layer (their C
APIs are gone, and the C++ APIs are unstable). Over time the dependence on this
library will decrease even further.

* Camera model file formats

Reading/writing camera models is done in Python with the [[file:mrcal-python-api-reference.html#cameramodel][=mrcal.cameramodel=]]
class. This class supports two different file formats:

- =.cameramodel=: the preferred format. This is a plain text representation of a
  Python =dict=. The pose is represented internally as =rt_fromref=: an =rt=
  transformation /from/ the reference coordinate system /to/ the coordinate
  system of this camera. That is the /internal/ representation: the class
  provides methods to get the transformation in any form.

- =.cahvor=: the alternative format available for compatibility with existing
  tools. If you don't need to interoperate with tools that require this format,
  there's little reason to use it. This format cannot store [[Splined stereographic lens model][splined models]] or
  the auxillary data required for the [[file:uncertainty.org][uncertainty computations]].

The [[file:mrcal-python-api-reference.html#cameramodel][=mrcal.cameramodel=]] class will intelligently pick the correct file format
based on the filename. The file format is just a way to store data: both the
CAHVOR and OpenCV lens models can be stored in either file format. The
[[file:mrcal-to-cahvor.html][=mrcal-to-cahvor=]] and [[file:mrcal-to-cameramodel.html][=mrcal-to-cameramodel=]] tools can be used to convert
between the two file formats.

The class (and its representation on disk) contains:

- The lens parameters
- The pose of the camera in space
- The =optimization_inputs=: the data used to compute the model initially. Used
  for the uncertainty computations

See the [[file:mrcal-python-api-reference.html#cameramodel][API documentation]] for usage details. A trivial example to

- read two models from disk
- recombine into a joint model that uses the lens parameters from one model with
  geometry from the other
- write to disk

#+begin_src python
model_for_intrinsics = mrcal.cameramodel('model0.cameramodel')
model_for_extrinsics = mrcal.cameramodel('model1.cameramodel')

model_joint = mrcal.cameramodel( model_for_intrinsics )

extrinsics = model_for_extrinsics.extrinsics_rt_fromref()
model_joint.extrinsics_rt_fromref(extrinsics)

model_joint.write('model-joint.cameramodel')
#+end_src

This is the basic operation of the [[file:mrcal-graft-models.html][=mrcal-graft-models= tool]].

Currently there's no support for reading/writing these files in the C API. I
will write it when I need it or when somebody bugs me about it, whichever comes
first.

* Lens models
#+NAME: Lens models
mrcal supports a wide range of lens models. The full set of supported models is
returned by the [[file:mrcal-python-api-reference.html#-supported_lensmodels][=mrcal.supported_models()=]] function. At the time of this writing
the supported models are:

- =LENSMODEL_PINHOLE=
- =LENSMODEL_STEREOGRAPHIC=
- =LENSMODEL_SPLINED_STEREOGRAPHIC_...=
- =LENSMODEL_OPENCV4=
- =LENSMODEL_OPENCV5=
- =LENSMODEL_OPENCV8=
- =LENSMODEL_OPENCV12=
- =LENSMODEL_CAHVOR=
- =LENSMODEL_CAHVORE=

In Python, the models are represented as one of the above strings. In C, in an
enum with =MRCAL_= prepended, and the =...= placeholder stripped. The =...=
above means that this model has /configuration parameters/ that would replace
the =...= placeholder. These are specific to each kind of model, and currently
only the [[Splined stereographic lens model][splined stereographic models]] have any configuration. The number of
parameters needed to fully describe a given model can be obtained by calling
[[file:mrcal-python-api-reference.html#-lensmodel_num_params][=mrcal.lensmodel_num_params()=]] in Python or [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h#mrcal_lensmodel_num_params][=mrcal_lensmodel_num_params()=]] in C.
Any configuration /must/ be included.

In C, the raw type of model is represented by the [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h#mrcal_lensmodel_type_t][=mrcal_lensmodel_type_t=]] enum.
The model type /and/ the configuration are represented by [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h##mrcal_lensmodel_t][=mrcal_lensmodel_t=]].

The pinhole and stereographic models are very simple, and are usually used as
part of data processing pipelines rather than trying to represent real-world
lenses. The splined stereographic model is [[Splined stereographic lens model][described in great detail later]]. This
is the recommended lens model to get the most fidelity and reliable
[[file:uncertainty.org][uncertainty estimates]].

The CAHVOR(E) and OpenCV lens models are supported by many other tools, so mrcal
also supporting them provides interoperability. These are much leaner than the
[[Splined stereographic lens model][splined models]], so they have many fewer parameters. Thus they need far less
computation, but they're not as good at representing arbitrary lenses, and they
provide overly-optimistic [[file:uncertainty.org][uncertainty estimates]].

CAHVORE is only partially supported: lensmodel parameter gradients aren't
implemented, so it isn't currently possible to solve for a CAHVORE model. Full
support may be added in the future.

* Calibration object
#+NAME: Calibration object
This is called a "chessboard" or just "board" in some parts of the code.

When running a camera calibration, we use observations of a known-geometry
object. Usually this object is a chessboard-like grid of black and white
squares, where the corners between squares are detected, and serve as the input
features to mrcal. mrcal is a purely geometrical toolkit, so this vision problem
must be handled by another library. I recommend [[https://github.com/dkogan/mrgingham/][=mrgingham=]], but any other
source of grid observations can be used.

The specific design of the calibration object is not important, as long as it
meets the current assumptions of the tool:

- flat (with a small amount of warping tolerated)
- contains a square grid of features

Chessboards are recommended, in contrast to grids of circles, which are strongly
discouraged. Precisely extracting the center of an observed circle from a tilted
observation that is also subjected to lens distortion is very difficult. And the
resulting inaccurate detections will introduce biases into the resulting
calibrations. Analysis [[file:tour.org::Optimal choreography][here]].

mrcal assumes independent noise on each point observation, so correlated sources
of points (such as corners of an apriltag) are not appropriate sources of data
currently.

* Commandline tools
#+NAME: Commandline tools
A number of commandline tools are available for common tasks. If you're just
using mrcal to calibrate some cameras, you may not need anything else.

- [[file:mrcal-calibrate-cameras.html][=mrcal-calibrate-cameras=]]: calibrate N cameras. This is the main tool to solve
  "calibration" problems.
- [[file:mrcal-show-projection-diff.html][=mrcal-show-projection-diff=]]: visualize the projection difference between a
  number of models
- [[file:mrcal-show-projection-uncertainty.html][=mrcal-show-projection-uncertainty=]]: visualize the projection uncertainty of a
  model
- [[file:mrcal-show-valid-intrinsics-region.html][=mrcal-show-valid-intrinsics-region=]]: Visualizes the region where a model's
  intrinsics are valid
- [[file:mrcal-is-within-valid-intrinsics-region.html][=mrcal-is-within-valid-intrinsics-region=]]: Augments a vnlog of pixel
  coordinates with a column indicating whether or not each point lies within
  the valid-intrinsics region
- [[file:mrcal-convert-lensmodel.html][=mrcal-convert-lensmodel=]]: Fits the behavior of one lens model to another
- [[file:mrcal-show-geometry.html][=mrcal-show-geometry=]]: Shows a visual representation of the geometry
  represented by some camera models on disk, and optionally, the
  chessboard observations used to compute that geometry
- [[file:mrcal-show-distortion-off-pinhole.html][=mrcal-show-distortion-off-pinhole=]]: visualize the deviation of a specific
  lens model from a pinhole model
- [[file:mrcal-show-splined-model-surface.html][=mrcal-show-splined-model-surface=]]: visualize the surface and knots used in
  the specification of splined models
- [[file:mrcal-reproject-image.html][=mrcal-reproject-image=]]: Given image(s) and lens model(s), produces a new set
  of images that observe the same scene with a different model. Several flavors
  of functionality are included here, such as undistortion-to-pinhole,
  re-rotation, and remapping to infinity.
- [[file:mrcal-reproject-points.html][=mrcal-reproject-points=]]: Given two lens models and a set of pixel coodinates,
  maps them from one lens model to the other
- [[file:mrcal-graft-models.html][=mrcal-graft-models=]]: Combines the intrinsics of one cameramodel with the
  extrinsics of another
- [[file:mrcal-to-cahvor.html][=mrcal-to-cahvor=]]: Converts a model stored in the native =.cameramodel= file
  format to the =.cahvor= format. This exists for compatibility only, and does
  not touch the data: any lens model may be used
- [[file:mrcal-to-cameramodel.html][=mrcal-to-cameramodel=]]: Converts a model stored in the =.cahvor= file format
  to the =.cameramodel= format. This exists for compatibility only, and does not
  touch the data: any lens model may be used
- [[file:mrcal-cull-corners.html][=mrcal-cull-corners=]]: Filters a corners.vnl on stdin to cut out some points

* Developer manual (APIs)
The mrcal toolkit has APIs in both C and Python. Everything that could
potentially be slow is written in C, but the higher-level logic is mostly in
Python. The Python-wrapping is done via the [[https://github.com/dkogan/numpysane/blob/master/README-pywrap.org][=numpysane_pywrap=]] library, which
makes it fairly simple to build the Python interfaces in a standard way, so over
time Python-only functionality will be translated to C, as needed (with
backwards-compatible Python wrappers replacing the Python implementations).

** C API
#+NAME: C API
The C API consists of 3 headers:
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/basic_geometry.h][=basic_geometry.h=]]: /very/ simple geometry structures
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/poseutils.h][=poseutils.h=]]: pose and geometry functions
- [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal.h=]]: lens models, projections, optimization

Many usages would =#include <mrcal.h>= only, and this includes all 3.

*** Geometry structures
We have 3 structures in [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/basic_geometry.h][=basic_geometry.h=]]:

- =mrcal_point2_t=: a vector containing 2 double-precision floating-point
  values. The elements can be accessed individually as =.x= and =.y= or as an
  array =.xy[]=

- =mrcal_point3_t=: exactly like =mrcal_point2_t=, but 3-dimensional. A vector
  containing 3 double-precision floating-point values. The elements can be
  accessed individually as =.x= and =.y= and =.z= or as an array =.xyz[]=

- =mrcal_pose_t=: an unconstrained 6-DOF pose. Contains two sub-structures:
  - =mrcal_point3_t r=: a [[https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation#Rotation_vector][Rodrigues rotation]]
  - =mrcal_point3_t t=: a translation

*** Geometry functions
A number of utility functions are defined in [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/poseutils.h][=poseutils.h=]]. Each routine has two
forms:

- A =mrcal_..._noncontiguous()= function that supports a non-contiguous memory
  layout for each input and output
- A convenience =mrcal_...()= macro that wraps =mrcal_..._noncontiguous()=, and
  expects contiguous data. This has many fewer arguments, and is easier to call

Each data argument (input or output) has several items in the argument list:

- =double* xxx=: a pointer to the first element
- =int xxx_stride0=, =int xxx_stride1=, ...: the strides, one per dimension

The strides are given in bytes, and work as expected. For a (for instance)
3-dimensional =xxx=, the element at =xxx[i,j,k]= would lie at

#+begin_src c
*(double*) &((char*)xxx)[ i*xxx_stride0 +
                          j*xxx_stride1 +
                          k*xxx_stride2 ]
#+end_src

These all have fairly direct Python bindings. For instance [[file:mrcal-python-api-reference.html#-rt_from_Rt][=mrcal.rt_from_Rt()=]].

The listing of available functions is best given with the commented header:

#+begin_src c
// Store an identity rotation matrix into the given (3,3) array
//
// This is simply an identity matrix
#define mrcal_identity_R(R) mrcal_identity_R_noncontiguous(R,0,0)
void mrcal_identity_R_noncontiguous(double* R,      // (3,3) array
                                    int R_stride0,  // in bytes. <= 0 means "contiguous"
                                    int R_stride1   // in bytes. <= 0 means "contiguous"
                                    );

// Store an identity rodrigues rotation into the given (3,) array
//
// This is simply an array of zeros
#define mrcal_identity_r(r) mrcal_identity_r_noncontiguous(r,0)
void mrcal_identity_r_noncontiguous(double* r,      // (3,) array
                                    int r_stride0   // in bytes. <= 0 means "contiguous"
                                    );

// Store an identity Rt transformation into the given (4,3) array
#define mrcal_identity_Rt(Rt) mrcal_identity_Rt_noncontiguous(Rt,0,0)
void mrcal_identity_Rt_noncontiguous(double* Rt,      // (4,3) array
                                     int Rt_stride0,  // in bytes. <= 0 means "contiguous"
                                     int Rt_stride1   // in bytes. <= 0 means "contiguous"
                                     );

// Store an identity rt transformation into the given (6,) array
#define mrcal_identity_rt(rt)  mrcal_identity_rt_noncontiguous(rt,0)
void mrcal_identity_rt_noncontiguous(double* rt,      // (6,) array
                                     int rt_stride0   // in bytes. <= 0 means "contiguous"
                                     );

// Rotate the point x_in in a (3,) array by the rotation matrix R in a (3,3)
// array. This is simply the matrix-vector multiplication R x_in
//
// The result is returned in a (3,) array x_out.
//
// The gradient dx_out/dR is returned in a (3, 3,3) array J_R. Set to NULL if
// this is not wanted
//
// The gradient dx_out/dx_in is returned in a (3,3) array J_x. This is simply
// the matrix R. Set to NULL if this is not wanted
#define mrcal_rotate_point_R(x_out,J_R,J_x,R,x_in) mrcal_rotate_point_R_noncontiguous(x_out,0,J_R,0,0,0,J_x,0,0,R,0,0,x_in,0)
void mrcal_rotate_point_R_noncontiguous( // output
                                        double* x_out,      // (3,) array
                                        int x_out_stride0,  // in bytes. <= 0 means "contiguous"
                                        double* J_R,        // (3,3,3) array. May be NULL
                                        int J_R_stride0,    // in bytes. <= 0 means "contiguous"
                                        int J_R_stride1,    // in bytes. <= 0 means "contiguous"
                                        int J_R_stride2,    // in bytes. <= 0 means "contiguous"
                                        double* J_x,        // (3,3) array. May be NULL
                                        int J_x_stride0,    // in bytes. <= 0 means "contiguous"
                                        int J_x_stride1,    // in bytes. <= 0 means "contiguous"

                                        // input
                                        const double* R,    // (3,3) array. May be NULL
                                        int R_stride0,      // in bytes. <= 0 means "contiguous"
                                        int R_stride1,      // in bytes. <= 0 means "contiguous"
                                        const double* x_in, // (3,) array. May be NULL
                                        int x_in_stride0    // in bytes. <= 0 means "contiguous"
                                        );

// Rotate the point x_in in a (3,) array by the rodrigues rotation in a (3,)
// array.
//
// The result is returned in a (3,) array x_out.
//
// The gradient dx_out/dr is returned in a (3,3) array J_r. Set to NULL if this
// is not wanted
//
// The gradient dx_out/dx_in is returned in a (3,3) array J_x. Set to NULL if
// this is not wanted
#define mrcal_rotate_point_r(x_out,J_r,J_x,r,x_in) mrcal_rotate_point_r_noncontiguous(x_out,0,J_r,0,0,J_x,0,0,r,0,x_in,0)
void mrcal_rotate_point_r_noncontiguous( // output
                                        double* x_out,      // (3,) array
                                        int x_out_stride0,  // in bytes. <= 0 means "contiguous"
                                        double* J_r,        // (3,3) array. May be NULL
                                        int J_r_stride0,    // in bytes. <= 0 means "contiguous"
                                        int J_r_stride1,    // in bytes. <= 0 means "contiguous"
                                        double* J_x,        // (3,3) array. May be NULL
                                        int J_x_stride0,    // in bytes. <= 0 means "contiguous"
                                        int J_x_stride1,    // in bytes. <= 0 means "contiguous"

                                        // input
                                        const double* r,    // (3,) array. May be NULL
                                        int r_stride0,      // in bytes. <= 0 means "contiguous"
                                        const double* x_in, // (3,) array. May be NULL
                                        int x_in_stride0    // in bytes. <= 0 means "contiguous"
                                        );

// Transform the point x_in in a (3,) array by the Rt transformation in a (4,3)
// array.
//
// The result is returned in a (3,) array x_out.
//
// The gradient dx_out/dRt is returned in a (3, 4,3) array J_Rt. Set to NULL if
// this is not wanted
//
// The gradient dx_out/dx_in is returned in a (3,3) array J_x. This is simply
// the matrix R. Set to NULL if this is not wanted
#define mrcal_transform_point_Rt(x_out,J_Rt,J_x,Rt,x_in) mrcal_transform_point_Rt_noncontiguous(x_out,0,J_Rt,0,0,0,J_x,0,0,Rt,0,0,x_in,0)
void mrcal_transform_point_Rt_noncontiguous( // output
                                            double* x_out,      // (3,) array
                                            int x_out_stride0,  // in bytes. <= 0 means "contiguous"
                                            double* J_Rt,       // (3,4,3) array. May be NULL
                                            int J_Rt_stride0,   // in bytes. <= 0 means "contiguous"
                                            int J_Rt_stride1,   // in bytes. <= 0 means "contiguous"
                                            int J_Rt_stride2,   // in bytes. <= 0 means "contiguous"
                                            double* J_x,        // (3,3) array. May be NULL
                                            int J_x_stride0,    // in bytes. <= 0 means "contiguous"
                                            int J_x_stride1,    // in bytes. <= 0 means "contiguous"

                                            // input
                                            const double* Rt,   // (4,3) array. May be NULL
                                            int Rt_stride0,     // in bytes. <= 0 means "contiguous"
                                            int Rt_stride1,     // in bytes. <= 0 means "contiguous"
                                            const double* x_in, // (3,) array. May be NULL
                                            int x_in_stride0    // in bytes. <= 0 means "contiguous"
                                            );

// Transform the point x_in in a (3,) array by the rt transformation in a (6,)
// array.
//
// The result is returned in a (3,) array x_out.
//
// The gradient dx_out/drt is returned in a (3,6) array J_rt. Set to NULL if
// this is not wanted
//
// The gradient dx_out/dx_in is returned in a (3,3) array J_x. This is simply
// the matrix R. Set to NULL if this is not wanted
#define mrcal_transform_point_rt(x_out,J_rt,J_x,rt,x_in) mrcal_transform_point_rt_noncontiguous(x_out,0,J_rt,0,0,J_x,0,0,rt,0,x_in,0)
void mrcal_transform_point_rt_noncontiguous( // output
                                            double* x_out,      // (3,) array
                                            int x_out_stride0,  // in bytes. <= 0 means "contiguous"
                                            double* J_rt,       // (3,6) array. May be NULL
                                            int J_rt_stride0,   // in bytes. <= 0 means "contiguous"
                                            int J_rt_stride1,   // in bytes. <= 0 means "contiguous"
                                            double* J_x,        // (3,3) array. May be NULL
                                            int J_x_stride0,    // in bytes. <= 0 means "contiguous"
                                            int J_x_stride1,    // in bytes. <= 0 means "contiguous"

                                            // input
                                            const double* rt,   // (6,) array. May be NULL
                                            int rt_stride0,     // in bytes. <= 0 means "contiguous"
                                            const double* x_in, // (3,) array. May be NULL
                                            int x_in_stride0    // in bytes. <= 0 means "contiguous"
                                            );

// Convert a rotation matrix in a (3,3) array to a rodrigues vector in a (3,)
// array
//
// The result is returned in a (3,) array r
//
// The gradient dr/dR is returned in a (3, 3,3) array J. Set to NULL if this is
// not wanted
#define mrcal_r_from_R(r,J,R) mrcal_r_from_R_noncontiguous(r,0,J,0,0,0,R,0,0)
void mrcal_r_from_R_noncontiguous( // output
                                  double* r,       // (3,) vector
                                  int r_stride0,   // in bytes. <= 0 means "contiguous"
                                  double* J,       // (3,3,3) array. Gradient. May be NULL
                                  int J_stride0,   // in bytes. <= 0 means "contiguous"
                                  int J_stride1,   // in bytes. <= 0 means "contiguous"
                                  int J_stride2,   // in bytes. <= 0 means "contiguous"

                                  // input
                                  const double* R, // (3,3) array
                                  int R_stride0,   // in bytes. <= 0 means "contiguous"
                                  int R_stride1    // in bytes. <= 0 means "contiguous"
                                  );

// Convert a rodrigues vector in a (3,) array to a rotation matrix in a (3,3)
// array
//
// The result is returned in a (3,3) array R
//
// The gradient dR/dr is returned in a (3,3 ,3) array J. Set to NULL if this is
// not wanted
#define mrcal_R_from_r(R,J,r) mrcal_R_from_r_noncontiguous(R,0,0,J,0,0,0,r,0)
void mrcal_R_from_r_noncontiguous( // outputs
                                  double* R,       // (3,3) array
                                  int R_stride0,   // in bytes. <= 0 means "contiguous"
                                  int R_stride1,   // in bytes. <= 0 means "contiguous"
                                  double* J,       // (3,3,3) array. Gradient. May be NULL
                                  int J_stride0,   // in bytes. <= 0 means "contiguous"
                                  int J_stride1,   // in bytes. <= 0 means "contiguous"
                                  int J_stride2,   // in bytes. <= 0 means "contiguous"

                                  // input
                                  const double* r, // (3,) vector
                                  int r_stride0    // in bytes. <= 0 means "contiguous"
                                   );

// Convert an Rt transformation in a (4,3) array to an rt transformation in a
// (6,) array
//
// The result is returned in a (6,) array rt
//
// The gradient dr/dR is returned in a (3, 3,3) array J_R. Set to NULL if this
// is not wanted
//
// The t terms are identical, so dt/dt = identity and I do not return it
//
// The r and R terms are independent of the t terms, so dr/dt and dt/dR are both
// 0, and I do not return them
#define mrcal_rt_from_Rt(rt,Rt) mrcal_rt_from_Rt_noncontiguous(rt,0,NULL,0,0,0,Rt,0,0)
void mrcal_rt_from_Rt_noncontiguous(   // output
                                    double* rt,      // (6,) vector
                                    int rt_stride0,  // in bytes. <= 0 means "contiguous"
                                    double* J_R,     // (3,3,3) array. Gradient. May be NULL
                                    // No J_t. It's always the identity
                                    int J_R_stride0, // in bytes. <= 0 means "contiguous"
                                    int J_R_stride1, // in bytes. <= 0 means "contiguous"
                                    int J_R_stride2, // in bytes. <= 0 means "contiguous"

                                    // input
                                    const double* Rt,  // (4,3) array
                                    int Rt_stride0,    // in bytes. <= 0 means "contiguous"
                                    int Rt_stride1     // in bytes. <= 0 means "contiguous"
                                    );

// Convert an rt transformation in a (6,) array to an Rt transformation in a
// (4,3) array
//
// The result is returned in a (4,3) array Rt
//
// The gradient dR/dr is returned in a (3,3 ,3) array J_r. Set to NULL if this
// is not wanted
//
// The t terms are identical, so dt/dt = identity and I do not return it
//
// The r and R terms are independent of the t terms, so dR/dt and dt/dr are both
// 0, and I do not return them
#define mrcal_Rt_from_rt(Rt,rt) mrcal_Rt_from_rt_noncontiguous(Rt,0,0,NULL,0,0,0,rt,0)
void mrcal_Rt_from_rt_noncontiguous(   // output
                                    double* Rt,      // (4,3) array
                                    int Rt_stride0,  // in bytes. <= 0 means "contiguous"
                                    int Rt_stride1,  // in bytes. <= 0 means "contiguous"
                                    double* J_r,     // (3,3,3) array. Gradient. May be NULL
                                    // No J_t. It's just the identity
                                    int J_r_stride0, // in bytes. <= 0 means "contiguous"
                                    int J_r_stride1, // in bytes. <= 0 means "contiguous"
                                    int J_r_stride2, // in bytes. <= 0 means "contiguous"

                                    // input
                                    const double* rt, // (6,) vector
                                    int rt_stride0    // in bytes. <= 0 means "contiguous"
                                    );

// Invert an Rt transformation
//
// The input is given in Rt_in in a (4,3) array
//
// The result is returned in a (4,3) array Rt_out
#define mrcal_invert_Rt(Rt_out,Rt_in) mrcal_invert_Rt_noncontiguous(Rt_out,0,0,Rt_in,0,0)
void mrcal_invert_Rt_noncontiguous( // output
                                   double* Rt_out,      // (4,3) array
                                   int Rt_out_stride0,  // in bytes. <= 0 means "contiguous"
                                   int Rt_out_stride1,  // in bytes. <= 0 means "contiguous"

                                   // input
                                   const double* Rt_in, // (4,3) array
                                   int Rt_in_stride0,   // in bytes. <= 0 means "contiguous"
                                   int Rt_in_stride1    // in bytes. <= 0 means "contiguous"
                                   );

// Invert an rt transformation
//
// The input is given in rt_in in a (6,) array
//
// The result is returned in a (6,) array rt_out
//
// The gradient dtout/drin is returned in a (3,3) array dtout_drin. Set to NULL
// if this is not wanted
//
// The gradient dtout/dtin is returned in a (3,3) array dtout_dtin. Set to NULL
// if this is not wanted
//
// The gradient drout/drin is always -identity. So it is not returned
//
// The gradient drout/dtin is always 0. So it is not returned
#define mrcal_invert_rt(rt_out,dtout_drin,dtout_dtin,rt_in) mrcal_invert_rt_noncontiguous(rt_out,0,dtout_drin,0,0,dtout_dtin,0,0,rt_in,0)
void mrcal_invert_rt_noncontiguous( // output
                                   double* rt_out,          // (6,) array
                                   int rt_out_stride0,      // in bytes. <= 0 means "contiguous"
                                   double* dtout_drin,      // (3,3) array
                                   int dtout_drin_stride0,  // in bytes. <= 0 means "contiguous"
                                   int dtout_drin_stride1,  // in bytes. <= 0 means "contiguous"
                                   double* dtout_dtin,      // (3,3) array
                                   int dtout_dtin_stride0,  // in bytes. <= 0 means "contiguous"
                                   int dtout_dtin_stride1,  // in bytes. <= 0 means "contiguous"

                                   // input
                                   const double* rt_in,     // (6,) array
                                   int rt_in_stride0        // in bytes. <= 0 means "contiguous"
                                   );

// Compose two Rt transformations
//
// Rt = Rt0 * Rt1  --->  Rt(x) = Rt0( Rt1(x) )
//
// The input transformations are given in (4,3) arrays Rt_0 and Rt_1
//
// The result is returned in a (4,3) array Rt_out
#define mrcal_compose_Rt(Rt_out,Rt_0,Rt_1) mrcal_compose_Rt_noncontiguous(Rt_out,0,0,Rt_0,0,0,Rt_1,0,0)
void mrcal_compose_Rt_noncontiguous( // output
                                    double* Rt_out,      // (4,3) array
                                    int Rt_out_stride0,  // in bytes. <= 0 means "contiguous"
                                    int Rt_out_stride1,  // in bytes. <= 0 means "contiguous"

                                    // input
                                    const double* Rt_0,  // (4,3) array
                                    int Rt_0_stride0,    // in bytes. <= 0 means "contiguous"
                                    int Rt_0_stride1,    // in bytes. <= 0 means "contiguous"
                                    const double* Rt_1,  // (4,3) array
                                    int Rt_1_stride0,    // in bytes. <= 0 means "contiguous"
                                    int Rt_1_stride1     // in bytes. <= 0 means "contiguous"
                                    );

// Compose two rt transformations
//
// rt = rt0 * rt1  --->  rt(x) = rt0( rt1(x) )
//
// The input transformations are given in (6,) arrays rt_0 and rt_1
//
// The result is returned in a (6,) array rt_out
//
// The gradient dr/dr0 is returned in a (3,3) array dr_dr0. Set to NULL if this
// is not wanted
//
// The gradient dr/dr1 is returned in a (3,3) array dr_dr1. Set to NULL if this
// is not wanted
//
// The gradient dt/dr0 is returned in a (3,3) array dt_dr0. Set to NULL if this
// is not wanted
//
// The gradient dt/dt1 is returned in a (3,3) array dt_dt1. Set to NULL if this
// is not wanted
//
// The gradients dr/dt0, dr/dt1, dt/dr1 are always 0, so they are never returned
//
// The gradient dt/dt0 is always identity, so it is never returned
#define mrcal_compose_rt(rt_out,dr_dr0,dr_dr1,dt_dr0,dt_dt1,rt_0,rt_1) mrcal_compose_rt_noncontiguous(rt_out,0,dr_dr0,0,0,dr_dr1,0,0,dt_dr0,0,0,dt_dt1,0,0,rt_0,0,rt_1,0)
void mrcal_compose_rt_noncontiguous( // output
                                    double* rt_out,       // (6,) array
                                    int rt_out_stride0,   // in bytes. <= 0 means "contiguous"
                                    double* dr_dr0,       // (3,3) array; may be NULL
                                    int dr_dr0_stride0,   // in bytes. <= 0 means "contiguous"
                                    int dr_dr0_stride1,   // in bytes. <= 0 means "contiguous"
                                    double* dr_dr1,       // (3,3) array; may be NULL
                                    int dr_dr1_stride0,   // in bytes. <= 0 means "contiguous"
                                    int dr_dr1_stride1,   // in bytes. <= 0 means "contiguous"
                                    double* dt_dr0,       // (3,3) array; may be NULL
                                    int dt_dr0_stride0,   // in bytes. <= 0 means "contiguous"
                                    int dt_dr0_stride1,   // in bytes. <= 0 means "contiguous"
                                    double* dt_dt1,       // (3,3) array; may be NULL
                                    int dt_dt1_stride0,   // in bytes. <= 0 means "contiguous"
                                    int dt_dt1_stride1,   // in bytes. <= 0 means "contiguous"

                                    // input
                                    const double* rt_0,   // (6,) array
                                    int rt_0_stride0,     // in bytes. <= 0 means "contiguous"
                                    const double* rt_1,   // (6,) array
                                    int rt_1_stride0      // in bytes. <= 0 means "contiguous"
                                    );
#+end_src

*** Everything else
The bulk of the C API lives in [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal.h=]]. [[https://en.wikipedia.org/wiki/X_Macro][X macros]] are used in several places.
These are a technique for templating using the C preprocessor that eliminates
boilerplate.

Functions, broken down by functionality:

**** Lens models
The lens model structures are defined here:

- =mrcal_lensmodel_type_t=: an enum decribing the lens model /type/. No [[Lens
   models][configuration]] is stored here.
- =mrcal_lensmodel_t=: a lens model type /and/ the [[Lens models][configuration]] parameters. The
  configuration lives in a =union= supporting all the known lens models
- =mrcal_lensmodel_metadata_t=: the metadata that describes any given lens model

The Python API describes a lens model with a string that contains the model type
and the configuration, and much of the functionality here is used to convert
between these strings and the =mrcal_lensmodel_t= structures, to manage
parameter counts, and so on. The listing of available functions is best given
with the commented header (with the extraneous bits removed, and the x-macros
expanded):

#+begin_src c
// parametric models have no extra configuration
typedef struct {} mrcal_LENSMODEL_PINHOLE__config_t;
typedef struct {} mrcal_LENSMODEL_OPENCV4__config_t;
// ... and the same for all the other configuration-less models

// Configuration for the splined stereographic models. Generated by an x-macro
typedef struct
{
    /* Maximum degree of each 1D polynomial. This is almost certainly 2 */
    /* (quadratic splines, C1 continuous) or 3 (cubic splines, C2 continuous) */
    uint16_t order;
    /* We have a Nx by Ny grid of control points */
    uint16_t Nx;
    uint16_t Ny;
    /* The horizontal field of view. Not including fov_y. It's proportional with */
    /* Ny and Nx */
    uint16_t fov_x_deg;
} mrcal_LENSMODEL_SPLINED_STEREOGRAPHIC__config_t;


// This lensmodel type selects the lens model, but does NOT provide the
// configuration. mrcal_lensmodel_t does that.
typedef enum
{ MRCAL_LENSMODEL_INVALID           = -2,
  MRCAL_LENSMODEL_INVALID_BADCONFIG = -1,
  // The rest, starting with 0

  // Generated by an x-macro
  // ...,
  MRCAL_LENSMODEL_PINHOLE,
  // ...,
  MRCAL_LENSMODEL_OPENCV4,
  // ...,
  MRCAL_LENSMODEL_SPLINED_STEREOGRAPHIC,
  // ... and so on for the other models
} mrcal_lensmodel_type_t;


// Defines a lens model: the type AND the configuration values
typedef struct
{
    // The type of lensmodel. This is an enum, selecting elements of
    // MRCAL_LENSMODEL_LIST (with "MRCAL_" prepended)
    mrcal_lensmodel_type_t type;

    // A union of all the possible configuration structures. We pick the
    // structure type based on the value of "type
    union
    {
        // Generated by an x-macro
        mrcal_LENSMODEL_PINHOLE__config_t               LENSMODEL_PINHOLE__config;
        mrcal_LENSMODEL_OPENCV4__config_t               LENSMODEL_OPENCV4__config;
        mrcal_LENSMODEL_SPLINED_STEREOGRAPHIC__config_t LENSMODEL_SPLINED_STEREOGRAPHIC__config;
        // ... and so on for the other models
    };
} mrcal_lensmodel_t;


// Return an array of strings listing all the available lens models
//
// These are all "unconfigured" strings that use "..." placeholders for any
// configuration values. Each return string is a \0-terminated const char*. The
// end of the list is signified by a NULL string
const char* const* mrcal_supported_lensmodel_names( void ); // NULL-terminated array of char* strings


// Return true if the given mrcal_lensmodel_type_t specifies a valid lens model
bool mrcal_lensmodel_type_is_valid(mrcal_lensmodel_type_t t);


// Return a string describing a lens model.
//
// This function returns a static string. For models with no configuration, this
// is the FULL string for that model. For models with a configuration, the
// configuration values have "..." placeholders. These placeholders mean that
// the resulting strings do not define a lens model fully, and cannot be
// converted to a mrcal_lensmodel_t with mrcal_lensmodel_from_name()
//
// This is the inverse of mrcal_lensmodel_type_from_name()
const char* mrcal_lensmodel_name_unconfigured( mrcal_lensmodel_t model );


// Return a CONFIGURED string describing a lens model.
//
// This function generates a fully-configured string describing the given lens
// model. For models with no configuration, this is just the static string
// returned by mrcal_lensmodel_name_unconfigured(). For models that have a
// configuration, however, the configuration values are filled-in. The resulting
// string may be converted back into a mrcal_lensmodel_t by calling
// mrcal_lensmodel_from_name().
//
// This function writes the string into the given buffer "out". The size of the
// buffer is passed in the "size" argument. The meaning of "size" is as with
// snprintf(), which is used internally. Returns true on success
//
// This is the inverse of mrcal_lensmodel_from_name()
bool mrcal_lensmodel_name( char* out, int size, mrcal_lensmodel_t model );


// Parse the lens model type from a lens model name string
//
// The configuration is ignored. Thus this function works even if the
// configuration is missing or unparseable. Unknown model names return
// MRCAL_LENSMODEL_INVALID
//
// This is the inverse of mrcal_lensmodel_name_unconfigured()
mrcal_lensmodel_type_t mrcal_lensmodel_type_from_name( const char* name );


// Parse the full configured lens model from a lens model name string
//
// The lens mode type AND the configuration are read into a mrcal_lensmodel_t
// structure, which this function returns. Strings with valid model names but
// missing or unparseable configuration return
//
//   {.type = MRCAL_LENSMODEL_INVALID_BADCONFIG}.
//
// Any other errors result in some other invalid lensmodel.type values, which
// can be checked with mrcal_lensmodel_type_is_valid(lensmodel->type)
//
// This is the inverse of mrcal_lensmodel_name()
mrcal_lensmodel_t mrcal_lensmodel_from_name( const char* name );


// Each lens model type has some metadata that describes its inherent
// properties. These properties can be queried by calling
// mrcal_lensmodel_metadata().
typedef struct
{
    // generated by an x-macro

    /* If true, this model contains an "intrinsics core". This is described */
    /* in mrcal_intrinsics_core_t. If present, the 4 core parameters ALWAYS */
    /* appear at the start of a model's parameter vector                    */
    bool has_core :1;


    /* Whether a model is able to project points behind the camera          */
    /* (z<0 in the camera coordinate system). Models based on a pinhole     */
    /* projection (pinhole, OpenCV, CAHVOR(E)) cannot do this. models based */
    /* on a stereographic projection (stereographic, splined stereographic) */
    /* can                                                                  */
    bool can_project_behind_camera :1;
} mrcal_lensmodel_metadata_t;


// Return a structure containing a model's metadata
//
// The available metadata is described in the definition of the
// MRCAL_LENSMODEL_META_LIST() macro
mrcal_lensmodel_metadata_t mrcal_lensmodel_metadata( const mrcal_lensmodel_t m );


// Return the number of parameters required to specify a given lens model
//
// For models that have a configuration, the parameter count value generally
// depends on the configuration. For instance, splined models use the model
// parameters as the spline control points, so the spline density (specified in
// the configuration) directly affects how many parameters such a model requires
int mrcal_lensmodel_num_params( const mrcal_lensmodel_t m );


// Return the locations of x and y spline knots

// Splined models are defined by the locations of their control points. These
// are arranged in a grid, the size and density of which is set by the model
// configuration. We fill-in the x knot locations into ux[] and the y locations
// into uy[]. ux[] and uy[] must be large-enough to hold configuration->Nx and
// configuration->Ny values respectively.
//
// This function applies to splined models only. Returns true on success
bool mrcal_knots_for_splined_models( double* ux, double* uy,
                                     mrcal_lensmodel_t lensmodel);
#+end_src

**** Projections
The fundamental functions for projection and unprojection are defined here.
=mrcal_project()= is the main routine that implements the "forward" direction,
and is available for every camera model. This function can return gradients in
respect to the coordinates of the point being project and/or in respect to the
intrinsics vector.

=mrcal_unproject()= is the reverse direction, and is implemented as a numerical
optimization to reverse the projection operation. Naturally, this is much slower
than =mrcal_project()=, and has no gradient reporting. Models that have no
gradients implemented (CAHVORE only, as of this writing) do not support
=mrcal_unproject()=. They /may/ have a Python [[file:mrcal-python-api-reference.html#-unproject][=mrcal.unproject()=]] implementation
available that uses a slower optimization routine that uses numerical
differences instead of analytical gradients.

=mrcal_project_stereographic()= and =mrcal_unproject_stereographic()= are
available as special-case routines. These are uses in analysis and not to
represent any actual lenses.

The listing of available functions is best given with the commented header:

#+begin_src c
// Project the given camera-coordinate-system points
//
// Compute a "projection", a mapping of points defined in the camera coordinate
// system to their observed pixel coordinates. If requested, gradients are
// computed as well.
//
// We project N 3D points p to N 2D pixel coordinates q using the given
// lensmodel and intrinsics parameter values.
//
// if (dq_dp != NULL) we report the gradient dq/dp in a dense (N,2,3) array
// ((N,2) mrcal_point3_t objects).
//
// if (dq_dintrinsics != NULL) we report the gradient dq/dintrinsics in a dense
// (N,2,Nintrinsics) array. Note that splined models have very high Nintrinsics
// and very sparse gradients. THIS function reports the gradients densely,
// however, so it is inefficient for splined models.
//
// This function supports CAHVORE distortions only if we don't ask for any
// gradients
//
// Projecting out-of-bounds points (beyond the field of view) returns undefined
// values. Generally things remain continuous even as we move off the imager
// domain. Pinhole-like projections will work normally if projecting a point
// behind the camera. Splined projections clamp to the nearest spline segment:
// the projection will fly off to infinity quickly since we're extrapolating a
// polynomial, but the function will remain continuous.
bool mrcal_project( // out
                   mrcal_point2_t* q,
                   mrcal_point3_t* dq_dp,
                   double*         dq_dintrinsics,

                   // in
                   const mrcal_point3_t* p,
                   int N,
                   mrcal_lensmodel_t lensmodel,
                   // core, distortions concatenated
                   const double* intrinsics);


// Unproject the given pixel coordinates
//
// Compute an "unprojection", a mapping of pixel coordinates to the camera
// coordinate system.
//
// We unproject N 2D pixel coordinates q to N 3D direction vectors v using the
// given lensmodel and intrinsics parameter values. The returned vectors v are
// not normalized, and may have any length.

// This is the "reverse" direction, so an iterative nonlinear optimization is
// performed internally to compute this result. This is much slower than
// mrcal_project(). For OpenCV models specifically, OpenCV has
// cvUndistortPoints() (and cv2.undistortPoints()), but these are unreliable:
// https://github.com/opencv/opencv/issues/8811
//
// This function does NOT support CAHVORE
bool mrcal_unproject( // out
                     mrcal_point3_t* v,

                     // in
                     const mrcal_point2_t* q,
                     int N,
                     mrcal_lensmodel_t lensmodel,
                     // core, distortions concatenated
                     const double* intrinsics);


// Project the given camera-coordinate-system points using a stereographic model
//
// Compute a "projection", a mapping of points defined in the camera coordinate
// system to their observed pixel coordinates. If requested, gradients are
// computed as well.
//
// We project N 3D points p to N 2D pixel coordinates q using the stereographic
// model with the given intrinsics core.
//
// if (dq_dp != NULL) we report the gradient dq/dp in a dense (N,2,3) array
// ((N,2) mrcal_point3_t objects).
//
// This is a special case of mrcal_project(). Useful as part of data analysis,
// not to represent any real-world lens
void mrcal_project_stereographic( // output
                                 mrcal_point2_t* q,
                                 mrcal_point3_t* dq_dp,

                                  // input
                                 const mrcal_point3_t* p,
                                 int N,
                                 double fx, double fy,
                                 double cx, double cy);


// Unproject the given pixel coordinates using a stereographic model
//
// Compute an "unprojection", a mapping pixel coordinates to the camera
// coordinate system.
//
// We project N 2D pixel coordinates q to N 3D direction vectors v using the
// stereographic model with the given intrinsics core. The returned vectors v
// are not normalized, and may have any length.
//
// if (dv_dq != NULL) we report the gradient dv/dq in a dense (N,3,2) array
// ((N,3) mrcal_point2_t objects).
//
// This is a special case of mrcal_unproject(). Useful as part of data analysis,
// not to represent any real-world lens
void mrcal_unproject_stereographic( // output
                                   mrcal_point3_t* v,
                                   mrcal_point2_t* dv_dq,

                                   // input
                                   const mrcal_point2_t* q,
                                   int N,
                                   double fx, double fy,
                                   double cx, double cy);
#+end_src

**** Optimization
The mrcal optimization routines are defined in [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal.h=]]. Primarily these exist
for the benefit of the Python layer, and it isn't expected that end users will
call these routines. A brief description is given here for completeness.

The details of the optimization being solved are defined in the
=mrcal_problem_details_t= structure. This defines

- Which elements of the optimization vector are locked-down, and which are given
  to the optimizer to adjust. Currently we can lock down the intrinsics, the
  extrinsics and/or the frames (chessboard poses)
- Whether we apply [[Regularization][regularization]] to stabilize the solution
- Whether the chessboard should be assumed flat, or if we should optimize
  deformation factors

Any function that needs the layout of the optimization vector takes a
=mrcal_problem_details_t=.

The listing of available functions is best given with the commented header:


#+begin_src c
// Used to specify which camera is making an observation. The "intrinsics" index
// is used to identify a specific camera, while the "extrinsics" index is used
// to locate a camera in space. If I have a camera that is moving over time, the
// intrinsics index will remain the same, while the extrinsics index will change
typedef struct
{
    // indexes the intrinsics array
    int  intrinsics;
    // indexes the extrinsics array. -1 means "at coordinate system reference"
    int  extrinsics;
} mrcal_camera_index_t;


// An observation of a calibration board. Each "observation" is ONE camera
// observing a board
typedef struct
{
    // which camera is making this observation
    mrcal_camera_index_t icam;

    // indexes the "frames" array to select the pose of the calibration object
    // being observed
    int                  iframe;
} mrcal_observation_board_t;


// The "intrinsics core" of a camera. This defines the final step of a
// projection operation. For instance with a pinhole model we have
//
//   q[0] = focal_xy[0] * x/z + center_xy[0]
//   q[1] = focal_xy[1] * y/z + center_xy[1]
typedef struct
{
    double focal_xy [2];
    double center_xy[2];
} mrcal_intrinsics_core_t;


// An observation of a discrete point. Each "observation" is ONE camera
// observing a single point in space
typedef struct
{
    // which camera is making this observation
    mrcal_camera_index_t icam;

    // indexes the "points" array to select the position of the point being
    // observed
    int                  i_point;

    // Observed pixel coordinates
    // .x, .y are the pixel observations
    // .z is the weight of the observation. Most of the weights are expected to
    // be 1.0. Less precise observations have lower weights.
    mrcal_point3_t px;
} mrcal_observation_point_t;


// The "details" of the optimization problem being solved. We can ask mrcal to
// solve for ALL the lens parameters and ALL the geometry and everything else.
// OR we can ask mrcal to lock down some part of the optimization problem, and
// to solve for the rest. If any variables are locked down, we use their initial
// values passed-in to mrcal_optimize()
typedef struct
{
    // If true, we solve for the intrinsics core. Applies only to those models
    // that HAVE a core (fx,fy,cx,cy)
    bool do_optimize_intrinsics_core        : 1;

    // If true, solve for the non-core lens parameters
    bool do_optimize_intrinsics_distortions : 1;

    // If true, solve for the geometry of the cameras
    bool do_optimize_extrinsics             : 1;

    // If true, solve for the poses of the calibration object
    bool do_optimize_frames                 : 1;

    // If true, apply the regularization terms in the solver
    bool do_apply_regularization            : 1;

    // If true, optimize the shape of the calibration object
    bool do_optimize_calobject_warp         : 1;
} mrcal_problem_details_t;


// Return the number of parameters needed in optimizing the given lens model
//
// This is identical to mrcal_lensmodel_num_params(), but takes into account the
// problem details. Any intrinsics parameters locked down in the
// mrcal_problem_details_t do NOT count towards the optimization parameters
int mrcal_num_intrinsics_optimization_params( mrcal_problem_details_t problem_details,
                                              mrcal_lensmodel_t m );


// Scales a state vector to the packed, unitless form used by the optimizer
//
// In order to make the optimization well-behaved, we scale all the variables in
// the state and the gradients before passing them to the optimizer. The internal
// optimization library thus works only with unitless (or "packed") data.
//
// This function takes an (Nstate,) array of full-units values p[], and scales
// it to produce packed data. This function applies the scaling directly to the
// input array; the input is modified, and nothing is returned.
//
// This is the inverse of mrcal_unpack_solver_state_vector()
void mrcal_pack_solver_state_vector( // out, in
                                     double* p,

                                     // in
                                     int Ncameras_intrinsics, int Ncameras_extrinsics,
                                     int Nframes,
                                     int Npoints, int Npoints_fixed,
                                     mrcal_problem_details_t problem_details,
                                     const mrcal_lensmodel_t lensmodel);


// Scales a state vector from the packed, unitless form used by the optimizer
//
// In order to make the optimization well-behaved, we scale all the variables in
// the state and the gradients before passing them to the optimizer. The internal
// optimization library thus works only with unitless (or "packed") data.
//
// This function takes an (Nstate,) array of unitless values p[], and scales it
// to produce full-units data. This function applies the scaling directly to the
// input array; the input is modified, and nothing is returned.
//
// This is the inverse of mrcal_pack_solver_state_vector()
void mrcal_unpack_solver_state_vector( // out, in
                                       double* p, // unitless state on input,
                                                  // scaled, meaningful state on
                                                  // output

                                       // in
                                       int Ncameras_intrinsics, int Ncameras_extrinsics,
                                       int Nframes,
                                       int Npoints, int Npoints_fixed,
                                       mrcal_problem_details_t problem_details,
                                       const mrcal_lensmodel_t lensmodel);


// Reports the icam_extrinsics corresponding to a given icam_intrinsics.
//
// If we're solving a calibration problem (stationary cameras observing a moving
// calibration object), each camera has a unique intrinsics vector and a unique
// extrinsics vector. And this function reports the latter, given the former. On
// success, the result is written to *icam_extrinsics, and we return true. If
// the given camera is at the reference coordinate system, it has no extrinsics,
// and we report -1.
//
// If we have moving cameras, there won't be a single icam_extrinsics for a
// given icam_intrinsics, and we report an error by returning false
bool mrcal_corresponding_icam_extrinsics(// out
                                         int* icam_extrinsics,

                                         // in
                                         int icam_intrinsics,
                                         int Ncameras_intrinsics,
                                         int Ncameras_extrinsics,
                                         int Nobservations_board,
                                         const mrcal_observation_board_t* observations_board,
                                         int Nobservations_point,
                                         const mrcal_observation_point_t* observations_point);

// Constants used in a mrcal optimization
typedef struct
{
    // The minimum distance of an observed discrete point from its observing
    // camera. Any observation of a point below this range will be penalized to
    // encourage the optimizer to move the point further away from the camera
    double  point_min_range;


    // The maximum distance of an observed discrete point from its observing
    // camera. Any observation of a point abive this range will be penalized to
    // encourage the optimizer to move the point closer to the camera
    double  point_max_range;
} mrcal_problem_constants_t;


// This structure is returned by the optimizer, and contains some statistics
// about the optimization
typedef struct
{
    // generated by an x-macro

    /* The RMS error of the optimized fit at the optimum. Generally the residual */
    /* vector x contains error values for each element of q, so N observed pixels */
    /* produce 2N measurements: len(x) = 2*N. And the RMS error is */
    /*   sqrt( norm2(x) / N ) */
    double rms_reproj_error__pixels;

    /* How many pixel observations were thrown out as outliers. Each pixel */
    /* observation produces two measurements. Note that this INCLUDES any */
    /* outliers that were passed-in at the start */
    int Noutliers;
} mrcal_stats_t;


// Solve the given optimization problem
//
// This is the entry point to the mrcal optimization routine. The argument list
// is commented. It is expected that this will be called from Python only.
mrcal_stats_t
mrcal_optimize( // out
                // Each one of these output pointers may be NULL
                // Shape (Nstate,)
                double* p_packed_final,
                // used only to confirm that the user passed-in the buffer they
                // should have passed-in. The size must match exactly
                int buffer_size_p_packed_final,

                // Shape (Nmeasurements,)
                double* x_final,
                // used only to confirm that the user passed-in the buffer they
                // should have passed-in. The size must match exactly
                int buffer_size_x_final,

                // out, in
                //
                // This is a dogleg_solverContext_t. I don't want to #include
                // <dogleg.h> here, so this is void
                //
                // if(_solver_context != NULL) then this is a persistent solver
                // context. The context is NOT freed on exit.
                // mrcal_free_context() should be called to release it
                //
                // if(*_solver_context != NULL), the given context is reused
                // if(*_solver_context == NULL), a context is created, and
                // returned here on exit
                void** _solver_context,

                // These are a seed on input, solution on output

                // intrinsics is a concatenation of the intrinsics core and the
                // distortion params. The specific distortion parameters may
                // vary, depending on lensmodel, so this is a variable-length
                // structure
                double*             intrinsics,         // Ncameras_intrinsics * NlensParams
                mrcal_pose_t*       extrinsics_fromref, // Ncameras_extrinsics of these. Transform FROM the reference frame
                mrcal_pose_t*       frames_toref,       // Nframes of these.    Transform TO the reference frame
                mrcal_point3_t*     points,             // Npoints of these.    In the reference frame
                mrcal_point2_t*     calobject_warp,     // 1 of these. May be NULL if !problem_details.do_optimize_calobject_warp

                // All the board pixel observations, in order. .x, .y are the
                // pixel observations .z is the weight of the observation. Most
                // of the weights are expected to be 1.0. Less precise
                // observations have lower weights.
                //
                // z<0 indicates that this is an outlier. This is respected on
                // input (even if !do_apply_outlier_rejection). New outliers are
                // marked with z<0 on output, so this isn't const
                mrcal_point3_t* observations_board_pool,
                int Nobservations_board,

                // in
                int Ncameras_intrinsics, int Ncameras_extrinsics, int Nframes,
                int Npoints, int Npoints_fixed, // at the end of points[]

                const mrcal_observation_board_t* observations_board,
                const mrcal_observation_point_t* observations_point,
                int Nobservations_point,

                bool check_gradient,
                bool verbose,
                // Whether to try to find NEW outliers. The outliers given on
                // input are respected regardless
                const bool do_apply_outlier_rejection,

                mrcal_lensmodel_t lensmodel,
                double observed_pixel_uncertainty,
                const int* imagersizes, // Ncameras_intrinsics*2 of these
                mrcal_problem_details_t          problem_details,
                const mrcal_problem_constants_t* problem_constants,

                double calibration_object_spacing,
                int calibration_object_width_n,
                int calibration_object_height_n);


struct cholmod_sparse_struct;

// Evaluate the value of the callback function at the given operating point
//
// The main optimization routine in mrcal_optimize() searches for optimal
// parameters by repeatedly calling a function to evaluate each hypothethical
// parameter set. This evaluation function is available by itself here,
// separated from the optimization loop. The arguments are largely the same as
// those to mrcal_optimize(), but the inputs are all read-only It is expected
// that this will be called from Python only.
bool mrcal_optimizer_callback(// out

                             // These output pointers may NOT be NULL, unlike
                             // their analogues in mrcal_optimize()

                             // Shape (Nstate,)
                             double* p_packed,
                             // used only to confirm that the user passed-in the buffer they
                             // should have passed-in. The size must match exactly
                             int buffer_size_p_packed,

                             // Shape (Nmeasurements,)
                             double* x,
                             // used only to confirm that the user passed-in the buffer they
                             // should have passed-in. The size must match exactly
                             int buffer_size_x,

                             // output Jacobian. May be NULL if we don't need
                             // it. This is the unitless Jacobian, used by the
                             // internal optimization routines
                             struct cholmod_sparse_struct* Jt,


                             // in

                             // intrinsics is a concatenation of the intrinsics core
                             // and the distortion params. The specific distortion
                             // parameters may vary, depending on lensmodel, so
                             // this is a variable-length structure
                             const double*             intrinsics,         // Ncameras_intrinsics * NlensParams
                             const mrcal_pose_t*       extrinsics_fromref, // Ncameras_extrinsics of these. Transform FROM reference frame
                             const mrcal_pose_t*       frames_toref,       // Nframes of these.    Transform TO reference frame
                             const mrcal_point3_t*     points,             // Npoints of these.    In the reference frame
                             const mrcal_point2_t*     calobject_warp,     // 1 of these. May be NULL if !problem_details.do_optimize_calobject_warp

                             int Ncameras_intrinsics, int Ncameras_extrinsics, int Nframes,
                             int Npoints, int Npoints_fixed, // at the end of points[]

                             const mrcal_observation_board_t* observations_board,

                             // All the board pixel observations, in order. .x,
                             // .y are the pixel observations .z is the weight
                             // of the observation. Most of the weights are
                             // expected to be 1.0. Less precise observations
                             // have lower weights.
                             //
                             // z<0 indicates that this is an outlier
                             const mrcal_point3_t* observations_board_pool,
                             int Nobservations_board,

                             const mrcal_observation_point_t* observations_point,
                             int Nobservations_point,
                             bool verbose,

                             mrcal_lensmodel_t lensmodel,
                             double observed_pixel_uncertainty,
                             const int* imagersizes, // Ncameras_intrinsics*2 of these

                             mrcal_problem_details_t          problem_details,
                             const mrcal_problem_constants_t* problem_constants,

                             double calibration_object_spacing,
                             int calibration_object_width_n,
                             int calibration_object_height_n);


// frees a dogleg_solverContext_t. I don't want to #include <dogleg.h> here, so
// this is void
void mrcal_free_context(void** ctx);
#+end_src

**** Layout of the measurement and state vectors
The optimization routine tries to minimize the length of the measurement
vector $\vec x$ by moving around the state vector $\vec p$.

Depending on the specific optimization problem being solved and the
=mrcal_problem_details_t=, the state vector may contain any of

- The lens parameters
- The geometry of the cameras
- The geometry of the observed chessboards and discrete points
- The chessboard shape

The measurement vector may contain
- The errors in observations of the chessboards
- The errors in observations of discrete points
- The penalties in the solved point positions
- The regularization terms

Given the problem details and a vector $\vec p$ or $\vec x$ it is often useful
to know where specific quantities lie in those vectors. Here we have 4 sets of
functions to answer such questions:

- =int mrcal_measurement_index_THING()=
  Returns the index in the measurement vector x where the contiguous block of
  values describing the THING begins. THING is any of
  - boards
  - points
  - regularization

- =int mrcal_num_measurements_THING()=
  Returns the number of values in the contiguous block in the measurement
  vector x that describe the given THING. THING is any of
  - boards
  - points
  - regularization

- =int mrcal_state_index_THING()=
  Returns the index in the state vector p where the contiguous block of
  values describing the THING begins. THING is any of
  - intrinsics
  - extrinsics
  - frames
  - points
  - calobject_warp

- =int mrcal_num_states_THING()=
  Returns the number of values in the contiguous block in the state
  vector p that describe the given THING. THING is any of
  - intrinsics
  - extrinsics
  - frames
  - points
  - calobject_warp

The function listing:

#+begin_src c
int mrcal_measurement_index_boards(int i_observation_board,
                                   int Nobservations_board,
                                   int Nobservations_point,
                                   int calibration_object_width_n,
                                   int calibration_object_height_n);
int mrcal_num_measurements_boards(int Nobservations_board,
                                  int calibration_object_width_n,
                                  int calibration_object_height_n);
int mrcal_measurement_index_points(int i_observation_point,
                                   int Nobservations_board,
                                   int Nobservations_point,
                                   int calibration_object_width_n,
                                   int calibration_object_height_n);
int mrcal_num_measurements_points(int Nobservations_point);
int mrcal_measurement_index_regularization(int Nobservations_board,
                                           int Nobservations_point,
                                           int calibration_object_width_n,
                                           int calibration_object_height_n);
int mrcal_num_measurements_regularization(int Ncameras_intrinsics, int Ncameras_extrinsics,
                                          int Nframes,
                                          int Npoints, int Npoints_fixed, int Nobservations_board,
                                          mrcal_problem_details_t problem_details,
                                          mrcal_lensmodel_t lensmodel);

int mrcal_num_measurements(int Nobservations_board,
                           int Nobservations_point,
                           int calibration_object_width_n,
                           int calibration_object_height_n,
                           int Ncameras_intrinsics, int Ncameras_extrinsics,
                           int Nframes,
                           int Npoints, int Npoints_fixed,
                           mrcal_problem_details_t problem_details,
                           mrcal_lensmodel_t lensmodel);

int mrcal_num_states(int Ncameras_intrinsics, int Ncameras_extrinsics,
                     int Nframes,
                     int Npoints, int Npoints_fixed, int Nobservations_board,
                     mrcal_problem_details_t problem_details,
                     mrcal_lensmodel_t lensmodel);
int mrcal_state_index_intrinsics(int icam_intrinsics,
                                 int Ncameras_intrinsics, int Ncameras_extrinsics,
                                 int Nframes,
                                 int Npoints, int Npoints_fixed, int Nobservations_board,
                                 mrcal_problem_details_t problem_details,
                                 mrcal_lensmodel_t lensmodel);
int mrcal_num_states_intrinsics(int Ncameras_intrinsics,
                                mrcal_problem_details_t problem_details,
                                mrcal_lensmodel_t lensmodel);
int mrcal_state_index_extrinsics(int icam_extrinsics,
                                 int Ncameras_intrinsics, int Ncameras_extrinsics,
                                 int Nframes,
                                 int Npoints, int Npoints_fixed, int Nobservations_board,
                                 mrcal_problem_details_t problem_details,
                                 mrcal_lensmodel_t lensmodel);
int mrcal_num_states_extrinsics(int Ncameras_extrinsics,
                                mrcal_problem_details_t problem_details);
int mrcal_state_index_frames(int iframe,
                             int Ncameras_intrinsics, int Ncameras_extrinsics,
                             int Nframes,
                             int Npoints, int Npoints_fixed, int Nobservations_board,
                             mrcal_problem_details_t problem_details,
                             mrcal_lensmodel_t lensmodel);
int mrcal_num_states_frames(int Nframes,
                            mrcal_problem_details_t problem_details);
int mrcal_state_index_points(int i_point,
                             int Ncameras_intrinsics, int Ncameras_extrinsics,
                             int Nframes,
                             int Npoints, int Npoints_fixed, int Nobservations_board,
                             mrcal_problem_details_t problem_details,
                             mrcal_lensmodel_t lensmodel);
int mrcal_num_states_points(int Npoints, int Npoints_fixed,
                            mrcal_problem_details_t problem_details);
int mrcal_state_index_calobject_warp(int Ncameras_intrinsics, int Ncameras_extrinsics,
                                     int Nframes,
                                     int Npoints, int Npoints_fixed, int Nobservations_board,
                                     mrcal_problem_details_t problem_details,
                                     mrcal_lensmodel_t lensmodel);
int mrcal_num_states_calobject_warp(mrcal_problem_details_t problem_details,
                                    int Nobservations_board);
#+end_src

** Python API
#+NAME: Python API

The full Python API reference is available [[file:mrcal-python-api-reference.html][here]]. Note that everything has
docstrings, so the =pydoc3= tool is effective at displaying the relevant
documentation. For convenience, all the docstrings have been extracted and
formatted into the webpage linked above.


* How to run a calibration
#+NAME: 
talk about --seed and how that can be used to validate intrinsics

** Tutorial
If all you want to do is run a calibration, read this section first.

You need to get observations of a grid of points. This tool doesn't dictate
exactly how these observations are obtained, but the recommended way to do that
is to use [[http://github.com/dkogan/mrgingham][mrgingham]]. This documentation assumes that's what is being done.

See the mrgingham documentation for a .pdf of a chessboard pattern. This pattern
should be printed (at some size; see below) and mounted onto a RIGID and FLAT
surface to produce the calibration object. The most useful observations are
close-ups: views that cover as much of the imager as possible. Thus you
generally a large printout of the chessboard pattern. If you're calibrating a
wide lens then this is especially true: the wider the lens, the larger an object
needs to be in order to cover the field of view.

Now that we have a calibration object, this object needs to be shown to the
camera(s) to produce the images that mrgingham will use to find the corner
coordinates, which mrcal will then use in its computations.

It is important that the images contain clear corners. If the image is badly
overexposed, the white chessboard squares will bleed into each other, the
adjoining black squares will no longer touch each other in the image, and there
would be no corner to detect. Conversely, if the image is badly underexposed,
the black squares will bleed into each other, which would also destroy the
corner. mrgingham tries to handle a variety of lighting conditions, including
varying illumination across the image, but the corners must exist in the image
in some form. A fundamental design decision in mrgingham is to only output
chessboards that we are very confident in, and a consequence of this is that
mrgingham requires the WHOLE chessboard to be visible in order to produce any
results. Thus it requires a bit of effort to produce any data at the edges and
in the corners of the imager: if even a small number of the chessboard corners
are out of bounds, mrgingham will not detect the chessboard at all. A live
preview of the calibration images being gathered is thus essential to aid the
user in obtaining good data. Another requirement due to the design of mrgingham
is that the board should be held with a flat edge parallel to the camera xz
plane (parallel to the ground, usually). mrgingham looks for vertical and
horizontal sequences of corners, but if the board is rotated diagonally, then
none of these sequences are "horizontal" or "vertical", but they're all
"diagonal", which isn't what mrgingham is looking for.

The most useful observations to gather are

- close-ups: the chessboard should fill the whole frame as much as possible

- oblique views: tilt the board forward/back and left/right. I generally tilt by
  more than 45 degrees. At a certain point the corners become indistinct and
  mrgingham starts having trouble, but depending on the lens, that point could
  come with quite a bit of tilt.

- If you are calibrating multiple cameras, and they are synchronized, you can
  calibrate them all at the same time, and obtain intrinsics AND extrinsics. In
  that case you want frames where multiple cameras see the calibration object at
  the same time. Depending on the geometry, it may be impossible to place a
  calibration object in a location where it's seen by all the cameras, AND where
  it's a close-up for all the cameras at the same time. In that case, get
  close-ups for each camera individually, and get observations common to
  multiple cameras, that aren't necessarily close-ups. The former will serve to
  define your camera intrinsics, and the latter will serve to define your
  extrinsics (geometry).

A dataset composed primarily of tilted closeups will produce good results. It is
better to have more data rather than less. mrgingham will throw away frames
where no chessboard can be found, so it is perfectly reasonable to grab too many
images with the expectation that they won't all end up being used in the
computation.

I usually aim for about 100 usable frames, but you can often get away with far
fewer. The mrcal confidence feedback (see below) will tell you if you need more
data.

Once we have gathered input images, we can run the calibration procedure:

#+begin_src sh
mrcal-calibrate-cameras
  --corners-cache corners.vnl
  -j 10
  --focal 2000
  --object-spacing 0.1
  --object-width-n 10
  --outdir /tmp
  --lensmodel LENSMODEL_OPENCV8
  --observed-pixel-uncertainty 1.0
  --explore
  'frame*-camera0.png' 'frame*-camera1.png' 'frame*-camera2.png'
#+end_src

You would adjust all the arguments for your specific case.

The first argument says that the chessboard corner coordinates live in a file
called =corners.vnl=. If this file exists, we'll use that data. If that file
does not exist (which is what will happen the first time), mrgingham will be
invoked to compute the corners from the images, and the results will be written
to that file. So the same command is used to both compute the corners initially,
and to reuse the pre-computed corners with subsequent runs.

=-j 10= says to spread the mrgingham computation across 10 CPU cores. This
command controls mrgingham only; if 'corners.vnl' already exists, this option
does nothing.

=--focal 2000= says that the initial estimate for the camera focal lengths is
2000 pixels. This doesn't need to be precise at all, but do try to get this
roughly correct if possible. Simple geometry says that

  focal_length = imager_width / ( 2 tan (field_of_view_horizontal / 2) )

=--object-spacing= is the width of each square in your chessboard. This depends on
the specific chessboard object you are using. --object-width-n is the corner
count of the calibration object. Currently mrgingham more or less assumes that
this is 10.

=--outdir= specifies the directory where the output models will be written

=--lensmodel= specifies which lens model we're using for the cameras.
At this time all OpenCV lens models are supported, in addition to
LENSMODEL_CAHVOR. The CAHVOR model is there for legacy compatibility only. If
you're not going to be using these models in a system that only supports CAHVOR,
there's little reason to use it. If you use a model that is too lean
(LENSMODEL_PINHOLE or LENSMODEL_OPENCV4 maybe), the model will not fit the data,
especially at the edges; the tool will tell you this. If you use a model that is
too rich (something crazy like LENSMODEL_OPENCV12), then you will need much
more data than you normally would. Most lenses I've seen work well with
LENSMODEL_OPENCV4 or LENSMODEL_OPENCV5 or LENSMODEL_OPENCV8; wider lenses
need richer models.

=--observed-pixel-uncertainty 1.0= says that the x,y corner coordinates reported
by mrgingham are distributed normally, independently, and with the standard
deviation as given in this argument. There's a tool to compute this value
empirically, but it needs more validation. For now pick a value that seems
reasonable. 1.0 pixels or less usually makes sense.

=--explore= says that after the models are computed, a REPL should be open so that
the user can look at various metrics describing the output; more on this
later.

After all the options, globs describing the images are passed in. Note that
these are GLOBS, not FILENAMES. So you need to quote or escape each glob to
prevent the shell from expanding it. You want one glob per camera; in the above
example we have 3 cameras. The program will look for all files matching the
globs, and filenames with identical matched strings are assumed to have been
gathered at the same instant in time. I.e. if in the above example we found
frame003-camera0.png and frame003-camera1.png, we will assume that these two
images were time-synchronized. If your capture system doesn't have
fully-functional frame syncronization, you should run a series of monocular
calibrations. Otherwise the models won't fit well (high reprojection errors
and/or high outlier counts) and you might see a frame with systematic
reprojection errors where one supposedly-synchronized camera's observation pulls
the solution in one direction, and another camera's observation pulls it in
another.

When you run the program as given above, the tool will spend a bit of time
computing (usually 10-20 seconds is enough, but this is highly dependent on the
specific problem, the amount of data, and the computational hardware). When
finished, it will write the resulting models to disk, and open a REPL (if
--explore was given). The resulting filenames are "camera-N.cameramodel" where N
is the index of the camera, starting at 0. The models contain the intrinsics and
extrinsics, with camera-0 sitting at the reference coordinate system.

When the solve is completed, you'll see a summary such as this one:

#+begin_example
RMS reprojection error: 0.3 pixels
Worst reprojection error: 4.0 pixels
Noutliers: 7 out of 9100 total points: 0.1% of the data
#+end_example

The reprojection errors should look reasonable given your
=--observed-pixel-uncertainty=. Since any outliers will be thrown out, the
reported reprojection errors will be reasonable.

Higher outlier counts are indicative of some/all of these:

- Errors in the input data, such as incorrectly-detected chessboard corners, or
  unsynchronized cameras

- Badly-fitting lens model

A lens model that doesn't fit isn't a problem in itself. The results will
simply not be reliable everywhere in the imager, as indicated by the uncertainty
and residual metrics (see below)

With --explore you get a REPL, and a message that points out some useful
functions. Generally you want to start with

#+begin_example
show_residuals_observation_worst(0)
#+end_example

This will show you the worst-fitting chessboard observation with its observed
and predicted corners, as an error vector. The reprojection errors are given by
a colored dot. Corners thrown out as outliers will be missing their colored dot.
You want to make sure that this is reasonable. Incorrectly-detected corners will
be visible: they will be outliers or they will have a high error. The errors
should be higher towards the edge of the imager, especially with a wider lens. A
richer better-fitting model would reduce those errors. Past that, there should
be no pattern to the errors. If the camera synchronization was broken, you'll
see a bias in the error vectors, to compensate for the motion of the chessboard.

Next do this for each camera in your calibration set (icam is an index counting
up from 0):

#+begin_example
show_residuals_regional(icam)
#+end_example

Each of these will pop up 3 plots describing your distribution of errors. You
get

- a plot showing the mean reprojection error across the imager
- a plot showing the standard deviation of reprojection errors across the imager
- a plot showing the number of data points across the imager AFTER the outlier
  rejection

The intrinsics are reliable in areas that have

- a low mean error relative to =--observed-pixel-uncertainty=
- a standard deviation roughly similar to =--observed-pixel-uncertainty=
- have some data available

If you have too little data, you will be overfitting, so you'd be expalining the
signal AND the noise, and your reprojection errors will be too low. With enough
input data you'll be explaining the signal only: the noise is random and with
enough samples our model can't explain it. Another factor that controls this is
the model we're fitting. If we fit a richer model (LENSMODEL_OPENCV8 vs
LENSMODEL_OPENCV4 for instance), the extra parameters will allow us to fit the
data better, and to produce lower errors in more areas of the imager.

These are very rough guidelines; I haven't written the logic to automatically
interpret these yet. A common feature that these plots bring to light is a
poorly-fitting model at the edges of the imager. In that case you'll see higher
errors with a wider distribution towards the edge.

Finally run this:

#+begin_example
show_projection_uncertainty()
#+end_example

This will pop up a plot of projection uncertainties for each camera. The
uncertainties are shown as a color-map along with contours. These are the
expected value of projection based on noise in input corner observations. The
noise is assumed to be independent, 0-mean gaussian with a standard deviation of
--observed-pixel-uncertainty. You will see low uncertainties in the center of
the imager (this is the default focus point; a different one can be picked). As
you move away from the center, you'll see higher errors. You should decide how
much error is acceptable, and determine the usable area of the imager based on
this. These uncertainty metrics are complementary to the residual metrics
described above. If you have too little data, the residuals will be low, but the
uncertainties will be very high. The more data you gather, the lower the
uncertainties. A richer lens model lowers the residuals, but raises the
uncertainties. So with a richer model you need to get more data to get to the
same acceptable uncertainty level.

** Capture images
 - Hold board straight
 - Oblique closeups
** mrgingham
*** mrcal
 - metrics
* Theory
** optimization, weighting, least squares
** research topics
- Is my spline representation good? Can I avoid it crossing itself?
- Note that regularization causes a bias
- Intrinsics uncertainty contains a built-in extrinsics uncertainty. As we move
  the cameras around, we carry with them an uncertain transformation
- Board warping
- outlier rejection. Cook's D
- rotation compensation for the diff
- compensating for board flex
- compensating for focal-length errors
  common-mode errors do not affect yaw. differential-mode errors affect yaw very
  much
- intrinsics errors effect on yaw. I ran some simulations earlier, I think.
  Similar effect: differential errors are very significant

** Model differencing
#+NAME: Model differencing
xzz

** Splined stereographic lens model
#+NAME: Splined stereographic lens model
yyy

* Visualization
- say that the plots are interactive in normal usage
* Other
** interesting stereo discoveries
- compensating for board flex
- compensating for focal-length errors
  common-mode errors do not affect yaw. differential-mode errors affect yaw very
  much
- intrinsics errors effect on yaw. I ran some simulations earlier, I think.
  Similar effect: differential errors are very significant
** things to mention in the talk and in the docs
- talk about regularization bias
- splined models shouldn't fit the core to keep things non-singular
- splined models may not be fitted into opencv8 without moving extrinsics
- say that poor uncertainty = overfitting
- say that we need to track down the source of all errors. The model we're
  optimizing should not produce any error on its own. And it shouldn't produce
  any constraints on its own. The "model" includes the lens model and the
  warping here. Thus the uncertainties are only directly usable with the splined
  models
- talk about how I'm projecting the "same world point", and how there're other
  (possibly-better) methods
- talk about how to get observed_pixel_uncertainty
- talk about how to select an appropriate splined model
- talk about --seed and how that can be used to validate intrinsics

* After-release todo
- feed uncertainties to stereo, triangulation
- compute uncertainties for multiple points at the same time to get covariance.
  Possibly could work across multiple cameras in the same solve as well
- better regularization non/crossing in splined models
- should include a study of how to calibrate long lenses. Tilted observations
  aren't as effective unless the board is GIANT
- Can we study intrinsics stability over time? In response to heating? Shaking?
- Can we use a 3-parallel calibration to quantify chromatic aberration?

* future work

- measure observed_pixel_uncertainty
- use uncertainty in triangulation, deltapose
- improve uncertainty method: faraway obervations don't make things worse
- projection_uncertainty() should be able to project multiple points at a time,
  and to report correlations in the projection
- splined models should behave more nicely at the edges
- sfm
- integrate deltapose-lite
- projection_uncertainty() should report correlated results
- can I quantify the heteroscedasticity and thus the model-nonfitting and the
  resulted expected bias? White test?
- study cubic/quadratic splines, spline density effects
- do a triangulation with explict uncertainty propagation

- Redo, show stability. Heat? Show effects?
- uncertainty questions:
  - study the effects of the spline control points density
  - are quadratic splines better? more sparse, but only c1 instead of c2
  - Can I use the heteroschedasticity metrics to say stuff about the lean
    models?

- mention sfm
- feed uncertainties to stereo, triangulation
- compute uncertainties for multiple points at the same time to get covariance.
  Possibly could work across multiple cameras in the same solve as well
- better regularization non/crossing in splined models
- should include a study of how to calibrate long lenses. Tilted observations
  aren't as effective unless the board is GIANT
- Can we study intrinsics stability over time? In response to heating? Shaking?
- Can we use a 3-parallel calibration to quantify chromatic aberration?
- Measure effect of focus, aperture

* todo for the document
The "commandline tools" link on top is generated wrong

code should no longer refer to the projection_uncertainty() docstring, but
rather refer here

should say what this toolkit isfor, other than calibration
