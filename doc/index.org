#+title: mrcal - a toolkit for manipulating cameras, projections and geometry

* Intro
mrcal is a toolkit for working with lens models, camera geometry, images,
projections, and the various related operations such as camera calibration. This
toolkit was originally built to produce high-accuracy calibrations demanded by
long-range stereo, so it provides facilities to analyze the results and to track
down sources of error.

mrcal provides a routine to compute the "[[file:differencing.org][difference]]" between two models, which
can be a fundamental piece of a wide number of analyses, for instance to measure
a lens's response to temperature cycles.

mrcal provides estimates of [[file:uncertainty.org][projection uncertainty]], which can be used to gauge
calibration quality, and to compute the uncertainty of any data products that
use the lens model.

A rich, [[#Splined stereographic lens model][splined lens model]] is available to fit any projection function and to
provide realistic uncertainty estimates.

The core functionality is exposed from the [[file:c-api.org][C API]], while higher-level routines
are available through [[file:python-api.org][Python]]. The most common workflows are available as
[[#Commandline tools][commandline tools]], with no coding required.

Please see [[file:tour.org][a tour of mrcal]] for a high-level overview of the capabilities of the
toolkit.

* Conventions
** Terminology
Some terms in the documentation and sources can have ambiguous meanings, so I
explicitly define them here

- *calibration*: the procedure used to compute the lens parameters and geometry
  of a set of cameras. Usually this involves a stationary set of cameras
  observing a moving object.

- *calibration object* or *chessboard* or *board*: these are used more or less
  interchangeably. They refer to the known-geometry object observed by the
  cameras, with those observations used as input during calibration

- *pose*: a position and orientation

- *intrinsics*: the parameters describing the behavior of a lens. The pose of
  the lens does not affect the intrinsics

- *extrinsics*: the pose of a lens in respect to some fixed coordinate system

- *frames*: in the context of mrcal's optimization these refer to an array of
  poses of the observed chessboards

- *SFM*: structure from motion. This is the converse of "calibration": we
  observe a stationary scene from a moving camera to compute the geometry of the
  scene

- *state*: the vector of parameters that an optimization algorithm is free to
  move around as it searches for the optimum. mrcal generally refers to this
  vector as $\vec p$

- *measurements* or *residuals*: I use these more or less interchangeably. This
  is the vector whose norm the optimization algorithm is trying to minimize.
  mrcal generally refers to this as $\vec x$, and it contains differences
  between pixel coordinates observed by a camera, and where the state vector
  $\vec p$ predicts those observations should be. The optimization tries to
  minimize these differences by finding the $\vec p$ that minimizes $\left \Vert
  \vec x \right \Vert ^2$

- *project*: to map a point in space to a pixel coordinate where that point
  would be observed by a given camera

- *unproject*: to map a pixel coordinate back to a point in space that would
  produce an observation at that pixel. Unprojection is only unique up-to scale

- *camera model*: this is used to refer to the intrinsics and extrinsics
  together.

- *uncertainty*: a measure of dispersion of some estimator. Higher uncertainty
  implies more dispersion. Inverse of *confidence*

- *confidence*: a measure of dispersion of some estimator. Higher confidence
  implies less dispersion. Inverse of *uncertainty*

** Symbols
*** Geometry
- $\vec q$ is a 2-dimensional vector representing a pixel coordinate: $\left( x,y \right)$

- $\vec v$ is a 3-dimensional vector representing a /direction/ $\left( x,y,z
  \right)$ in space. $\vec v$ is unique only up-to-length. In a camera's
  coordinate system we have $\vec q = \mathrm{project}\left(\vec v \right)$

- $\vec p$ is a 3-dimensional vector representing a /point/ $\left( x,y,z
  \right)$ in space. Unlike $\vec v$, $\vec p$ has a defined range. Like $\vec
  v$ we have $\vec q = \mathrm{project}\left(\vec p \right)$

*** Optimization
The core of the mrcal calibration routine is a nonlinear least-squares
optimization

\[
\min_{\vec p} E = \min_{\vec p} \left \Vert \vec x \left( \vec p \right) \right \Vert ^2
\]

Here we have

- $\vec p$ is the vector of parameters being optimized. It's clear from context
  whether $\vec p$ refers to some point in space, or the optimization vector.

- $\vec x$ is the vector of /measurements/ describing the error of the solution
  at some hypothesis $\vec p$

- $\vec E$ is the cost function being optimized. $E \equiv \left \Vert \vec x \right \Vert ^2$

- $\vec J$ is the /jacobian/ matrix. This is the matrix $\frac{ \partial \vec x
  }{ \partial \vec p }$. Usually this is large and sparse.

** Camera coordinate system
mrcal uses right-handed coordinate systems. No convention is assumed for the
world coordinate system. The canonical /camera/ coordinate system has $x$ and
$y$ as with pixel coordinates in an image: $x$ is to the right and $y$ is down.
$z$ is then forward to complete the right-handed system of coordinates.

** Transformations
We describe transformations as mappings between a representation of a point in
one coordinate system to a representation of the /same/ point in another
coordinate system. =T_AB= is a transformation from coordinate system =B= to
coordinate system =A=. These chain together nicely, so if we know the
transformation between =A= and =B= and between =B= and =C=, we can transform a
point represented in =C= to =A=: =x_A = T_AB T_BC x_C = T_AC x_C=. And =T_AC =
T_AB T_BC=.

** Poses

Various parts of the toolkit have preferred representations of pose, and mrcal
has functions to convert between them. Available representations are:

- =Rt=: a (4,3) numpy array with a (3,3) rotation matrix concatenated with a
  (1,3) translation vector. This form is easy to work with, but there are
  implied constraints: most (4,3) numpy arrays are /not/ valid =Rt=
  transformations.

- =rt=: a (6,) numpy array with a (3,) vector representing a [[https://en.wikipedia.org/wiki/Axis%E2%80%93angle_representation#Rotation_vector][Rodrigues rotation]]
  concatenated with another (3,) vector, representing a rotation. This form
  requires more computations to deal with, but has no implied constraints: /any/
  (6,) numpy array is a valid =rt= transformation. Thus this is the form used
  inside the mrcal optimization routine.

Each of these represents a transformation =rotate(x) + t=.

Since a pose represents a transformation between two coordinate systems, the
toolkit generally refers to a pose as something like =Rt_AB=, which is an
=Rt=-represented transformation to convert a point from a representation in the
coordinate system =B= to a representation in coordinate system =A=.

A Rodrigues rotation vector =r= represents a rotation of =length(r)= radians
around an axis in the direction =r=. Converting between =R= and =r= is done via
the [[https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula][Rodrigues rotation formula]]: using the [[file:mrcal-python-api-reference.html#-r_from_R][=mrcal.r_from_R()=]] and
[[file:mrcal-python-api-reference.html#-R_from_r][=mrcal.R_from_r()=]] functions. For translating /poses/, not just rotations, use
[[file:mrcal-python-api-reference.html#-rt_from_Rt][=mrcal.rt_from_Rt()=]] and [[file:mrcal-python-api-reference.html#-Rt_from_rt][=mrcal.Rt_from_rt()=]].

There're [[file:mrcal-python-api-reference.html#-R_from_quat][several]] [[file:mrcal-python-api-reference.html#-quat_from_R][functions]] to work with unit quaternions as a rotation
representation, but they're lightly used, and exist only for compatibility with
other tools. mrcal does not use quaternions.

** Linear algebra
mrcal follows the usual linear algebra convention of column vectors. So applying
a rotation looks like $\vec b = R \vec a$ where both $\vec a$ and $\vec b$ are
column vectors.

However, numpy print vectors (1-dimensional objects), as /row/ vectors, so the
code treats 1-dimensional objects as transposed vectors. In the code, the above
rotation would be implemented equivalently: $\vec b^T = \vec a^T R^T$. The
[[file:mrcal-python-api-reference.html#-rotate_point_R][=mrcal.rotate_point_R()=]] and [[file:mrcal-python-api-reference.html#-transform_point_Rt][=mrcal.transform_point_Rt()=]] functions serve to
handle this transparently.

A similar issue is that numpy follows the linear algebra convention of indexing
with =(index_column, index_row)= and not the other way around. This runs against
the /other/ convention of referring to image dimensions as =(width, height)= and
referring to pixels as =(x,y)=. mrcal places the =x= coordinate first (as in the
latter) whenever possible, but when interacting directly with numpy, it must
place the =y= coordinate first. The choice being made is very clearly
documented, so when in doubt, do read the docs.

When computing gradients mrcal places the dependent variables in the leading
dimensions, and the independent variables in the trailing dimensions. So in the
above expressions we have $\frac{ \partial \vec b }{ \partial \vec a } = R$ and
row $i$ of $R$ represents the $\frac{ \partial b_i }{ \partial \vec a }$

** Implementation
The core of mrcal is written in C, but most of the API is currently available in
Python only. The python-wrapping is done via the [[https://github.com/dkogan/numpysane/blob/master/README-pywrap.org][=numpysane_pywrap=]] library,
which makes it fairly simple to make the Python interface /and/ provides
[[https://numpy.org/doc/stable/user/basics.broadcasting.html][broadcasting]] support.

The Python layer uses [[https://numpy.org/][numpy]] and [[https://github.com/dkogan/numpysane/][=numpysane=]] heavily. All the plotting is done
with [[https://github.com/dkogan/gnuplotlib][=gnuplotlib=]]. [[https://opencv.org/][OpenCV]] is used a bit, but /only/ in the Python layer (their C
APIs are gone, and the C++ APIs are unstable). Over time the dependence on this
library will decrease even further.

* Camera model file formats

Reading/writing camera models is done in Python with the [[file:mrcal-python-api-reference.html#cameramodel][=mrcal.cameramodel=]]
class. This class supports two different file formats:

- =.cameramodel=: the preferred format. This is a plain text representation of a
  Python =dict=. The pose is represented internally as =rt_fromref=: an =rt=
  transformation /from/ the reference coordinate system /to/ the coordinate
  system of this camera. That is the /internal/ representation: the class
  provides methods to get the transformation in any form.

- =.cahvor=: the alternative format available for compatibility with existing
  tools. If you don't need to interoperate with tools that require this format,
  there's little reason to use it. This format cannot store [[#Splined stereographic lens model][splined models]] or
  the auxillary data required for the [[file:uncertainty.org][uncertainty computations]].

The [[file:mrcal-python-api-reference.html#cameramodel][=mrcal.cameramodel=]] class will intelligently pick the correct file format
based on the filename. The file format is just a way to store data: both the
CAHVOR and OpenCV lens models can be stored in either file format. The
[[file:mrcal-to-cahvor.html][=mrcal-to-cahvor=]] and [[file:mrcal-to-cameramodel.html][=mrcal-to-cameramodel=]] tools can be used to convert
between the two file formats.

The class (and its representation on disk) contains:

- The lens parameters
- The pose of the camera in space
- The =optimization_inputs=: the data used to compute the model initially. Used
  for the uncertainty computations

See the [[file:mrcal-python-api-reference.html#cameramodel][API documentation]] for usage details. A trivial example to

- read two models from disk
- recombine into a joint model that uses the lens parameters from one model with
  geometry from the other
- write to disk

#+begin_src python
model_for_intrinsics = mrcal.cameramodel('model0.cameramodel')
model_for_extrinsics = mrcal.cameramodel('model1.cameramodel')

model_joint = mrcal.cameramodel( model_for_intrinsics )

extrinsics = model_for_extrinsics.extrinsics_rt_fromref()
model_joint.extrinsics_rt_fromref(extrinsics)

model_joint.write('model-joint.cameramodel')
#+end_src

This is the basic operation of the [[file:mrcal-graft-models.html][=mrcal-graft-models= tool]].

Currently there's no support for reading/writing these files in the [[file:c-api.org][C API]]. I
will write it when I need it or when somebody bugs me about it, whichever comes
first.

* Lens models
:PROPERTIES:
:CUSTOM_ID: Lens models
:END:

mrcal supports a wide range of lens models in both C and in Python. The
representation details and projection behaviors are described here.

** Representation
In Python the models are identified with a string =LENSMODEL_XXX= where the
=XXX= selects the specific model in question. For most models, this
specification describes the model fully. For some models, however, the =XXX=
selects a model /family/, and some /configuration parameters/ are required to
define the specific model in question. An example string with a configuration:
=LENSMODEL_SPLINED_STEREOGRAPHIC_order=3_Nx=30_Ny=20_fov_x_deg=170=. The
configuration parameters (=order=3=, =Nx=30= and so on) select the model, and
are /not/ subject to optimization. Currently only the [[#Splined stereographic lens model][splined stereographic
models]] have any configuration, but more will be added over time.

In C, the model family is selected with the [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h#mrcal_lensmodel_type_t][=mrcal_lensmodel_type_t=]] enum. The
elements are the same as the Python model names, but with =MRCAL_= prepended. So
in C the above splined model is of type =MRCAL_LENSMODEL_SPLINED_STEREOGRAPHIC=.
In C the type /and/ configuration are represented by the [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h##mrcal_lensmodel_t][=mrcal_lensmodel_t=]]
structure. Most routines require the configuration to be available. For
instance, the number of parameters needed to fully describe a given model can be
obtained by calling [[file:mrcal-python-api-reference.html#-lensmodel_num_params][=mrcal.lensmodel_num_params()=]] in Python or
[[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h#mrcal_lensmodel_num_params][=mrcal_lensmodel_num_params()=]] in C (requires the full [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h##mrcal_lensmodel_t][=mrcal_lensmodel_t=]]).

** Intrinsics core
Most models contain an "intrinsics core". These are 4 values that appear at the
start of the parameter list:

- $f_x$: the focal-length in the horizontal direction, in pixels
- $f_y$: the focal-length in the vertical direction, in pixels
- $c_x$: the horizontal projection center, in pixels
- $c_y$: the vertical projection center, in pixels

At this time all models contain a core, but this will change in the future.

** Models
*** =LENSMODEL_PINHOLE=
This is the basic "pinhole" model with 4 parameters (the core only). Projection
of a point $\vec p$ is defined as

\[\vec q = \left( \begin{array}{c} f_x \frac{p_x}{p_z} + c_x \\ f_y \frac{p_y}{p_z} + c_y \end{array} \right) \]

This model is defined only in front of the camera, and projects to infinity as
we approach 90 degrees off the projection axis ($p_z \rightarrow 0$). Straight
lines in space remain straight under this projection, and observations of the
same plane by two pinhole cameras define a homography. No real-world lens
follows this projection, so this exists for data processing only.

*** =LENSMODEL_STEREOGRAPHIC=
Another trivial model that exists for data processing, and not to represent real
lenses. Like the pinhole model, this has just the 4 core parameters.

To define the projection of a point $\vec p$, let's define the angle off the
projection axis:

\[ \theta \equiv \tan^{-1} \frac{\left| \vec p_{xy} \right|}{p_z} \]

then

\[ \vec u \equiv \frac{\vec p_{xy}}{\left| \vec p_{xy} \right|} 2 \tan\frac{\theta}{2} \]

and

\[\vec q = \left( \begin{array}{c} f_x u_x + c_x \\ f_y u_y + c_y \end{array} \right) \]

This model is able to project behind the camera, and has a single singularity:
directly opposite the projection axis.

Note that the pinhole model can be defined in the same way, except the pinhole
model has $\vec u \equiv \frac{\vec p_{xy}} {\left| \vec p_{xy} \right|} \tan
\theta$. And we can thus see that for long lenses (where $\theta$ is small) the
pinhole model and the stereographic model function similarly: $\tan \theta
\approx 2 \tan \frac{\theta}{2}$

*** =LENSMODEL_OPENCV4=, =LENSMODEL_OPENCV5=, =LENSMODEL_OPENCV8=, =LENSMODEL_OPENCV12=
These are simple parametric models that have the given number of "distortion"
parameters in addition to the 4 core parameters. The projection behavior is
described in the [[https://docs.opencv.org/4.5.0/d9/d0c/group__calib3d.html#details][OpenCV documentation]]. These do a reasonable (up to a point) job
in representing real-world lenses, /and/ they're compatible with many other
tools.

*** =LENSMODEL_CAHVOR=
mrcal supports =LENSMODEL_CAHVOR=, a lens model used in a number of tools used
at JPL. Primarily this support exists for compatibility. The CAHVOR model has 5
"distortion" parameters in addition to the 4 core parameters. If you want to use
this, you already know what it does.

*** =LENSMODEL_CAHVORE=
This is an extended =LENSMODEL_CAHVOR= to support wider lenses. CAHVORE is only
partially supported: the parameter gradients aren't implemented, so it isn't
currently possible to solve for a CAHVORE model. Full support may be added in
the future.

*** =LENSMODEL_SPLINED_STEREOGRAPHIC_...=
:PROPERTIES:
:CUSTOM_ID: Splined stereographic lens model
:END:

This projection function is a stereographic model with correction factors. We
compute $\vec u$ as in the [[*=LENSMODEL_STEREOGRAPHIC=][=LENSMODEL_STEREOGRAPHIC=]] projection definition
above. We then use $\vec u$ to look-up a $\Delta \vec u$ using two splined
surfaces: one for each of the two elements of

\[ \Delta \vec u \equiv
\begin{bmatrix}
\Delta u_x \left( \vec u \right) \\
\Delta u_y \left( \vec u \right)
\end{bmatrix} \]

Then we can define the rest of the projection function:

\[\vec q =
 \left( \begin{array}{c}
 f_x \left( u_x + \Delta u_x \right) + c_x \\
 f_y \left( u_y + \Delta u_y \right) + c_y
\end{array} \right) \]

The surfaces $\Delta u_x$ and $\Delta u_y$ are defined as B-splines with
evenly-spaced knots (control points) in the space of the domain $\vec u$. The
values of the knots comprise the parameters of this lens model. We're using
B-splines primarily for their local support properties: moving a knot only
affect the surface in the immediate region surrounding that knot. This makes for
a nice optimization problem.

Everything else needed to define the splined surfaces is given in the model
configuration:

- =order=: the degree of each 1D polynomial. This is either 2 (quadratic
  splines, C1 continuous) or 3 (cubic splines, C2 continuous)

- =Nx= and =Ny=: The spline density. We have a =Nx= by =Ny= grid of
  evenly-spaced control points. More control points results in more parameters
  and a more flexible model. Naturally this also increases the amount of
  calibration data we need to achieve the same projection uncertainty. The ratio
  of =Nx= to =Ny= should usually follow the ratio of the two imager dimensions,
  but this isn't required. No data-driven method of choosing =Nx= or =Ny= is
  available at this time. Something will be built eventually.

- =fov_x_deg=: The horizontal field of view, in degrees. Controls the area where
  the spline is defined. Beyond this area the projection function will use the
  nearest spline patch. This will produce continuous, but very aphysical
  projection behavior. =fov_y_deg= is not included in the configuration: it is
  assumed proportional with =Ny= and =Nx=.

**** Splined models and uncertainties
This splined model has many more parameters, and is far more flexible than the
lean parametric models (all the other lens models). This has several significant
effects.

These models are much more capable of representing the behavior of real-world
lenses than the lean models. At a certain level of precision, the parametric
models are always wrong.

As usual, the flip side of this flexibility is potential overfitting.
"Overfitting" means that the solution is influenced too much by random noise,
and not enough by the input data. mrcal explicitly quantifies the effects of
input noise in its [[file:uncertainty.org][uncertainty estimates]], so it reports exactly how much
overfitting is happening, and the user can decide whether that is acceptable or
not. More than that, mrcal reports the covariance matrix of any projection
operations, so the uncertainty can be propagated to whatever is using the model.
This is much better than simply deciding whether a given calibration is
good-enough.

More parameters do imply more overfitting, so these rich models /do/ have higher
reported uncertainties (see the [[file:tour.org::#uncertainty][tour of mrcal]] for examples). This is a good
thing, however: the lean models report uncertainty estimates that are low, but
do not match reality, while the higher uncertainty estimates from the splined
models do. This is because the [[file:uncertainty.org][uncertainty estimate algorithm]] constrains the
lenses to the space that's representable by a given lens model, which is a
constraint that only exists on paper.

It is thus recommended to use splined models even for long lenses, which do fit
the pinhole model more or less

**** Splined model optimization practicalities
***** Core redundancy
As can be seen in the projection function above, the splined stereographic model
contains splined correction factors $\Delta \vec u$ /and/ an intrinsics core.
The core variables are largely redundant with $\Delta \vec u$: for any
perturbation in the core, we can achieve a /very/ similar change in projection
behavior by bumping $\Delta \vec u$ in a specific way. As a result, if we allow
the optimization algorithm to control all the variables, the system will be
under-determined, and the optimization routine will fail: complaining about a
"not positive definite" (singular in this case) Hessian. At best the Hessian
will be slightly non-singular, but convergence will be slow. To resolve this,
the recommended sequence for optimizing splined stereographic models is:

1. Fit the best =LENSMODEL_STEREOGRAPHIC= to compute an estimate of the
   intrinsics core
2. Refine that solution with a full =LENSMODEL_SPLINED_STEREOGRAPHIC_...= model,
   using the core we just computed, and asking the optimizer to lock down those
   core values. This can be done by setting the =do_optimize_intrinsics_core=
   bit to 0 in the [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_problem_details_t=]] structure passed to
   [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_optimize()=]] in C (or passing =do_optimize_intrinsics_core=False= to
   [[file:mrcal-python-api-reference.html#-optimize][=mrcal.optimize()=]] in Python). This is what the [[file:mrcal-calibrate-cameras.html][=mrcal-calibrate-cameras=]]
   tool does.

***** Regularization
:PROPERTIES:
:CUSTOM_ID: splined model regularization
:END:
Another issue that comes up is the treatment of areas in the imager where no
points were observed. By design, each parameter of the splined model controls
projection from a small area in space. So what happens if we haven't gathered
any data from an area? We then don't have anything to suggest to the solver what
values the corresponding variables should take: they don't affect the cost
function at all. Trying to optimize such a problem will result in a singular
Hessian, and complaints from the solver. Currently we address this issue with
regularization. mrcal applies light [[https://en.wikipedia.org/wiki/L2_regularization][L2 regularization]] to all the spline
parameters. Thus $\Delta \vec u$ is always pulled lightly towards 0. The weights
are chosen to be light-enough to not noticeably affect the optimization where we
do have data. Where we don't have data, though, the optimizer now /does/ have
information to act on: pull $\Delta \vec u$ towards 0. This could be handled
better in the future.

***** Uglyness at the edges
:PROPERTIES:
:CUSTOM_ID: splined non-monotonicity
:END:
An unwelcome property of the projection function defined above, is that it
allows aphysical, nonmonotonic behavior to be represented. For instance, let's
look at the gradient in one particular direction.

\begin{eqnarray*}
q_x &=& f_x \left( u_x + \Delta u_x \right) + c_x \\
\frac{\mathrm{d}q_x}{\mathrm{d}u_x} &\propto& 1 + \frac{\mathrm{d}\Delta u_x}{\mathrm{d}u_x}
\end{eqnarray*}

We would expect $\frac{\mathrm{d}q_x}{\mathrm{d}u_x}$ to always be positive, but
as we can see, here that depends on $\frac{\mathrm{d}\Delta
u_x}{\mathrm{d}u_x}$, which could be /anything/ since $\Delta u_x$ is an
arbitrary spline function. Most of the time we're fitting the spline into real
data, so the real-world monotonic behavior will be represented. However, near
the edges the behavior is driven by [[#splined model regularization][regularization]], which is /not/ based on
data, and we're very likely to hit this odd-looking non-monotonic behavior
there. This looks bad, but it's not /really/ a problem: we get aphysical
behavior in areas where we don't have any data to know better, and we wouldn't
expect to have any confidence in projection in those areas anyway. But it looks
bad, and it makes the [[file:mrcal-show-splined-model-surface.html][=mrcal-show-splined-model-surface= tool]] produce
odd-looking knot layouts and imager contours. A better regularization scheme or
(better yet) a better representation would fix this. This will be addressed in
time.

**** Splined models: selecting the configuration
:PROPERTIES:
:CUSTOM_ID: splined models configuration selection
:END:
If we want to calibrate a camera using a splined lens model, how do we select
the configuration parameters? Here are some rules of thumb.

- =order=: Use =3= (cubic splines). I haven't yet done a thorough study on this,
  but some initial empirical results tell me that quadratic splines are
  noticeably less flexible, and require a denser spline to fit as well as a
  comparable cubic spline.

- =Nx= and =Ny=: their ratio should match the aspect ratio of the imager. Inside
  each spline patch we effectively have a lean parametric model. So choosing a
  too-sparse spline spacing will result in not being able to fit real-world
  lenses. I haven't yet done a study on this either, but =Nx=30_Ny=20= appears
  to work well for some /very/ wide lenses I tested with.

- =fov_x_deg=: this should be set widely-enough to cover the full viewable
  angular span in space, but not so wide to waste spline knots representing
  space outside the camera's field of view. Estimate this from the datasheet of
  the lens, and run a calibration. The [[file:mrcal-show-splined-model-surface.html][=mrcal-show-splined-model-surface= tool]]
  can be used to compare the imager bounds against the bounds of the
  valid-spline region. Note that the spline behavior at the edges of the imager
  is usually not well-defined (since it's difficult to get usable calibration
  data there), so reports of unprojectable imager regions from that tool should
  be taken with an appropriate grain of salt. =mrcal-show-splined-model-surface=
  has a =--observations= option to overlay the observations onto that plot. The
  existing observations /must/ all lie within the valid-projection region.

* Commandline tools
:PROPERTIES:
:CUSTOM_ID: Commandline tools
:END:

A number of commandline tools are available for common tasks. If you're just
using mrcal to calibrate some cameras, you may not need anything else.

- [[file:mrcal-calibrate-cameras.html][=mrcal-calibrate-cameras=]]: calibrate N cameras. This is the main tool to solve
  "calibration" problems.
- [[file:mrcal-show-projection-diff.html][=mrcal-show-projection-diff=]]: visualize the projection difference between a
  number of models
- [[file:mrcal-show-projection-uncertainty.html][=mrcal-show-projection-uncertainty=]]: visualize the projection uncertainty of a
  model
- [[file:mrcal-show-valid-intrinsics-region.html][=mrcal-show-valid-intrinsics-region=]]: Visualizes the region where a model's
  intrinsics are valid
- [[file:mrcal-is-within-valid-intrinsics-region.html][=mrcal-is-within-valid-intrinsics-region=]]: Augments a vnlog of pixel
  coordinates with a column indicating whether or not each point lies within
  the valid-intrinsics region
- [[file:mrcal-convert-lensmodel.html][=mrcal-convert-lensmodel=]]: Fits the behavior of one lens model to another
- [[file:mrcal-show-geometry.html][=mrcal-show-geometry=]]: Shows a visual representation of the geometry
  represented by some camera models on disk, and optionally, the
  chessboard observations used to compute that geometry
- [[file:mrcal-show-distortion-off-pinhole.html][=mrcal-show-distortion-off-pinhole=]]: visualize the deviation of a specific
  lens model from a pinhole model
- [[file:mrcal-show-splined-model-surface.html][=mrcal-show-splined-model-surface=]]: visualize the surface and knots used in
  the specification of splined models
- [[file:mrcal-reproject-image.html][=mrcal-reproject-image=]]: Given image(s) and lens model(s), produces a new set
  of images that observe the same scene with a different model. Several flavors
  of functionality are included here, such as undistortion-to-pinhole,
  re-rotation, and remapping to infinity.
- [[file:mrcal-reproject-points.html][=mrcal-reproject-points=]]: Given two lens models and a set of pixel coodinates,
  maps them from one lens model to the other
- [[file:mrcal-graft-models.html][=mrcal-graft-models=]]: Combines the intrinsics of one cameramodel with the
  extrinsics of another
- [[file:mrcal-to-cahvor.html][=mrcal-to-cahvor=]]: Converts a model stored in the native =.cameramodel= file
  format to the =.cahvor= format. This exists for compatibility only, and does
  not touch the data: any lens model may be used
- [[file:mrcal-to-cameramodel.html][=mrcal-to-cameramodel=]]: Converts a model stored in the =.cahvor= file format
  to the =.cameramodel= format. This exists for compatibility only, and does not
  touch the data: any lens model may be used
- [[file:mrcal-cull-corners.html][=mrcal-cull-corners=]]: Filters a corners.vnl on stdin to cut out some points

* Developer manual (APIs)
The mrcal toolkit has APIs in both C and Python. Everything that could
potentially be slow is written in C, but the higher-level logic is mostly in
Python. The Python-wrapping is done via the [[https://github.com/dkogan/numpysane/blob/master/README-pywrap.org][=numpysane_pywrap=]] library, which
makes it fairly simple to build the Python interfaces in a standard way, so over
time Python-only functionality will be translated to C, as needed (with
backwards-compatible Python wrappers replacing the Python implementations).

* Calibration object
:PROPERTIES:
:CUSTOM_ID: Calibration object
:END:
This is called a "chessboard" or just "board" in some parts of the code. The
optimization code refers to the chessboard pose array as "frames".

When running a camera calibration, we use observations of a known-geometry
object. At this time mrcal expects this object to be a planar grid of observable
points, with possibly a small amount of [[#board deformation][deformation]].

Usually this object is a chessboard-like grid of black and white squares, where
the observed points are the corners between squares. These are detected and
serve as the input features to mrcal. mrcal is a purely geometrical toolkit, so
this vision problem must be handled by another library. I recommend [[https://github.com/dkogan/mrgingham/][=mrgingham=]],
but any other source of grid observations may be used.

When given an image of a chessboard, the detector is directly observing the
feature we actually care about. Another common calibration board style is a grid
of circles. When given an image of a grid of circles, the detector sees the edge
of each circle, and then infers the circle center. This is difficult to do
accurately when given tilted images subjected to arbitrary lens behaviors. The
resulting inaccuracies in detections of the circle centers will introduce biases
into the solve that aren't modeled by the [[file:uncertainty.org::#noise model][projection uncertainty routine]], so
chessboards are /strongly/ recommended.

mrcal [[file:uncertainty.org::#noise model][assumes independent noise]] on each point observation, so correlated sources
of points (such as corners of an apriltag) are also not appropriate sources of
data currently. Apriltag centers would work, however.

** Board deformation
:PROPERTIES:
:CUSTOM_ID: board deformation
:END:

The calibration object is assumed to be planar. However, large calibration
boards used for calibration of wide lenses are never flat: temperature and
humidity effects deform the board strongly-enough to affect the calibration.
mrcal models this deformation with two axis-aligned parabolic factors. If the
chessboard grid spans $[-1,1]$ along the $x$ and $y$ axes, then I define the
non-planar deformation as $z \equiv k_x (1 - x^2) + k_y (1 - y^2)$ with $k_x$
and $k_y$ being the two deformation factors being optimized by the solver.

Empirically, this appears to work well: I get better-fitting solves, and less
systematic error. And the optimal deformation factors $k_x$, $k_y$ are
consistent between different calibrations. A richer deformation model could work
even better, and will eventually be the studied.

* After-release todo                                               :noexport:
- feed uncertainties to stereo, triangulation
- compute uncertainties for multiple points at the same time to get covariance.
  Possibly could work across multiple cameras in the same solve as well
- better regularization non/crossing in splined models
- should include a study of how to calibrate long lenses. Tilted observations
  aren't as effective unless the board is GIANT
- Can we study intrinsics stability over time? In response to heating? Shaking?
- Can we use a 3-parallel calibration to quantify chromatic aberration?

* future work                                                      :noexport:

- measure observed_pixel_uncertainty
- use uncertainty in triangulation, deltapose
- improve uncertainty method: faraway obervations don't make things worse
- projection_uncertainty() should be able to project multiple points at a time,
  and to report correlations in the projection
- splined models should behave more nicely at the edges
- sfm
- integrate deltapose-lite
- projection_uncertainty() should report correlated results
- can I quantify the heteroscedasticity and thus the model-nonfitting and the
  resulted expected bias? White test?
- study cubic/quadratic splines, spline density effects
- do a triangulation with explict uncertainty propagation

- Redo, show stability. Heat? Show effects?
- uncertainty questions:
  - study the effects of the spline control points density
  - are quadratic splines better? more sparse, but only c1 instead of c2
  - Can I use the heteroschedasticity metrics to say stuff about the lean
    models?

- feed uncertainties to stereo, triangulation
- compute uncertainties for multiple points at the same time to get covariance.
  Possibly could work across multiple cameras in the same solve as well
- better regularization non/crossing in splined models
- should include a study of how to calibrate long lenses. Tilted observations
  aren't as effective unless the board is GIANT
- Can we study intrinsics stability over time? In response to heating? Shaking?
- Can we use a 3-parallel calibration to quantify chromatic aberration?
- Measure effect of focus, aperture
- I still don't quite understand why I needed such a wide FOV. Test program:
#+begin_src python
#!/usr/bin/python3

import sys
import numpy as np
import numpysane as nps
import gnuplotlib as gp
import mrcal

model = mrcal.cameramodel( "/home/dima/jpl/mrcaldocs/data/board/splined.cameramodel" )

N = 200
th = np.linspace(-np.pi, np.pi, N)

v = nps.glue( nps.transpose(np.sin(th)),
              np.zeros((N,1), dtype=float),
              nps.transpose(np.cos(th)),
              axis=-1)

print(model.intrinsics()[0])
q = mrcal.project( v, *model.intrinsics() )

gp.plot( th*180./np.pi, (q - np.array((6000,4000))/2.).transpose(),
         equation=("3000","-3000"),
         wait=1, yrange=[-5000., 5000.])
#+end_src

- cahvore linearity should be a config parameter
- cahvore: non-gradientness should be a metadata parameter
- stereo.py should be a separate tool
- better outlier rejection. cook's D

- better regularization scheme for the splined models. I should pull not towards
  0 but towards the mean. I had an implementation in
  c8f9918023142d7ee463821661dc5bcc8f770b51 that I reverted because any planar
  splined surface would have "perfect" regularization, and that was breaking
  things (crazy focal lengths would be picked). But now that I'm locking down
  the intrinsics core when optimizing splined models, this isn't a problem anymore

- dance-study: board dimensions, point counts

** research topics
- Is my spline representation good? Can I avoid it crossing itself?
- rotation compensation for the diff
- compensating for focal-length errors
  common-mode errors do not affect yaw. differential-mode errors affect yaw very
  much
- intrinsics errors effect on yaw. I ran some simulations earlier, I think.
  Similar effect: differential errors are very significant
- splined models may not be fitted into opencv8 without moving extrinsics
- say that poor uncertainty = overfitting
- say that we need to track down the source of all errors. The model we're
  optimizing should not produce any error on its own. And it shouldn't produce
  any constraints on its own. The "model" includes the lens model and the
  warping here. Thus the uncertainties are only directly usable with the splined
  models
- talk about how I'm projecting the "same world point", and how there're other
  (possibly-better) methods
- talk about --seed and how that can be used to validate intrinsics

* todo for the document                                            :noexport:

diffs

document m-c-c and/or mrcal.optimize and/or mrcal_optimize

stereo. Try opencv rectification





code should no longer refer to the projection_uncertainty() docstring, but
rather refer here

should say what this toolkit is for, other than calibration

something somewhere should describe the optimizer_callback()

Somewhere talk about these:
  - [[file:mrcal-python-api-reference.html#-ingest_packed_state][=mrcal.ingest_packed_state()=]]: Read a given packed state into optimization_inputs
  - [[https://github.jpl.nasa.gov/maritime-robotics/mrcal/blob/master/mrcal.h][=mrcal_corresponding_icam_extrinsics()=]]
  - [[file:mrcal-python-api-reference.html#-corresponding_icam_extrinsics][=mrcal.corresponding_icam_extrinsics()=]]: Return the icam_extrinsics corresponding to a given icam_intrinsics



the individual documentation pages need a title, and links to/from. sitemap?

tour: stereo shouldn't use deltapose, but a procrustes fit. Much better demo

Add some sort of "visualization" section

Add some sort of "Stereo" section. Compare with opencv rectification
