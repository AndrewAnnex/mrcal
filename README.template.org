* SYNOPSIS

#+BEGIN_EXAMPLE
$ mrcal-calibrate-cameras --focal 2000
                    --outdir /tmp --object-spacing 0.01
                    --object-width-n 10 '/tmp/left*.png' '/tmp/right*.png'

... lots of output as the solve runs ...
Wrote /tmp/camera0-0.cameramodel
Wrote /tmp/camera0-1.cameramodel
#+END_EXAMPLE

* SUMMARY

Mrcal is a generic toolkit to solve calibration and SFM-like problems.
Functionality related to these problems is exposed as a set of python libraries.
Both CAHVOR and OpenCV distortion models are fully supported; CAHVORE is
partially supported. The toolkit includes:

- Some libraries:
  - =libmrcal=: A flexible solver core written in C and providing a C API that
    solves the underlying optimization problem
  - =mrcal=: a Python library that contains (among other things) an interface
    to this core. Other things provided by the =mrcal= Python library:
    - functions to read/write/manipulate camera models
    - functions to manipulate 3D poses
    - functions to (un)project and (un)distort data

- Some tools:
  - =mrcal-calibrate-cameras=: calibrates N cameras
  - =mrcal-convert-distortion=: fits one distortion model to another
  - =mrcal-show-distortion=: visualize the distortion effects of a specific
    model
  - =mrcal-show-intrinsics-uncertainty=: visualize the uncertainty of intrinsics
    due to noise in the calibration inputs
  - =mrcal-show-intrinsics-diff=: visualize the difference between the
    intrinsics of a number of models
  - =mrcal-undistort-image=: Given image(s) and a distortion model, produces a
    new set of images that have removed the distortion
  - =mrcal-redistort-points=: Given two distortion models and a set of points,
    maps them from one distortion model to the other
  - =mrcal-redistort-image=: Given two distortion models and two images, maps
    them from one distortion model to the other
  - =mrcal-graft-cameramodel=: Combines the intrinsics of one cameramodel with
    the extrinsics of another
  - =mrcal-to-cahvor=: Converts a model stored in the native =.cameramodel= file
    format to the =.cahvor= format. This exists for compatibility only, and does
    not touch the data: the lens distortion may or may not use the CAHVOR
    distortion model
  - =mrcal-to-cameramodel=: Converts a model stored in the legacy =.cahvor= file
    format to the =.cameramodel= format. This exists for compatibility only, and
    does not touch the data: the lens distortion may or may not use the CAHVOR
    distortion model
  - =mrcal-show-geometry=: Shows a visual representation of the extrinsics of N
    cameras

These libraries and tools make it easy to both produce calibrations in many ways
and to manipulate them by moving stuff around, grafting various
intrinsics/extrinsics, etc.

* DESCRIPTION

** Fundamental assumptions

Some notational conventions are used throught the code and implementation, and
they're explicitly described here.

*** Coordinate system conventions

No convention is assumed for the world coordinate system. The canonical camera
coordinate system has =x,y= as with pixel coordinates in an image: =x= is to the
"right" and =y= is "down". =z= is then "forward" to complete the right-handed
system of coordinates

*** Transformation conventions

When describing a transformation (or its rotation/translation components) that
maps a point represented in coordinate system A to its representation in
coordinate system B, =T_AB= is the notation used. These chain together nicely,
so if we know the transformation between =A= and =B= and between =B= and =C=, we
can transform a point represented in =C= to =A=: =x_A = T_AB T_BC x_C=.

*** Pose representations

Various parts of the toolkit have preferred representations of pose, and =mrcal=
has functions to convert between them. Available representations are:

- =Rt=: a (4,3) numpy array with a (3,3) rotation matrix concatenated with a
  (1,3) translation vector

- =rt=: a (6,) numpy array with a (3,) vector representing a Rodrigues rotation
  concatenated with another (3,) vector, representing a rotation.

Each of these represents a transformation =rotate(x) + t=.

Since a pose represents a transformation between two coordinate systems, the
toolkit generally refers to a pose as something like =Rt_AB=, which is an
=Rt=-represented transformation to convert a point from a representation in the
coordinate system =B= to a representation in coordinate system =A=. =B=

A Rodrigues rotation vector =r= represents a rotation of =length(r)= radians
around an axis in the direction =r=. Converting between =R= and =r= is done via
the [[https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula][Rodrigues rotation formula]]. This is implemented in OpenCV Python function
=cv2.Rodrigues=. For translating /poses/, not just rotations, use
=mrcal.Rt_from_rt()= and =mrcal.rt_from_Rt()=.

** Camera model file formats

Reading/writing cameramodels is done in Python with the =mrcal.cameramodel=
class. This class supports two different file formats:

- =.cameramodel=: the preferred format. This is a simple text representation
  that has clear sections for the distortion model, pinhole intrinsics,
  distortion coefficients, and an extrinsic pose. The pose is represented as
  =rt_fromref=: an =rt= transformation /from/ the reference coordinate system
  /to/ the coordinate system of this camera. The class provides methods to get
  the transformation in any form, but =rt_fromref= is the internal
  representation

- =.cahvor=: the legacy format. This exists for compatibility with existing JPL
  tools. There's no other reason to use this format

The file format is just a way to store data: any distortion model can be stored
in any file format. Currently some things aren't representable in a =.cahvor=
file (covariance stuff), but only mrcal tools know what to do with that data,
and mrcal supports =.cameramodel= files.

** Distortion models

Distortion models are specified as elements of =enum distortion_model_t= (in C)
or, as strings that match the entries of that enum (in Python). Currently I
support all CAHVOR flavors and all models implemented in OpenCV. A limitation is
that the solver core does not support CAHVORE, so use the OpenCV models if a
high-distoriton model is required. Currently the supported models are:

- =DISTORTION_NONE=
- =DISTORTION_OPENCV4=
- =DISTORTION_OPENCV5=
- =DISTORTION_OPENCV8=
- =DISTORTION_OPENCV12= (if we have OpenCV >= 3.0.0)
- =DISTORTION_OPENCV14= (if we have OpenCV >= 3.1.0)
- =DISTORTION_CAHVOR=
- =DISTORTION_CAHVORE=

** Calibration object

When running a camera calibration, we use camera observations of a calibration
object (usually a chessboard). These images must be converted to a set of pixels
where chessboard corners were observed. =mrcal= is a purely geometrical toolkit,
so this vision problem is handled by another library: [[https://github.com/dkogan/mrgingham/][=mrgingham=]]. See its
documentation for more details.

* MANPAGES
** mrcal-calibrate-cameras
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-calibrate-cameras-xxx
#+END_EXAMPLE
** mrcal-convert-distortion
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-convert-distortion-xxx
#+END_EXAMPLE
** mrcal-show-distortion
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-show-distortion-xxx
#+END_EXAMPLE
** mrcal-show-intrinsics-uncertainty
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-show-intrinsics-uncertainty-xxx
#+END_EXAMPLE
** mrcal-show-intrinsics-diff
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-show-intrinsics-diff-xxx
#+END_EXAMPLE
** mrcal-undistort-image
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-undistort-image-xxx
#+END_EXAMPLE
** mrcal-redistort-points
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-redistort-points-xxx
#+END_EXAMPLE
** mrcal-redistort-image
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-redistort-image-xxx
#+END_EXAMPLE
** mrcal-graft-cameramodel
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-graft-cameramodel-xxx
#+END_EXAMPLE
** mrcal-to-cahvor
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-to-cahvor-xxx
#+END_EXAMPLE
** mrcal-to-cameramodel
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-to-cameramodel-xxx
#+END_EXAMPLE
** mrcal-show-geometry
#+BEGIN_EXAMPLE
xxx-manpage-mrcal-show-geometry-xxx
#+END_EXAMPLE


* REPOSITORY

https://github.jpl.nasa.gov/maritime-robotics/mrcal/

* AUTHOR

Dima Kogan (=Dmitriy.Kogan@jpl.nasa.gov=)

* LICENSE AND COPYRIGHT

All of this is currently proprietary. Do not distribute outside of JPL

Copyright 2016-2018 California Institute of Technology
