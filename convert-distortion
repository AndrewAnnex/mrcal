#!/usr/bin/python2


r'''Converts a camera model from one distortion model to another

Synopsis:

  $ convert-distortion --viz --to DISTORTION_OPENCV4 left.cameramodel > left.opencv4.cameramodel

  ... lots of output as the solve runs ...
  libdogleg at dogleg.c:1064: success! took 10 iterations
  RMS error of the solution: 3.40256580058 pixels.

  ... a plot pops up showing the vector field of the difference ...


Description:

This is a tool to convert a given camera model from one distortion model to
another. The input and output models have identical extrinsics and an identical
intrinsic core (focal lengths, center pixel coords). The ONLY differing part is
the distortion coefficients.

While the distortion models all exist to solve the same problem, the different
representations don't map to one another perfectly, so this tool seeks to find
the best fit only. It does this by sampling a number of points in the imager,
converting them to observation vectors in the camera coordinate system (using
the given camera model), and then fitting a new camera model (with a different
distortions) that matches the observation vectors to the source imager
coordinates.

Note that the distortion model implementations are usually optimized in the
'undistort' direction, not the 'distort' direction, so the step of converting
the target imager coordinates to observation vectors can be slow. This is highly
dependent on the camera model specifically. CAHVORE especially is glacial. This
can be mitigated somewhat by a better implementation, but in the meantime,
please be patient.

Camera models have originally been computed by a calibration procedure that
takes as input a number of point observations, and the resulting models are only
valid in an area where those observations were available; it's an extrapolation
everywhere else. This is generally OK, and we try to cover the whole imager when
calibrating cameras. Models with high distortions (CAHVORE, OPENCV >= 8)
generally have quickly-increasing effects towards the edges of the imager, and
the distortions represented by these models at the extreme edges of the imager
are often not reliable, since the initial calibration data is rarely available
at the extreme edges. Thus using points at the extreme edges to fit another
model is often counterproductive, and I provide the --where and --radius
commandline options for this case. We use data in a circular region of the
imager. This region is centered on the point given by --where (or at the center
of the imager, if omitted). The radius of this region is given by --radius. If
'--radius 0' is given, I use ALL the data. A radius<0 can be used to set the
size of the no-data margin at the corners; in this case I'll use sqrt(width^2 +
height^2) - abs(radius)

'''



import sys
import numpy as np
import numpysane as nps
import cv2
import re
import argparse
import os

import mrcal

def parse_args():

    parser = \
        argparse.ArgumentParser(description = __doc__,
                                formatter_class=argparse.RawDescriptionHelpFormatter)
    parser.add_argument('--to',
                        required=True,
                        type=str,
                        help='The target distortion model')

    parser.add_argument('--verbose',
                        action='store_true',
                        help='''Report the solver details''')

    parser.add_argument('--viz',
                        action='store_true',
                        help='''Visualize the difference''')
    parser.add_argument('--where',
                        type=float,
                        nargs=2,
                        help='''I use a subset of the imager to compute the fit. The active region is a
                        circle centered on this point. If omitted, we will
                        focus on the center of the imager''')
    parser.add_argument('--radius',
                        type=float,
                        default=0.,
                        help='''I use a subset of the imager to compute the fit. The active region is a
                        circle with a radius given by this paramter. If radius
                        == 0, I'll use the whole imager for the fit. If radius <
                        0, this parameter specifies the width of the region at
                        the corners that I should ignore: I will use
                        sqrt(width^2 + height^2) - abs(radius). This is valid
                        ONLY if we're focussing at the center of the imager''')

    parser.add_argument('cameramodel',
                        type=lambda f: f if os.path.isfile(f) else \
                                parser.error("The cameramodel must be an existing readable file, but got '{}'".format(f)),
                        nargs=1,
                        help='''Input camera model. Assumed to be mrcal native, Unless the name is xxx.cahvor,
                        in which case the cahvor format is assumed''')

    return parser.parse_args()




args = parse_args()

distortionmodel_to = args.to
try:
    Ndistortions = mrcal.getNdistortionParams(distortionmodel_to)
except:
    raise Exception("Unknown distortion model: '{}'".format(distortionmodel_to))


m = mrcal.cameramodel(args.cameramodel[0])

intrinsics_from = m.intrinsics()
distortionmodel_from = intrinsics_from[0]

if distortionmodel_from == distortionmodel_to:
    sys.stderr.write("Input and output have the same distortion model: {}. Returning the input\n".format(distortionmodel_to))
    sys.stderr.write("RMS error of the solution: 0 pixels.\n")
    m.write(sys.stdout)
    sys.exit(0)


if distortionmodel_to == 'DISTORTION_CAHVORE':
    raise Exception("DISTORTION_CAHVORE models aren't supported at this time: gradients aren't implemented")




# Alrighty. Let's actually do the work. I do this:
#
# 1. Sample the imager space with the known model
# 2. Unproject to get the 3d observation vectors
# 3. Solve a new model that fits those vectors to the known observations, but
#    using the new model
dims = m.imagersize()
if dims is None:
    sys.stderr.write("Warning: imager size not available. Using centerpixel*2\n")
    dims = m.intrinsics()[1][2:4] * 2


### I sample the pixels in an NxN grid
N       = 60
Npoints = N*N

px = np.linspace(0, dims[0]-1, N)
py = np.linspace(0, dims[1]-1, N)

# pxy is (N*N, 2). Each slice of pxy[:] is an (x,y) pixel coord
pxy = nps.transpose(nps.clump( nps.cat(*np.meshgrid(px,py)), n=-2))
if args.radius != 0:
    # we use a subset of the input data for the fit
    if args.where is None:
        focus_center = (dims - 1.) / 2.
    else:
        focus_center = args.where

    if args.radius > 0:
        r = args.radius
    else:
        if nps.norm2(focus_center - (dims - 1.) / 2) > 1e-3:
            sys.stderr.write("A radius <0 is only implemented if we're focussing on the imager center\n")
            sys.exit(1)
        r = np.sqrt(nps.norm2(dims)) + args.radius

    grid_off_center = pxy - focus_center
    i = nps.norm2(grid_off_center) < r*r
    pxy = pxy[i, ...]


### I unproject this, with broadcasting
v = mrcal.unproject( pxy, m.intrinsics() )


### Solve!

### I solve the optimization a number of times with different random seed
### values, taking the best-fitting results. This is required for the richer
### models such as DISTORTION_OPENCV8
err_rms_best = 1e10
intrinsics_values_best = np.array(())
for i in xrange(40): # this many trials
    # random seed for the new intrinsics
    intrinsics_core = m.intrinsics()[1][:4]
    distortions     = (np.random.rand(Ndistortions) - 0.5) * 1e-8 # random initial seed
    intrinsics_to_values = nps.dummy(nps.glue(intrinsics_core, distortions, axis=-1),
                                     axis=-2)
    # range-less points
    observations_points = nps.glue(pxy, -np.ones((Npoints, 1),), axis=-1)
    observations_points = np.ascontiguousarray(observations_points) # must be contiguous. mrcal.optimize() should really be more lax here

    # Which points we're observing. This is dense and kinda silly for this
    # application. Each slice is (i_point,i_camera)
    indices_points = nps.transpose(nps.glue(np.arange(Npoints,    dtype=np.int32),
                                            np.zeros ((Npoints,), dtype=np.int32), axis=-2))
    indices_points = np.ascontiguousarray(indices_points) # must be contiguous. mrcal.optimize() should really be more lax here

    # Moving rotation too can make this better. Current formulation doesn't
    # allow this.
    # - have a way to use custom calibration objects
    # - optimize the single view of this object by tweaking ONLY the rotation
    # - for data I generate I can regularize the off-center optical axis. But
    #   this doesn't help for other people's data
    mrcal.optimize(intrinsics_to_values,
                   None, # no extrinsics. Just one camera
                   None, # no frames. Just points
                   v,
                   None, # no board observations
                   None, # no board observations
                   observations_points,
                   indices_points,
                   distortionmodel_to,

                   do_optimize_intrinsic_core        = False,
                   do_optimize_intrinsic_distortions = True,
                   do_optimize_extrinsics            = False,
                   do_optimize_frames                = False,
                   VERBOSE                           = args.verbose)
    pxy_solved = mrcal.project( v,
                                distortionmodel_to,
                                intrinsics_to_values.ravel())
    diff = pxy_solved - pxy
    err_rms = np.sqrt(np.mean(nps.inner(diff, diff)))
    sys.stderr.write("RMS error of this solution: {} pixels.\n".format(err_rms))
    if err_rms < err_rms_best:
        err_rms_best = err_rms
        intrinsics_values_best = np.array(intrinsics_to_values)



sys.stderr.write("RMS error of the BEST solution: {} pixels.\n".format(err_rms_best))
m_to = mrcal.cameramodel( intrinsics            = (distortionmodel_to, intrinsics_values_best.ravel()),
                          extrinsics_rt_fromref = m.extrinsics_rt(False),
                          imagersize            = dims )
m_to.write(sys.stdout)

if args.viz:

    plot = mrcal.show_intrinsics_diff( (m, m_to),
                                       focus_radius=0, # don't compute an implicit rotation
                                       cbmax=10)
    plot.wait()

